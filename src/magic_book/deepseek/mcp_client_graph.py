"""
DeepSeek MCP å®¢æˆ·ç«¯å›¾æ¶æ„ - äºŒæ¬¡æ¨ç†å¢å¼ºç‰ˆ

æ ¸å¿ƒ APIï¼š
==========
- create_mcp_workflow(): åˆ›å»º MCP å·¥ä½œæµçŠ¶æ€å›¾
- execute_mcp_workflow(): æ‰§è¡Œå·¥ä½œæµå¹¶è¿”å›å“åº”æ¶ˆæ¯

å·¥ä½œæµèŠ‚ç‚¹è¯´æ˜ï¼š
=================

1. é¢„å¤„ç†èŠ‚ç‚¹ (preprocess)
   - æ„å»ºç³»ç»Ÿæç¤ºï¼ŒåŒ…å«å·¥å…·ä½¿ç”¨è¯´æ˜
   - å‡†å¤‡å¢å¼ºæ¶ˆæ¯ä¾› LLM ä½¿ç”¨
   - æ™ºèƒ½å¤„ç†å·²æœ‰çš„ç³»ç»Ÿæ¶ˆæ¯ï¼ˆè¿½åŠ è€Œéæ›¿æ¢ï¼‰

2. é¦–æ¬¡ LLM è°ƒç”¨ (llm_invoke)
   - ä½¿ç”¨å¤–éƒ¨ä¼ å…¥çš„ DeepSeek LLM å®ä¾‹
   - è°ƒç”¨ DeepSeek ç”Ÿæˆåˆå§‹å“åº”
   - å¯èƒ½åŒ…å« JSON æ ¼å¼çš„å·¥å…·è°ƒç”¨æŒ‡ä»¤

3. å·¥å…·è§£æèŠ‚ç‚¹ (tool_parse)
   - ä½¿ç”¨ ToolCallParser è§£æ LLM å“åº”ä¸­çš„å·¥å…·è°ƒç”¨
   - æ”¯æŒ JSON æ ¼å¼ï¼š{"tool_call": {"name": "...", "arguments": {...}}}
   - åˆ¤æ–­æ˜¯å¦éœ€è¦æ‰§è¡Œå·¥å…·

4. æ¡ä»¶åˆ†æ”¯ï¼š
   - å¦‚æœéœ€è¦å·¥å…·æ‰§è¡Œ â†’ tool_execution
   - å¦‚æœä¸éœ€è¦å·¥å…· â†’ response_synthesis

5. å·¥å…·æ‰§è¡ŒèŠ‚ç‚¹ (tool_execution)
   - ä½¿ç”¨ asyncio.gather() å¹¶å‘æ‰§è¡Œæ‰€æœ‰å·¥å…·è°ƒç”¨
   - æ”¯æŒè¶…æ—¶æ§åˆ¶å’Œå¤±è´¥é‡è¯•ï¼ˆæœ€å¤š2æ¬¡ï¼‰
   - æ”¶é›†å·¥å…·æ‰§è¡Œç»“æœï¼ˆåŒ…å«æˆåŠŸçŠ¶æ€ã€ç»“æœæ•°æ®ã€æ‰§è¡Œæ—¶é—´ï¼‰

6. **äºŒæ¬¡æ¨ç†èŠ‚ç‚¹ (llm_re_invoke) [æ ¸å¿ƒåˆ›æ–°]**
   - å°†å·¥å…·ç»“æœä½œä¸ºä¸Šä¸‹æ–‡ï¼Œå†æ¬¡è°ƒç”¨ LLM
   - è®© AI åŸºäºå·¥å…·ç»“æœè¿›è¡Œæ™ºèƒ½åˆ†æå’Œå›ç­”
   - ä¿æŒåŸæœ‰çš„è§’è‰²è®¾å®šï¼ˆå¦‚æµ·ç›—è¯­æ°”ç­‰ï¼‰
   - **çµæ´»å¤„ç†ç”¨æˆ·æ ¼å¼è¦æ±‚**ï¼š
     * ç¦æ­¢å·¥å…·è°ƒç”¨æ ¼å¼çš„ JSON
     * ä½†å…è®¸ç”¨æˆ·è¦æ±‚çš„è¾“å‡ºæ ¼å¼ï¼ˆJSON/Markdown/YAML ç­‰ï¼‰
     * ä¸¥æ ¼éµå®ˆç”¨æˆ·åœ¨ Human Message ä¸­æŒ‡å®šçš„æ‰€æœ‰çº¦æŸ

7. å“åº”åˆæˆèŠ‚ç‚¹ (response_synthesis)
   - å¤„ç†æœ€ç»ˆå“åº”è¾“å‡º
   - ä¼˜å…ˆä½¿ç”¨äºŒæ¬¡æ¨ç†ç»“æœï¼ˆæœ‰å·¥å…·æ‰§è¡Œçš„æƒ…å†µï¼‰
   - é™çº§ä½¿ç”¨åŸå§‹ LLM å“åº”ï¼ˆæ— å·¥å…·æ‰§è¡Œæˆ–äºŒæ¬¡æ¨ç†å¤±è´¥ï¼‰

æ¶æ„ä¼˜åŠ¿ï¼š
=========
- âœ… çœŸæ­£çš„æ™ºèƒ½å·¥å…·ç»“æœå¤„ç†ï¼Œè€Œéç®€å•æ‹¼æ¥
- âœ… ä¿æŒ AI è§’è‰²è®¾å®šå’Œå¯¹è¯é£æ ¼
- âœ… å°Šé‡ç”¨æˆ·çš„æ ¼å¼å’Œç»“æ„è¦æ±‚
- âœ… æ›´è‡ªç„¶çš„äººæœºäº¤äº’ä½“éªŒ
- âœ… æ”¯æŒå¤æ‚å·¥å…·ç»“æœçš„æ·±åº¦åˆ†æ
- âœ… å¤–éƒ¨ LLM å®ä¾‹ç®¡ç†ï¼Œæé«˜çµæ´»æ€§å’Œå¯æµ‹è¯•æ€§

è®¾è®¡åŸåˆ™ï¼š
=========
1. **çŠ¶æ€é©±åŠ¨**ï¼šä½¿ç”¨ McpState TypedDict ç®¡ç†æ‰€æœ‰çŠ¶æ€
2. **å…³æ³¨ç‚¹åˆ†ç¦»**ï¼šæ¯ä¸ªèŠ‚ç‚¹ä¸“æ³¨å•ä¸€èŒè´£
3. **å¯ç»„åˆæ€§**ï¼šèŠ‚ç‚¹å¯ç‹¬ç«‹æµ‹è¯•å’Œæ›¿æ¢
4. **é”™è¯¯å®¹é”™**ï¼šå®Œå–„çš„é”™è¯¯å¤„ç†å’Œé™çº§ç­–ç•¥
5. **ç”¨æˆ·æ„å›¾ä¼˜å…ˆ**ï¼šäºŒæ¬¡æ¨ç†ä¸¥æ ¼éµå®ˆç”¨æˆ·è¦æ±‚

æµç¨‹å›¾ï¼š
=======
preprocess â†’ llm_invoke â†’ tool_parse â†’ [æ¡ä»¶åˆ¤æ–­]
                                          â†“ (éœ€è¦å·¥å…·)
                                    tool_execution â†’ llm_re_invoke â†’ response_synthesis
                                          â†“ (ä¸éœ€è¦å·¥å…·)
                                    response_synthesis

ä½¿ç”¨ç¤ºä¾‹ï¼š
=========
```python
# 1. åˆ›å»ºå·¥ä½œæµ
llm = create_deepseek_llm()
workflow = await create_mcp_workflow("my_workflow", mcp_client)

# 2. æ„å»ºçŠ¶æ€
chat_history: McpState = {
    "messages": [SystemMessage(content="ä½ æ˜¯æµ·ç›—")],
    "llm": llm,
    "mcp_client": mcp_client,
    "available_tools": tools,
}

user_input: McpState = {
    "messages": [HumanMessage(content="ç°åœ¨å‡ ç‚¹äº†ï¼Ÿç”¨JSONæ ¼å¼å›ç­”")],
    "llm": llm,
    "mcp_client": mcp_client,
    "available_tools": tools,
}

# 3. æ‰§è¡Œå·¥ä½œæµ
responses = await execute_mcp_workflow(workflow, chat_history, user_input)
```
"""

from dotenv import load_dotenv
from loguru import logger

# åŠ è½½ .env æ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡
load_dotenv()

import asyncio
from typing import Annotated, Any, Dict, List, Optional
from langchain.schema import AIMessage, SystemMessage, HumanMessage
from langchain_core.messages import BaseMessage
from langchain_deepseek import ChatDeepSeek
from langgraph.graph import StateGraph
from langgraph.graph.message import add_messages
from langgraph.graph.state import CompiledStateGraph
from typing_extensions import TypedDict

# å¯¼å…¥ç»Ÿä¸€ MCP å®¢æˆ·ç«¯å’ŒåŠŸèƒ½
from ..mcp import (
    McpClient,
    McpToolInfo,
    ToolCallParser,
    execute_mcp_tool,
    build_json_tool_example,
    format_tool_description_simple,
)


############################################################################################################
class McpState(TypedDict, total=False):
    """
    MCP å¢å¼ºçš„çŠ¶æ€ï¼ŒåŒ…å«æ¶ˆæ¯å’Œ MCP å®¢æˆ·ç«¯ç›¸å…³ä¿¡æ¯
    """

    messages: Annotated[List[BaseMessage], add_messages]
    llm: Optional[ChatDeepSeek]  # DeepSeek LLMå®ä¾‹ï¼Œæ•´ä¸ªgraphæµç¨‹å…±äº«
    mcp_client: Optional[McpClient]  # MCP å®¢æˆ·ç«¯
    available_tools: List[McpToolInfo]  # å¯ç”¨çš„ MCP å·¥å…·
    tool_outputs: List[Dict[str, Any]]  # å·¥å…·æ‰§è¡Œç»“æœ

    # æ–°å¢å­—æ®µç”¨äºå¤šèŠ‚ç‚¹æµç¨‹
    system_prompt: Optional[str]  # ç³»ç»Ÿæç¤ºç¼“å­˜
    enhanced_messages: List[BaseMessage]  # åŒ…å«ç³»ç»Ÿæç¤ºçš„å¢å¼ºæ¶ˆæ¯
    llm_response: Optional[BaseMessage]  # LLMåŸå§‹å“åº”
    parsed_tool_calls: List[Dict[str, Any]]  # è§£æå‡ºçš„å·¥å…·è°ƒç”¨
    needs_tool_execution: bool  # æ˜¯å¦éœ€è¦æ‰§è¡Œå·¥å…·

    # äºŒæ¬¡æ¨ç†æ¶æ„æ–°å¢å­—æ®µ
    final_response: Optional[BaseMessage]  # æœ€ç»ˆå“åº”ï¼ˆæ¥è‡ªäºŒæ¬¡æ¨ç†æˆ–åŸå§‹å“åº”ï¼‰


############################################################################################################
def _build_tool_instruction_prompt(available_tools: List[McpToolInfo]) -> str:
    """
    æ„å»ºç³»ç»Ÿæç¤ºï¼Œä»…æ”¯æŒJSONæ ¼å¼å·¥å…·è°ƒç”¨

    Args:
        available_tools: å¯ç”¨å·¥å…·åˆ—è¡¨

    Returns:
        str: æ„å»ºå¥½çš„ç³»ç»Ÿæç¤º
    """
    # å·¥å…·ä½¿ç”¨è¯´æ˜ï¼ˆä¸åŒ…å«è§’è‰²è®¾å®šï¼‰
    tool_instruction_prompt = """å½“ä½ éœ€è¦è·å–å®æ—¶ä¿¡æ¯æˆ–æ‰§è¡Œç‰¹å®šæ“ä½œæ—¶ï¼Œå¯ä»¥è°ƒç”¨ç›¸åº”çš„å·¥å…·ã€‚

## å·¥å…·è°ƒç”¨æ ¼å¼

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è°ƒç”¨å·¥å…·ï¼ˆæ”¯æŒåŒæ—¶è°ƒç”¨å¤šä¸ªï¼‰ï¼š

```json
{
  "tool_call": {
    "name": "å·¥å…·åç§°1",
    "arguments": {
      "å‚æ•°å": "å‚æ•°å€¼1"
    }
  }
}

{
  "tool_call": {
    "name": "å·¥å…·åç§°2",
    "arguments": {
      "å‚æ•°å": "å‚æ•°å€¼2"
    }
  }
}
```

## ä½¿ç”¨æŒ‡å—

- æ ¹æ®éœ€è¦è°ƒç”¨ä¸€ä¸ªæˆ–å¤šä¸ªå·¥å…·ï¼ˆè°ƒç”¨ä¸€ä¸ªå·¥å…·åªæ˜¯å¤šä¸ªçš„ç‰¹ä¾‹ï¼‰
- å¯ä»¥åœ¨å›å¤ä¸­è‡ªç„¶åœ°è§£é‡Šä½ è¦åšä»€ä¹ˆï¼Œç„¶ååŒ…å«å·¥å…·è°ƒç”¨
- å·¥å…·æ‰§è¡Œå®Œæˆåï¼Œæ ¹æ®ç»“æœç»™å‡ºå®Œæ•´çš„å›ç­”
- å¦‚æœå·¥å…·æ‰§è¡Œå¤±è´¥ï¼Œè¯·ä¸ºç”¨æˆ·æä¾›æ›¿ä»£æ–¹æ¡ˆæˆ–è§£é‡ŠåŸå› """

    if not available_tools:
        tool_instruction_prompt += "\n\nâš ï¸ å½“å‰æ²¡æœ‰å¯ç”¨å·¥å…·ï¼Œè¯·ä»…ä½¿ç”¨ä½ çš„çŸ¥è¯†å›ç­”é—®é¢˜ã€‚"
        return tool_instruction_prompt

    # æ„å»ºå·¥å…·æè¿° - ç®€åŒ–ç‰ˆæœ¬ï¼Œç»Ÿä¸€ä½¿ç”¨çº¿æ€§å±•ç¤º
    tool_instruction_prompt += "\n\n## å¯ç”¨å·¥å…·"

    # ç›´æ¥åˆ—è¡¨å±•ç¤ºæ‰€æœ‰å·¥å…·ï¼Œæ— éœ€åˆ†ç±»
    for tool in available_tools:
        tool_desc = format_tool_description_simple(tool)
        tool_instruction_prompt += f"\n{tool_desc}"

    # æ·»åŠ å·¥å…·è°ƒç”¨ç¤ºä¾‹
    example_tool = available_tools[0]
    tool_instruction_prompt += f"\n\n## è°ƒç”¨ç¤ºä¾‹\n\n"
    tool_instruction_prompt += build_json_tool_example(example_tool)

    return tool_instruction_prompt


############################################################################################################
async def _preprocess_node(state: McpState) -> McpState:
    """
    é¢„å¤„ç†èŠ‚ç‚¹ï¼šå‡†å¤‡ç³»ç»Ÿæç¤ºå’Œå¢å¼ºæ¶ˆæ¯

    Args:
        state: å½“å‰çŠ¶æ€

    Returns:
        McpState: æ›´æ–°åçš„çŠ¶æ€
    """
    try:
        messages = state["messages"]
        available_tools = state.get("available_tools", [])

        # æ„å»ºç³»ç»Ÿæç¤º
        tool_instruction_prompt = _build_tool_instruction_prompt(available_tools)

        # æ™ºèƒ½æ·»åŠ ç³»ç»Ÿæ¶ˆæ¯ï¼šå¦‚æœå·²æœ‰ç³»ç»Ÿæ¶ˆæ¯åˆ™è¿½åŠ ï¼Œå¦åˆ™æ’å…¥åˆ°å¼€å¤´
        enhanced_messages = messages.copy()
        if enhanced_messages and isinstance(enhanced_messages[0], SystemMessage):
            # å·²ç»æœ‰ç³»ç»Ÿæ¶ˆæ¯åœ¨å¼€å¤´ï¼Œè¿½åŠ æ–°çš„å·¥å…·è¯´æ˜
            enhanced_messages.insert(1, SystemMessage(content=tool_instruction_prompt))
        else:
            # æ²¡æœ‰ç³»ç»Ÿæ¶ˆæ¯ï¼Œæ’å…¥é»˜è®¤è§’è‰²è®¾å®šå’Œå·¥å…·è¯´æ˜åˆ°å¼€å¤´
            default_role_prompt = (
                "ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œå…·æœ‰ä½¿ç”¨å·¥å…·çš„èƒ½åŠ›ã€‚\n\n" + tool_instruction_prompt
            )
            enhanced_messages.insert(0, SystemMessage(content=default_role_prompt))

        result: McpState = {
            "messages": [],  # é¢„å¤„ç†èŠ‚ç‚¹ä¸è¿”å›æ¶ˆæ¯ï¼Œé¿å…é‡å¤ç´¯ç§¯
            "llm": state["llm"],  # ç›´æ¥ä½¿ç”¨çŠ¶æ€ä¸­çš„LLMå®ä¾‹
            "mcp_client": state.get("mcp_client"),
            "available_tools": available_tools,
            "tool_outputs": state.get("tool_outputs", []),
            "system_prompt": tool_instruction_prompt,  # ä¿å­˜ç³»ç»Ÿæç¤ºä¾›åç»­ä½¿ç”¨
            "enhanced_messages": enhanced_messages,  # ä¿å­˜å¢å¼ºæ¶ˆæ¯ä¾›LLMä½¿ç”¨
        }
        return result

    except Exception as e:
        logger.error(f"é¢„å¤„ç†èŠ‚ç‚¹é”™è¯¯: {e}")
        return state


############################################################################################################
async def _llm_invoke_node(state: McpState) -> McpState:
    """
    LLMè°ƒç”¨èŠ‚ç‚¹ï¼šè°ƒç”¨DeepSeekç”Ÿæˆå“åº”

    Args:
        state: å½“å‰çŠ¶æ€

    Returns:
        McpState: æ›´æ–°åçš„çŠ¶æ€
    """
    try:
        # ä½¿ç”¨çŠ¶æ€ä¸­çš„ ChatDeepSeek å®ä¾‹
        llm = state["llm"]
        assert llm is not None, "LLM instance is None in state"

        # ä½¿ç”¨å¢å¼ºæ¶ˆæ¯ï¼ˆåŒ…å«ç³»ç»Ÿæç¤ºï¼‰è¿›è¡ŒLLMè°ƒç”¨
        enhanced_messages = state.get("enhanced_messages", state["messages"])

        # è°ƒç”¨ LLM
        response = llm.invoke(enhanced_messages)

        result: McpState = {
            "messages": [],  # LLMè°ƒç”¨èŠ‚ç‚¹ä¸è¿”å›æ¶ˆæ¯ï¼Œé¿å…é‡å¤ç´¯ç§¯
            "llm": llm,  # ä¼ é€’LLMå®ä¾‹
            "mcp_client": state.get("mcp_client"),
            "available_tools": state.get("available_tools", []),
            "tool_outputs": state.get("tool_outputs", []),
            "llm_response": response,  # ä¿å­˜LLMå“åº”ä¾›åç»­å¤„ç†
            "enhanced_messages": enhanced_messages,  # ä¼ é€’å¢å¼ºæ¶ˆæ¯
        }
        return result

    except Exception as e:
        logger.error(f"LLMè°ƒç”¨èŠ‚ç‚¹é”™è¯¯: {e}")
        error_message = AIMessage(content=f"æŠ±æ­‰ï¼Œå¤„ç†è¯·æ±‚æ—¶å‘ç”Ÿé”™è¯¯ï¼š{str(e)}")
        llm_error_result: McpState = {
            "messages": [error_message],  # åªè¿”å›é”™è¯¯æ¶ˆæ¯
            "llm": state["llm"],  # ä¿æŒLLMå®ä¾‹
            "mcp_client": state.get("mcp_client"),
            "available_tools": state.get("available_tools", []),
            "tool_outputs": [],
        }
        return llm_error_result


############################################################################################################
async def _tool_parse_node(state: McpState) -> McpState:
    """
    å·¥å…·è§£æèŠ‚ç‚¹ï¼šä½¿ç”¨å¢å¼ºè§£æå™¨è§£æLLMå“åº”ä¸­çš„å·¥å…·è°ƒç”¨

    Args:
        state: å½“å‰çŠ¶æ€

    Returns:
        McpState: æ›´æ–°åçš„çŠ¶æ€
    """
    try:
        llm_response = state.get("llm_response")
        available_tools = state.get("available_tools", [])

        parsed_tool_calls = []

        if llm_response and available_tools:
            response_content = str(llm_response.content) if llm_response.content else ""

            # ä½¿ç”¨å¢å¼ºçš„å·¥å…·è°ƒç”¨è§£æå™¨
            parser = ToolCallParser(available_tools)
            parsed_tool_calls = parser.parse_tool_calls(response_content)

            logger.info(f"ğŸ“‹ è§£æåˆ° {len(parsed_tool_calls)} ä¸ªå·¥å…·è°ƒç”¨")
            for call in parsed_tool_calls:
                logger.debug(f"   - {call['name']}: {call['args']}")

        result: McpState = {
            "messages": [],  # å·¥å…·è§£æèŠ‚ç‚¹ä¸è¿”å›æ¶ˆæ¯ï¼Œé¿å…é‡å¤ç´¯ç§¯
            "llm": state["llm"],  # ä¼ é€’LLMå®ä¾‹
            "mcp_client": state.get("mcp_client"),
            "available_tools": available_tools,
            "tool_outputs": state.get("tool_outputs", []),
            "llm_response": llm_response,
            "parsed_tool_calls": parsed_tool_calls,
            "needs_tool_execution": len(parsed_tool_calls) > 0,
        }
        return result

    except Exception as e:
        logger.error(f"å·¥å…·è§£æèŠ‚ç‚¹é”™è¯¯: {e}")
        # å‘ç”Ÿé”™è¯¯æ—¶ï¼Œç»§ç»­æµç¨‹ä½†ä¸æ‰§è¡Œå·¥å…·
        error_result: McpState = {
            "messages": [],
            "llm": state["llm"],  # ä¼ é€’LLMå®ä¾‹
            "mcp_client": state.get("mcp_client"),
            "available_tools": state.get("available_tools", []),
            "tool_outputs": state.get("tool_outputs", []),
            "llm_response": state.get("llm_response"),
            "parsed_tool_calls": [],
            "needs_tool_execution": False,
        }
        return error_result


############################################################################################################
async def _tool_execution_node(state: McpState) -> McpState:
    """
    å·¥å…·æ‰§è¡ŒèŠ‚ç‚¹ï¼šæ‰§è¡Œè§£æå‡ºçš„å·¥å…·è°ƒç”¨ï¼ˆå¢å¼ºç‰ˆï¼‰

    Args:
        state: å½“å‰çŠ¶æ€

    Returns:
        McpState: æ›´æ–°åçš„çŠ¶æ€
    """
    try:
        parsed_tool_calls = state.get("parsed_tool_calls", [])
        mcp_client = state.get("mcp_client")

        tool_outputs = []

        if parsed_tool_calls and mcp_client:
            logger.info(f"ğŸ”§ å¼€å§‹æ‰§è¡Œ {len(parsed_tool_calls)} ä¸ªå·¥å…·è°ƒç”¨")

            # ä½¿ç”¨ asyncio.gather() ç»Ÿä¸€å¤„ç†æ‰€æœ‰å·¥å…·è°ƒç”¨ï¼ˆçœŸæ­£å¹¶å‘æ‰§è¡Œï¼‰
            tasks = []
            for tool_call in parsed_tool_calls:
                task = execute_mcp_tool(
                    tool_call["name"],
                    tool_call["args"],
                    mcp_client,
                    timeout=30.0,
                    max_retries=2,  # ç»Ÿä¸€ä½¿ç”¨2æ¬¡é‡è¯•
                )
                tasks.append((tool_call, task))

            # çœŸæ­£å¹¶å‘æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
            try:
                execution_results = await asyncio.gather(
                    *[task for _, task in tasks], return_exceptions=True
                )

                for (tool_call, _), exec_result in zip(tasks, execution_results):
                    if isinstance(exec_result, Exception):
                        logger.error(
                            f"å·¥å…·æ‰§è¡Œä»»åŠ¡å¤±è´¥: {tool_call['name']}, é”™è¯¯: {exec_result}"
                        )
                        tool_outputs.append(
                            {
                                "tool": tool_call["name"],
                                "args": tool_call["args"],
                                "result": f"æ‰§è¡Œå¤±è´¥: {str(exec_result)}",
                                "success": False,
                                "execution_time": 0.0,
                            }
                        )
                    elif isinstance(exec_result, tuple) and len(exec_result) == 3:
                        success, task_result, exec_time = exec_result
                        tool_outputs.append(
                            {
                                "tool": tool_call["name"],
                                "args": tool_call["args"],
                                "result": task_result,
                                "success": success,
                                "execution_time": exec_time,
                            }
                        )
                    else:
                        # æ„å¤–çš„ç»“æœç±»å‹
                        logger.error(
                            f"å·¥å…·æ‰§è¡Œè¿”å›æ„å¤–ç»“æœç±»å‹: {tool_call['name']}, ç»“æœ: {exec_result}"
                        )
                        tool_outputs.append(
                            {
                                "tool": tool_call["name"],
                                "args": tool_call["args"],
                                "result": f"æ„å¤–ç»“æœç±»å‹: {type(exec_result)}",
                                "success": False,
                                "execution_time": 0.0,
                            }
                        )
            except Exception as e:
                logger.error(f"å¹¶å‘æ‰§è¡Œå·¥å…·å¤±è´¥: {e}")
                # é™çº§å¤„ç†ï¼šä¸ºæ‰€æœ‰å·¥å…·è°ƒç”¨è®°å½•é”™è¯¯
                for tool_call in parsed_tool_calls:
                    tool_outputs.append(
                        {
                            "tool": tool_call["name"],
                            "args": tool_call["args"],
                            "result": f"å¹¶å‘æ‰§è¡Œå¤±è´¥: {str(e)}",
                            "success": False,
                            "execution_time": 0.0,
                        }
                    )

            # ç»Ÿè®¡æ‰§è¡Œç»“æœ
            successful_calls = sum(1 for output in tool_outputs if output["success"])
            total_time = sum(output["execution_time"] for output in tool_outputs)

            logger.info(
                f"âœ… å·¥å…·æ‰§è¡Œå®Œæˆ: {successful_calls}/{len(tool_outputs)} æˆåŠŸ, "
                f"æ€»è€—æ—¶: {total_time:.2f}s"
            )

        final_result: McpState = {
            "messages": [],  # å·¥å…·æ‰§è¡ŒèŠ‚ç‚¹ä¸è¿”å›æ¶ˆæ¯ï¼Œé¿å…é‡å¤ç´¯ç§¯
            "llm": state["llm"],  # ä¼ é€’LLMå®ä¾‹
            "mcp_client": mcp_client,
            "available_tools": state.get("available_tools", []),
            "tool_outputs": tool_outputs,
            "llm_response": state.get("llm_response"),
            "parsed_tool_calls": parsed_tool_calls,
        }
        return final_result

    except Exception as e:
        logger.error(f"å·¥å…·æ‰§è¡ŒèŠ‚ç‚¹é”™è¯¯: {e}")
        # å³ä½¿æ‰§è¡Œå¤±è´¥ï¼Œä¹Ÿè¦è¿”å›çŠ¶æ€ä»¥ç»§ç»­æµç¨‹
        error_result: McpState = {
            "messages": [],
            "llm": state["llm"],  # ä¼ é€’LLMå®ä¾‹
            "mcp_client": state.get("mcp_client"),
            "available_tools": state.get("available_tools", []),
            "tool_outputs": [
                {
                    "tool": "ç³»ç»Ÿ",
                    "args": {},
                    "result": f"å·¥å…·æ‰§è¡ŒèŠ‚ç‚¹å‘ç”Ÿé”™è¯¯: {str(e)}",
                    "success": False,
                    "execution_time": 0.0,
                }
            ],
            "llm_response": state.get("llm_response"),
            "parsed_tool_calls": state.get("parsed_tool_calls", []),
        }
        return error_result


############################################################################################################
async def _llm_re_invoke_node(state: McpState) -> McpState:
    """
    äºŒæ¬¡æ¨ç†èŠ‚ç‚¹ï¼šåŸºäºå·¥å…·æ‰§è¡Œç»“æœé‡æ–°è°ƒç”¨LLMè¿›è¡Œæ™ºèƒ½åˆ†æ

    è¿™æ˜¯æ–°æ¶æ„çš„æ ¸å¿ƒèŠ‚ç‚¹ï¼Œè§£å†³äº†å·¥å…·ç»“æœåªæ˜¯ç®€å•æ‹¼æ¥çš„é—®é¢˜ã€‚
    è®©AIèƒ½å¤ŸåŸºäºå·¥å…·ç»“æœè¿›è¡Œæ·±åº¦åˆ†æå’Œä¸ªæ€§åŒ–å›ç­”ã€‚

    Args:
        state: å½“å‰çŠ¶æ€

    Returns:
        McpState: æ›´æ–°åçš„çŠ¶æ€
    """
    try:
        llm = state["llm"]
        tool_outputs = state.get("tool_outputs", [])
        original_messages = state.get("enhanced_messages", state["messages"])

        assert llm is not None, "LLM instance is None in state"

        if not tool_outputs:
            # æ²¡æœ‰å·¥å…·è¾“å‡ºï¼Œç›´æ¥ä½¿ç”¨åŸå§‹LLMå“åº”
            original_response = state.get("llm_response")
            if original_response:
                no_tool_result: McpState = {
                    "messages": [original_response],
                    "llm": llm,
                    "mcp_client": state.get("mcp_client"),
                    "available_tools": state.get("available_tools", []),
                    "tool_outputs": [],
                    "final_response": original_response,  # æ ‡è®°ä¸ºæœ€ç»ˆå“åº”
                }
                return no_tool_result

        # æ„å»ºåŒ…å«å·¥å…·ç»“æœçš„ä¸Šä¸‹æ–‡æ¶ˆæ¯
        tool_context_parts = []

        for i, output in enumerate(tool_outputs, 1):
            tool_name = output.get("tool", "æœªçŸ¥å·¥å…·")
            success = output.get("success", False)
            result_data = output.get("result", "æ— ç»“æœ")
            exec_time = output.get("execution_time", 0.0)

            status = "æˆåŠŸ" if success else "å¤±è´¥"
            tool_context_parts.append(
                f"å·¥å…·{i}: {tool_name} (æ‰§è¡Œ{status}, è€—æ—¶{exec_time:.2f}s)\n"
                f"ç»“æœ: {result_data}"
            )

        tool_context = "\n\n".join(tool_context_parts)

        # æ„å»ºäºŒæ¬¡æ¨ç†çš„æç¤ºï¼ˆçµæ´»å¤„ç†ï¼Œä¸å¼ºåˆ¶ç¦æ­¢ç”¨æˆ·è¦æ±‚çš„æ ¼å¼ï¼‰
        tool_analysis_prompt = f"""
å·¥å…·å·²ç»æ‰§è¡Œå®Œæ¯•ï¼Œè¯·ç›´æ¥åŸºäºä»¥ä¸‹ç»“æœå›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼š

{tool_context}

## é‡è¦çº¦æŸ
âŒ ä¸è¦å†æ¬¡è°ƒç”¨å·¥å…·ï¼æ‰€æœ‰å·¥å…·å·²æ‰§è¡Œå®Œæˆï¼
âŒ ä¸è¦ç”Ÿæˆå·¥å…·è°ƒç”¨æ ¼å¼çš„JSONï¼ˆå³ {{"tool_call": {{"name": "...", "arguments": {{...}}}}}}ï¼‰
âœ… ç›´æ¥åŸºäºå·¥å…·ç»“æœå›ç­”ç”¨æˆ·çš„é—®é¢˜
âœ… ä¸¥æ ¼éµå®ˆç”¨æˆ·åœ¨é—®é¢˜ä¸­æå‡ºçš„æ‰€æœ‰è¦æ±‚ï¼ˆåŒ…æ‹¬æ ¼å¼ã€è¯­æ°”ã€ç»“æ„ç­‰ï¼‰
âœ… ä¿æŒä½ çš„è§’è‰²è®¾å®šå’Œè¯­è¨€é£æ ¼
âœ… å¦‚æœç”¨æˆ·è¦æ±‚ç‰¹å®šçš„è¾“å‡ºæ ¼å¼ï¼ˆå¦‚JSONã€Markdownç­‰ï¼‰ï¼Œè¯·ä¸¥æ ¼æŒ‰ç…§ç”¨æˆ·è¦æ±‚è¾“å‡º

ç°åœ¨è¯·ç›´æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚
"""

        # åˆ›å»ºäºŒæ¬¡æ¨ç†çš„æ¶ˆæ¯åˆ—è¡¨ï¼Œä¿æŒåŸæœ‰çš„è§’è‰²è®¾å®š
        re_invoke_messages: List[BaseMessage] = []

        # ä»åŸå§‹æ¶ˆæ¯ä¸­æå–å·²æœ‰çš„è§’è‰²è®¾å®š
        for msg in original_messages:
            if isinstance(msg, SystemMessage):
                # ä¿æŒåŸæœ‰çš„è§’è‰²è®¾å®š
                re_invoke_messages.append(msg)

        # åœ¨è§’è‰²è®¾å®šåæ’å…¥å·¥å…·åˆ†ææç¤º
        re_invoke_messages.append(SystemMessage(content=tool_analysis_prompt))

        # æ·»åŠ ç”¨æˆ·çš„é—®é¢˜
        for msg in original_messages:
            if isinstance(msg, HumanMessage):
                re_invoke_messages.append(msg)

        # äºŒæ¬¡è°ƒç”¨ LLM
        logger.info("ğŸ”„ å¼€å§‹äºŒæ¬¡æ¨ç†ï¼ŒåŸºäºå·¥å…·ç»“æœç”Ÿæˆæ™ºèƒ½å›ç­”...")
        re_invoke_response = llm.invoke(re_invoke_messages)

        logger.info("âœ… äºŒæ¬¡æ¨ç†å®Œæˆ")

        re_invoke_result: McpState = {
            "messages": [re_invoke_response],
            "llm": llm,
            "mcp_client": state.get("mcp_client"),
            "available_tools": state.get("available_tools", []),
            "tool_outputs": tool_outputs,
            "final_response": re_invoke_response,  # æ ‡è®°ä¸ºæœ€ç»ˆå“åº”
        }
        return re_invoke_result

    except Exception as e:
        logger.error(f"äºŒæ¬¡æ¨ç†èŠ‚ç‚¹é”™è¯¯: {e}")
        # é™çº§å¤„ç†ï¼šä½¿ç”¨åŸå§‹å“åº”åˆæˆ
        original_response = state.get("llm_response")
        if original_response and state.get("tool_outputs"):
            from ..mcp.response import synthesize_response_with_tools

            synthesized_content = synthesize_response_with_tools(
                str(original_response.content) if original_response.content else "",
                state.get("tool_outputs", []),
                state.get("parsed_tool_calls", []),
            )
            original_response.content = synthesized_content

        error_fallback_response = original_response or AIMessage(
            content=f"æŠ±æ­‰ï¼ŒäºŒæ¬¡æ¨ç†æ—¶å‘ç”Ÿé”™è¯¯ï¼š{str(e)}"
        )

        error_result: McpState = {
            "messages": [error_fallback_response],
            "llm": state["llm"],
            "mcp_client": state.get("mcp_client"),
            "available_tools": state.get("available_tools", []),
            "tool_outputs": state.get("tool_outputs", []),
        }
        return error_result


############################################################################################################
async def _response_synthesis_node(state: McpState) -> McpState:
    """
    å“åº”åˆæˆèŠ‚ç‚¹ï¼šå¤„ç†æœ€ç»ˆå“åº”è¾“å‡º

    åœ¨æ–°æ¶æ„ä¸­ï¼Œè¿™ä¸ªèŠ‚ç‚¹ä¸»è¦è´Ÿè´£ï¼š
    1. å¯¹äºæœ‰å·¥å…·æ‰§è¡Œçš„æƒ…å†µï¼Œæ¥æ”¶äºŒæ¬¡æ¨ç†çš„ç»“æœ
    2. å¯¹äºæ— å·¥å…·æ‰§è¡Œçš„æƒ…å†µï¼Œç›´æ¥ä½¿ç”¨åŸå§‹LLMå“åº”
    3. ç¡®ä¿æœ€ç»ˆå“åº”çš„æ ¼å¼æ­£ç¡®

    Args:
        state: å½“å‰çŠ¶æ€

    Returns:
        McpState: æ›´æ–°åçš„çŠ¶æ€
    """
    try:
        # æ£€æŸ¥æ˜¯å¦æœ‰æ¥è‡ªäºŒæ¬¡æ¨ç†çš„æœ€ç»ˆå“åº”
        final_response = state.get("final_response")
        if final_response:
            # æœ‰äºŒæ¬¡æ¨ç†ç»“æœï¼Œç›´æ¥ä½¿ç”¨
            final_result: McpState = {
                "messages": [final_response],
                "llm": state["llm"],
                "mcp_client": state.get("mcp_client"),
                "available_tools": state.get("available_tools", []),
                "tool_outputs": state.get("tool_outputs", []),
            }
            return final_result

        # æ²¡æœ‰äºŒæ¬¡æ¨ç†ç»“æœï¼Œä½¿ç”¨åŸå§‹LLMå“åº”
        llm_response = state.get("llm_response")
        tool_outputs = state.get("tool_outputs", [])
        parsed_tool_calls = state.get("parsed_tool_calls", [])

        if not llm_response:
            error_message = AIMessage(content="æŠ±æ­‰ï¼Œæ²¡æœ‰æ”¶åˆ°LLMå“åº”ã€‚")
            synthesis_error_result: McpState = {
                "messages": [error_message],
                "llm": state["llm"],
                "mcp_client": state.get("mcp_client"),
                "available_tools": state.get("available_tools", []),
                "tool_outputs": tool_outputs,
            }
            return synthesis_error_result

        response_content = str(llm_response.content) if llm_response.content else ""

        # å¦‚æœæœ‰å·¥å…·è¢«æ‰§è¡Œä½†æ²¡æœ‰äºŒæ¬¡æ¨ç†ç»“æœï¼Œä½¿ç”¨é™çº§å¤„ç†
        if tool_outputs:
            logger.warning("âš ï¸ å‘ç°å·¥å…·è¾“å‡ºä½†æ²¡æœ‰äºŒæ¬¡æ¨ç†ç»“æœï¼Œä½¿ç”¨é™çº§å¤„ç†")
            from ..mcp.response import synthesize_response_with_tools

            synthesized_content = synthesize_response_with_tools(
                response_content, tool_outputs, parsed_tool_calls
            )
            llm_response.content = synthesized_content

        synthesis_result: McpState = {
            "messages": [llm_response],
            "llm": state["llm"],
            "mcp_client": state.get("mcp_client"),
            "available_tools": state.get("available_tools", []),
            "tool_outputs": tool_outputs,
        }
        return synthesis_result

    except Exception as e:
        logger.error(f"å“åº”åˆæˆèŠ‚ç‚¹é”™è¯¯: {e}")
        error_message = AIMessage(content=f"æŠ±æ­‰ï¼Œåˆæˆå“åº”æ—¶å‘ç”Ÿé”™è¯¯ï¼š{str(e)}")
        synthesis_exception_result: McpState = {
            "messages": [error_message],
            "llm": state["llm"],
            "mcp_client": state.get("mcp_client"),
            "available_tools": state.get("available_tools", []),
            "tool_outputs": [],
        }
        return synthesis_exception_result


############################################################################################################
def _should_execute_tools(state: McpState) -> str:
    """
    æ¡ä»¶è·¯ç”±ï¼šåˆ¤æ–­æ˜¯å¦éœ€è¦æ‰§è¡Œå·¥å…·

    Args:
        state: å½“å‰çŠ¶æ€

    Returns:
        str: ä¸‹ä¸€ä¸ªèŠ‚ç‚¹åç§°
    """
    needs_tool_execution = state.get("needs_tool_execution", False)
    return "tool_execution" if needs_tool_execution else "response_synthesis"


############################################################################################################
async def _preprocess_wrapper(state: McpState) -> McpState:
    """
    é¢„å¤„ç†åŒ…è£…å™¨ï¼Œç¡®ä¿çŠ¶æ€åŒ…å«å¿…è¦ä¿¡æ¯

    Args:
        state: å½“å‰çŠ¶æ€

    Returns:
        McpState: æ›´æ–°åçš„çŠ¶æ€
    """
    # ç¡®ä¿çŠ¶æ€åŒ…å«å¿…è¦ä¿¡æ¯ï¼ŒåŒ…æ‹¬LLMå®ä¾‹
    state_with_context: McpState = {
        "messages": state.get("messages", []),
        "llm": state.get("llm", None),  # ç¡®ä¿LLMå®ä¾‹å­˜åœ¨
        "mcp_client": state.get("mcp_client", None),
        "available_tools": state.get("available_tools", []),
        "tool_outputs": state.get("tool_outputs", []),
    }
    return await _preprocess_node(state_with_context)


############################################################################################################
async def _error_fallback_wrapper(state: McpState) -> McpState:
    """
    é”™è¯¯å¤„ç†åŒ…è£…å™¨ï¼Œç¡®ä¿æ€»èƒ½è¿”å›æœ‰æ•ˆå“åº”

    Args:
        state: å½“å‰çŠ¶æ€

    Returns:
        McpState: æ›´æ–°åçš„çŠ¶æ€
    """
    try:
        # å¦‚æœä¹‹å‰çš„èŠ‚ç‚¹éƒ½å¤±è´¥äº†ï¼Œæä¾›ä¸€ä¸ªåŸºæœ¬çš„é”™è¯¯å“åº”
        if not state.get("messages"):
            error_message = AIMessage(content="æŠ±æ­‰ï¼Œå¤„ç†è¯·æ±‚æ—¶å‘ç”Ÿé”™è¯¯ã€‚")
            fallback_result: McpState = {
                "messages": [error_message],
                "llm": state.get("llm", None),  # ç¡®ä¿LLMå®ä¾‹å­˜åœ¨
                "mcp_client": state.get("mcp_client", None),
                "available_tools": state.get("available_tools", []),
                "tool_outputs": [],
            }
            return fallback_result
        return state
    except Exception as e:
        logger.error(f"é”™è¯¯å¤„ç†åŒ…è£…å™¨å¤±è´¥: {e}")
        error_message = AIMessage(content="æŠ±æ­‰ï¼Œç³»ç»Ÿå‘ç”ŸæœªçŸ¥é”™è¯¯ã€‚")
        fallback_exception_result: McpState = {
            "messages": [error_message],
            "llm": state.get("llm", None),  # ç¡®ä¿LLMå®ä¾‹å­˜åœ¨
            "mcp_client": state.get("mcp_client", None),
            "available_tools": state.get("available_tools", []),
            "tool_outputs": [],
        }
        return fallback_exception_result


############################################################################################################
async def create_mcp_workflow() -> (
    CompiledStateGraph[McpState, Any, McpState, McpState]
):
    """
    åˆ›å»ºå¸¦ MCP æ”¯æŒçš„ç¼–è¯‘çŠ¶æ€å›¾ï¼ˆå¤šèŠ‚ç‚¹æ¶æ„ï¼‰

    Args:
        workflow_name: å·¥ä½œæµåç§°æ ‡è¯†
        mcp_client: MCPå®¢æˆ·ç«¯å®ä¾‹

    Returns:
        CompiledStateGraph: ç¼–è¯‘åçš„çŠ¶æ€å›¾
    """

    # æ„å»ºå¤šèŠ‚ç‚¹çŠ¶æ€å›¾
    graph_builder = StateGraph(McpState)

    # æ·»åŠ å„ä¸ªèŠ‚ç‚¹
    graph_builder.add_node("preprocess", _preprocess_wrapper)
    graph_builder.add_node("llm_invoke", _llm_invoke_node)
    graph_builder.add_node("tool_parse", _tool_parse_node)
    graph_builder.add_node("tool_execution", _tool_execution_node)
    graph_builder.add_node("llm_re_invoke", _llm_re_invoke_node)  # æ–°å¢äºŒæ¬¡æ¨ç†èŠ‚ç‚¹
    graph_builder.add_node("response_synthesis", _response_synthesis_node)
    graph_builder.add_node("error_fallback", _error_fallback_wrapper)

    # è®¾ç½®æµç¨‹è·¯å¾„
    graph_builder.set_entry_point("preprocess")
    graph_builder.add_edge("preprocess", "llm_invoke")
    graph_builder.add_edge("llm_invoke", "tool_parse")

    # æ·»åŠ æ¡ä»¶è·¯ç”±ï¼šå·¥å…·è§£æååˆ¤æ–­æ˜¯å¦éœ€è¦æ‰§è¡Œå·¥å…·
    graph_builder.add_conditional_edges(
        "tool_parse",
        _should_execute_tools,
        {
            "tool_execution": "tool_execution",
            "response_synthesis": "response_synthesis",
        },
    )

    # æ–°æ¶æ„ï¼šå·¥å…·æ‰§è¡Œåè¿›å…¥äºŒæ¬¡æ¨ç†
    graph_builder.add_edge("tool_execution", "llm_re_invoke")

    # äºŒæ¬¡æ¨ç†åç›´æ¥åˆ°å“åº”åˆæˆ
    graph_builder.add_edge("llm_re_invoke", "response_synthesis")

    graph_builder.set_finish_point("response_synthesis")

    return graph_builder.compile()  # type: ignore[return-value]


############################################################################################################
async def execute_mcp_workflow(
    state_compiled_graph: CompiledStateGraph[McpState, Any, McpState, McpState],
    chat_history_state: McpState,
    user_input_state: McpState,
) -> List[BaseMessage]:
    """
    æµå¼å¤„ç† MCP å›¾æ›´æ–°

    Args:
        state_compiled_graph: ç¼–è¯‘åçš„çŠ¶æ€å›¾
        chat_history_state: èŠå¤©å†å²çŠ¶æ€
        user_input_state: ç”¨æˆ·è¾“å…¥çŠ¶æ€

    Returns:
        List[BaseMessage]: å“åº”æ¶ˆæ¯åˆ—è¡¨
    """
    ret: List[BaseMessage] = []

    # åˆå¹¶çŠ¶æ€ï¼Œä¿æŒ MCP ç›¸å…³ä¿¡æ¯
    llm_instance = user_input_state.get("llm") or chat_history_state.get("llm")
    assert (
        llm_instance is not None
    ), "LLM instance is required in either chat history or user input state"
    if not llm_instance:
        logger.error("LLM å®ä¾‹ç¼ºå¤±ï¼Œæ— æ³•å¤„ç†è¯·æ±‚")
        return []
        # å¦‚æœä¸¤ä¸ªçŠ¶æ€éƒ½æ²¡æœ‰LLMå®ä¾‹ï¼Œåˆ›å»ºä¸€ä¸ªæ–°çš„
        # llm_instance = create_deepseek_llm()

    merged_message_context: McpState = {
        "messages": chat_history_state["messages"] + user_input_state["messages"],
        "llm": llm_instance,  # ç¡®ä¿LLMå®ä¾‹å­˜åœ¨
        "mcp_client": user_input_state.get(
            "mcp_client", chat_history_state.get("mcp_client")
        ),
        "available_tools": user_input_state.get(
            "available_tools", chat_history_state.get("available_tools", [])
        ),
        "tool_outputs": chat_history_state.get("tool_outputs", []),
    }

    try:
        final_messages = []
        async for event in state_compiled_graph.astream(merged_message_context):
            for node_name, value in event.items():
                # åªæ”¶é›†æ¥è‡ªæœ€ç»ˆèŠ‚ç‚¹çš„æ¶ˆæ¯ï¼Œé¿å…é‡å¤
                if node_name == "response_synthesis" and value.get("messages"):
                    final_messages = value["messages"]
                # è®°å½•å·¥å…·æ‰§è¡Œä¿¡æ¯ï¼ˆç”¨äºè°ƒè¯•ï¼‰
                if value.get("tool_outputs"):
                    logger.debug(f"å·¥å…·æ‰§è¡Œè®°å½•: {value['tool_outputs']}")

        # è¿”å›æœ€ç»ˆæ¶ˆæ¯
        ret.extend(final_messages)
    except Exception as e:
        logger.error(f"Stream processing error: {e}")
        error_message = AIMessage(content="æŠ±æ­‰ï¼Œå¤„ç†æ¶ˆæ¯æ—¶å‘ç”Ÿé”™è¯¯ã€‚")
        ret.append(error_message)

    return ret


############################################################################################################
