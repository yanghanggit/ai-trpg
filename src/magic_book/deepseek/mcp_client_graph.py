"""
DeepSeek MCP å®¢æˆ·ç«¯å›¾æ¶æ„ - äºŒæ¬¡æ¨ç†å¢å¼ºç‰ˆ

æ–°æ¶æ„æµç¨‹è¯´æ˜ï¼š
=================

1. é¢„å¤„ç†èŠ‚ç‚¹ (preprocess)
   - æ„å»ºç³»ç»Ÿæç¤ºï¼ŒåŒ…å«å·¥å…·ä½¿ç”¨è¯´æ˜
   - å‡†å¤‡å¢å¼ºæ¶ˆæ¯ä¾› LLM ä½¿ç”¨

2. é¦–æ¬¡LLMè°ƒç”¨ (llm_invoke)
   - è°ƒç”¨ DeepSeek ç”Ÿæˆåˆå§‹å“åº”
   - å¯èƒ½åŒ…å«å·¥å…·è°ƒç”¨æŒ‡ä»¤

3. å·¥å…·è§£æèŠ‚ç‚¹ (tool_parse)
   - è§£æ LLM å“åº”ä¸­çš„å·¥å…·è°ƒç”¨
   - åˆ¤æ–­æ˜¯å¦éœ€è¦æ‰§è¡Œå·¥å…·

4. æ¡ä»¶åˆ†æ”¯ï¼š
   - å¦‚æœéœ€è¦å·¥å…·æ‰§è¡Œ â†’ tool_execution
   - å¦‚æœä¸éœ€è¦å·¥å…· â†’ response_synthesis

5. å·¥å…·æ‰§è¡ŒèŠ‚ç‚¹ (tool_execution)
   - å¹¶å‘æ‰§è¡Œæ‰€æœ‰è§£æå‡ºçš„å·¥å…·è°ƒç”¨
   - æ”¶é›†å·¥å…·æ‰§è¡Œç»“æœ

6. **äºŒæ¬¡æ¨ç†èŠ‚ç‚¹ (llm_re_invoke) [æ–°å¢]**
   - å°†å·¥å…·ç»“æœä½œä¸ºä¸Šä¸‹æ–‡ï¼Œå†æ¬¡è°ƒç”¨ LLM
   - è®© AI åŸºäºå·¥å…·ç»“æœè¿›è¡Œæ™ºèƒ½åˆ†æå’Œå›ç­”
   - ä¿æŒè§’è‰²è®¾å®šï¼ˆå¦‚æµ·ç›—è¯­æ°”ç­‰ï¼‰

7. å“åº”åˆæˆèŠ‚ç‚¹ (response_synthesis)
   - å¤„ç†æœ€ç»ˆå“åº”
   - å¯¹äºæœ‰å·¥å…·çš„æƒ…å†µï¼Œä½¿ç”¨äºŒæ¬¡æ¨ç†ç»“æœ
   - å¯¹äºæ— å·¥å…·çš„æƒ…å†µï¼Œä½¿ç”¨åŸå§‹ LLM å“åº”

æ¶æ„ä¼˜åŠ¿ï¼š
=========
- çœŸæ­£çš„æ™ºèƒ½å·¥å…·ç»“æœå¤„ç†ï¼Œè€Œéç®€å•æ‹¼æ¥
- ä¿æŒAIè§’è‰²è®¾å®šå’Œå¯¹è¯é£æ ¼
- æ›´è‡ªç„¶çš„äººæœºäº¤äº’ä½“éªŒ
- æ”¯æŒå¤æ‚å·¥å…·ç»“æœçš„æ·±åº¦åˆ†æ

æµç¨‹å›¾ï¼š
=======
preprocess â†’ llm_invoke â†’ tool_parse â†’ [æ¡ä»¶åˆ¤æ–­]
                                          â†“ (éœ€è¦å·¥å…·)
                                    tool_execution â†’ llm_re_invoke â†’ response_synthesis
                                          â†“ (ä¸éœ€è¦å·¥å…·)
                                    response_synthesis
"""

from dotenv import load_dotenv
from loguru import logger

# åŠ è½½ .env æ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡
load_dotenv()

import asyncio
from typing import Annotated, Any, Dict, List, Optional

from langchain.schema import AIMessage, SystemMessage, HumanMessage
from langchain_core.messages import BaseMessage
from langchain_deepseek import ChatDeepSeek
from langgraph.graph import StateGraph
from langgraph.graph.message import add_messages
from langgraph.graph.state import CompiledStateGraph
from typing_extensions import TypedDict

# å¯¼å…¥ç»Ÿä¸€ MCP å®¢æˆ·ç«¯å’ŒåŠŸèƒ½
from ..mcp import (
    McpClient,
    McpToolInfo,
    ToolCallParser,
    execute_mcp_tool,
    build_json_tool_example,
    format_tool_description_simple,
)

# å¯¼å…¥ç»Ÿä¸€çš„ DeepSeek LLM å®¢æˆ·ç«¯
from .client import create_deepseek_llm


############################################################################################################
class McpState(TypedDict, total=False):
    """
    MCP å¢å¼ºçš„çŠ¶æ€ï¼ŒåŒ…å«æ¶ˆæ¯å’Œ MCP å®¢æˆ·ç«¯ç›¸å…³ä¿¡æ¯
    """

    messages: Annotated[List[BaseMessage], add_messages]
    llm: ChatDeepSeek  # DeepSeek LLMå®ä¾‹ï¼Œæ•´ä¸ªgraphæµç¨‹å…±äº«
    mcp_client: Optional[McpClient]  # MCP å®¢æˆ·ç«¯
    available_tools: List[McpToolInfo]  # å¯ç”¨çš„ MCP å·¥å…·
    tool_outputs: List[Dict[str, Any]]  # å·¥å…·æ‰§è¡Œç»“æœ

    # æ–°å¢å­—æ®µç”¨äºå¤šèŠ‚ç‚¹æµç¨‹
    system_prompt: Optional[str]  # ç³»ç»Ÿæç¤ºç¼“å­˜
    enhanced_messages: List[BaseMessage]  # åŒ…å«ç³»ç»Ÿæç¤ºçš„å¢å¼ºæ¶ˆæ¯
    llm_response: Optional[BaseMessage]  # LLMåŸå§‹å“åº”
    parsed_tool_calls: List[Dict[str, Any]]  # è§£æå‡ºçš„å·¥å…·è°ƒç”¨
    needs_tool_execution: bool  # æ˜¯å¦éœ€è¦æ‰§è¡Œå·¥å…·

    # äºŒæ¬¡æ¨ç†æ¶æ„æ–°å¢å­—æ®µ
    final_response: Optional[BaseMessage]  # æœ€ç»ˆå“åº”ï¼ˆæ¥è‡ªäºŒæ¬¡æ¨ç†æˆ–åŸå§‹å“åº”ï¼‰


############################################################################################################
def _build_system_prompt(available_tools: List[McpToolInfo]) -> str:
    """
    æ„å»ºç³»ç»Ÿæç¤ºï¼Œä»…æ”¯æŒJSONæ ¼å¼å·¥å…·è°ƒç”¨

    Args:
        available_tools: å¯ç”¨å·¥å…·åˆ—è¡¨

    Returns:
        str: æ„å»ºå¥½çš„ç³»ç»Ÿæç¤º
    """
    # å·¥å…·ä½¿ç”¨è¯´æ˜ï¼ˆä¸åŒ…å«è§’è‰²è®¾å®šï¼‰
    system_prompt = """å½“ä½ éœ€è¦è·å–å®æ—¶ä¿¡æ¯æˆ–æ‰§è¡Œç‰¹å®šæ“ä½œæ—¶ï¼Œå¯ä»¥è°ƒç”¨ç›¸åº”çš„å·¥å…·ã€‚

## å·¥å…·è°ƒç”¨æ ¼å¼

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è°ƒç”¨å·¥å…·ï¼š

```json
{
  "tool_call": {
    "name": "å·¥å…·åç§°",
    "arguments": {
      "å‚æ•°å": "å‚æ•°å€¼"
    }
  }
}
```

## ä½¿ç”¨æŒ‡å—

- ä½ å¯ä»¥åœ¨å›å¤ä¸­è‡ªç„¶åœ°è§£é‡Šä½ è¦åšä»€ä¹ˆ
- ç„¶ååœ¨å›å¤ä¸­åŒ…å«JSONæ ¼å¼çš„å·¥å…·è°ƒç”¨
- å·¥å…·æ‰§è¡Œå®Œæˆåï¼Œæ ¹æ®ç»“æœç»™å‡ºå®Œæ•´çš„å›ç­”
- å¦‚æœå·¥å…·æ‰§è¡Œå¤±è´¥ï¼Œè¯·ä¸ºç”¨æˆ·æä¾›æ›¿ä»£æ–¹æ¡ˆæˆ–è§£é‡ŠåŸå› """

    if not available_tools:
        system_prompt += "\n\nâš ï¸ å½“å‰æ²¡æœ‰å¯ç”¨å·¥å…·ï¼Œè¯·ä»…ä½¿ç”¨ä½ çš„çŸ¥è¯†å›ç­”é—®é¢˜ã€‚"
        return system_prompt

    # æ„å»ºå·¥å…·æè¿° - ç®€åŒ–ç‰ˆæœ¬ï¼Œç»Ÿä¸€ä½¿ç”¨çº¿æ€§å±•ç¤º
    system_prompt += "\n\n## å¯ç”¨å·¥å…·"

    # ç›´æ¥åˆ—è¡¨å±•ç¤ºæ‰€æœ‰å·¥å…·ï¼Œæ— éœ€åˆ†ç±»
    for tool in available_tools:
        tool_desc = format_tool_description_simple(tool)
        system_prompt += f"\n{tool_desc}"

    # æ·»åŠ å®é™…å·¥å…·çš„è°ƒç”¨ç¤ºä¾‹
    example_tool = available_tools[0]
    system_prompt += f"\n\n## è°ƒç”¨ç¤ºä¾‹\n\n"
    system_prompt += build_json_tool_example(example_tool)

    return system_prompt


############################################################################################################
async def _preprocess_node(state: McpState) -> McpState:
    """
    é¢„å¤„ç†èŠ‚ç‚¹ï¼šå‡†å¤‡ç³»ç»Ÿæç¤ºå’Œå¢å¼ºæ¶ˆæ¯

    Args:
        state: å½“å‰çŠ¶æ€

    Returns:
        McpState: æ›´æ–°åçš„çŠ¶æ€
    """
    try:
        messages = state["messages"]
        available_tools = state.get("available_tools", [])

        # æ„å»ºç³»ç»Ÿæç¤º
        system_prompt = _build_system_prompt(available_tools)

        # æ™ºèƒ½æ·»åŠ ç³»ç»Ÿæ¶ˆæ¯ï¼šå¦‚æœå·²æœ‰ç³»ç»Ÿæ¶ˆæ¯åˆ™è¿½åŠ ï¼Œå¦åˆ™æ’å…¥åˆ°å¼€å¤´
        enhanced_messages = messages.copy()
        if enhanced_messages and isinstance(enhanced_messages[0], SystemMessage):
            # å·²ç»æœ‰ç³»ç»Ÿæ¶ˆæ¯åœ¨å¼€å¤´ï¼Œè¿½åŠ æ–°çš„å·¥å…·è¯´æ˜
            enhanced_messages.insert(1, SystemMessage(content=system_prompt))
        else:
            # æ²¡æœ‰ç³»ç»Ÿæ¶ˆæ¯ï¼Œæ’å…¥é»˜è®¤è§’è‰²è®¾å®šå’Œå·¥å…·è¯´æ˜åˆ°å¼€å¤´
            default_role_prompt = (
                "ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œå…·æœ‰ä½¿ç”¨å·¥å…·çš„èƒ½åŠ›ã€‚\n\n" + system_prompt
            )
            enhanced_messages.insert(0, SystemMessage(content=default_role_prompt))

        result: McpState = {
            "messages": [],  # é¢„å¤„ç†èŠ‚ç‚¹ä¸è¿”å›æ¶ˆæ¯ï¼Œé¿å…é‡å¤ç´¯ç§¯
            "llm": state["llm"],  # ç›´æ¥ä½¿ç”¨çŠ¶æ€ä¸­çš„LLMå®ä¾‹
            "mcp_client": state.get("mcp_client"),
            "available_tools": available_tools,
            "tool_outputs": state.get("tool_outputs", []),
            "system_prompt": system_prompt,  # ä¿å­˜ç³»ç»Ÿæç¤ºä¾›åç»­ä½¿ç”¨
            "enhanced_messages": enhanced_messages,  # ä¿å­˜å¢å¼ºæ¶ˆæ¯ä¾›LLMä½¿ç”¨
        }
        return result

    except Exception as e:
        logger.error(f"é¢„å¤„ç†èŠ‚ç‚¹é”™è¯¯: {e}")
        return state


############################################################################################################
async def _llm_invoke_node(state: McpState) -> McpState:
    """
    LLMè°ƒç”¨èŠ‚ç‚¹ï¼šè°ƒç”¨DeepSeekç”Ÿæˆå“åº”

    Args:
        state: å½“å‰çŠ¶æ€

    Returns:
        McpState: æ›´æ–°åçš„çŠ¶æ€
    """
    try:
        # ä½¿ç”¨çŠ¶æ€ä¸­çš„ ChatDeepSeek å®ä¾‹
        llm = state["llm"]
        assert llm is not None, "LLM instance is None in state"

        # ä½¿ç”¨å¢å¼ºæ¶ˆæ¯ï¼ˆåŒ…å«ç³»ç»Ÿæç¤ºï¼‰è¿›è¡ŒLLMè°ƒç”¨
        enhanced_messages = state.get("enhanced_messages", state["messages"])

        # è°ƒç”¨ LLM
        response = llm.invoke(enhanced_messages)

        result: McpState = {
            "messages": [],  # LLMè°ƒç”¨èŠ‚ç‚¹ä¸è¿”å›æ¶ˆæ¯ï¼Œé¿å…é‡å¤ç´¯ç§¯
            "llm": llm,  # ä¼ é€’LLMå®ä¾‹
            "mcp_client": state.get("mcp_client"),
            "available_tools": state.get("available_tools", []),
            "tool_outputs": state.get("tool_outputs", []),
            "llm_response": response,  # ä¿å­˜LLMå“åº”ä¾›åç»­å¤„ç†
            "enhanced_messages": enhanced_messages,  # ä¼ é€’å¢å¼ºæ¶ˆæ¯
        }
        return result

    except Exception as e:
        logger.error(f"LLMè°ƒç”¨èŠ‚ç‚¹é”™è¯¯: {e}")
        error_message = AIMessage(content=f"æŠ±æ­‰ï¼Œå¤„ç†è¯·æ±‚æ—¶å‘ç”Ÿé”™è¯¯ï¼š{str(e)}")
        llm_error_result: McpState = {
            "messages": [error_message],  # åªè¿”å›é”™è¯¯æ¶ˆæ¯
            "llm": state["llm"],  # ä¿æŒLLMå®ä¾‹
            "mcp_client": state.get("mcp_client"),
            "available_tools": state.get("available_tools", []),
            "tool_outputs": [],
        }
        return llm_error_result


############################################################################################################
async def _tool_parse_node(state: McpState) -> McpState:
    """
    å·¥å…·è§£æèŠ‚ç‚¹ï¼šä½¿ç”¨å¢å¼ºè§£æå™¨è§£æLLMå“åº”ä¸­çš„å·¥å…·è°ƒç”¨

    Args:
        state: å½“å‰çŠ¶æ€

    Returns:
        McpState: æ›´æ–°åçš„çŠ¶æ€
    """
    try:
        llm_response = state.get("llm_response")
        available_tools = state.get("available_tools", [])

        parsed_tool_calls = []

        if llm_response and available_tools:
            response_content = str(llm_response.content) if llm_response.content else ""

            # ä½¿ç”¨å¢å¼ºçš„å·¥å…·è°ƒç”¨è§£æå™¨
            parser = ToolCallParser(available_tools)
            parsed_tool_calls = parser.parse_tool_calls(response_content)

            logger.info(f"ğŸ“‹ è§£æåˆ° {len(parsed_tool_calls)} ä¸ªå·¥å…·è°ƒç”¨")
            for call in parsed_tool_calls:
                logger.debug(f"   - {call['name']}: {call['args']}")

        result: McpState = {
            "messages": [],  # å·¥å…·è§£æèŠ‚ç‚¹ä¸è¿”å›æ¶ˆæ¯ï¼Œé¿å…é‡å¤ç´¯ç§¯
            "llm": state["llm"],  # ä¼ é€’LLMå®ä¾‹
            "mcp_client": state.get("mcp_client"),
            "available_tools": available_tools,
            "tool_outputs": state.get("tool_outputs", []),
            "llm_response": llm_response,
            "parsed_tool_calls": parsed_tool_calls,
            "needs_tool_execution": len(parsed_tool_calls) > 0,
        }
        return result

    except Exception as e:
        logger.error(f"å·¥å…·è§£æèŠ‚ç‚¹é”™è¯¯: {e}")
        # å‘ç”Ÿé”™è¯¯æ—¶ï¼Œç»§ç»­æµç¨‹ä½†ä¸æ‰§è¡Œå·¥å…·
        error_result: McpState = {
            "messages": [],
            "llm": state["llm"],  # ä¼ é€’LLMå®ä¾‹
            "mcp_client": state.get("mcp_client"),
            "available_tools": state.get("available_tools", []),
            "tool_outputs": state.get("tool_outputs", []),
            "llm_response": state.get("llm_response"),
            "parsed_tool_calls": [],
            "needs_tool_execution": False,
        }
        return error_result


############################################################################################################
async def _tool_execution_node(state: McpState) -> McpState:
    """
    å·¥å…·æ‰§è¡ŒèŠ‚ç‚¹ï¼šæ‰§è¡Œè§£æå‡ºçš„å·¥å…·è°ƒç”¨ï¼ˆå¢å¼ºç‰ˆï¼‰

    Args:
        state: å½“å‰çŠ¶æ€

    Returns:
        McpState: æ›´æ–°åçš„çŠ¶æ€
    """
    try:
        parsed_tool_calls = state.get("parsed_tool_calls", [])
        mcp_client = state.get("mcp_client")

        tool_outputs = []

        if parsed_tool_calls and mcp_client:
            logger.info(f"ğŸ”§ å¼€å§‹æ‰§è¡Œ {len(parsed_tool_calls)} ä¸ªå·¥å…·è°ƒç”¨")

            # ä½¿ç”¨ asyncio.gather() ç»Ÿä¸€å¤„ç†æ‰€æœ‰å·¥å…·è°ƒç”¨ï¼ˆçœŸæ­£å¹¶å‘æ‰§è¡Œï¼‰
            tasks = []
            for tool_call in parsed_tool_calls:
                task = execute_mcp_tool(
                    tool_call["name"],
                    tool_call["args"],
                    mcp_client,
                    timeout=30.0,
                    max_retries=2,  # ç»Ÿä¸€ä½¿ç”¨2æ¬¡é‡è¯•
                )
                tasks.append((tool_call, task))

            # çœŸæ­£å¹¶å‘æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
            try:
                execution_results = await asyncio.gather(
                    *[task for _, task in tasks], return_exceptions=True
                )

                for (tool_call, _), exec_result in zip(tasks, execution_results):
                    if isinstance(exec_result, Exception):
                        logger.error(
                            f"å·¥å…·æ‰§è¡Œä»»åŠ¡å¤±è´¥: {tool_call['name']}, é”™è¯¯: {exec_result}"
                        )
                        tool_outputs.append(
                            {
                                "tool": tool_call["name"],
                                "args": tool_call["args"],
                                "result": f"æ‰§è¡Œå¤±è´¥: {str(exec_result)}",
                                "success": False,
                                "execution_time": 0.0,
                            }
                        )
                    elif isinstance(exec_result, tuple) and len(exec_result) == 3:
                        success, task_result, exec_time = exec_result
                        tool_outputs.append(
                            {
                                "tool": tool_call["name"],
                                "args": tool_call["args"],
                                "result": task_result,
                                "success": success,
                                "execution_time": exec_time,
                            }
                        )
                    else:
                        # æ„å¤–çš„ç»“æœç±»å‹
                        logger.error(
                            f"å·¥å…·æ‰§è¡Œè¿”å›æ„å¤–ç»“æœç±»å‹: {tool_call['name']}, ç»“æœ: {exec_result}"
                        )
                        tool_outputs.append(
                            {
                                "tool": tool_call["name"],
                                "args": tool_call["args"],
                                "result": f"æ„å¤–ç»“æœç±»å‹: {type(exec_result)}",
                                "success": False,
                                "execution_time": 0.0,
                            }
                        )
            except Exception as e:
                logger.error(f"å¹¶å‘æ‰§è¡Œå·¥å…·å¤±è´¥: {e}")
                # é™çº§å¤„ç†ï¼šä¸ºæ‰€æœ‰å·¥å…·è°ƒç”¨è®°å½•é”™è¯¯
                for tool_call in parsed_tool_calls:
                    tool_outputs.append(
                        {
                            "tool": tool_call["name"],
                            "args": tool_call["args"],
                            "result": f"å¹¶å‘æ‰§è¡Œå¤±è´¥: {str(e)}",
                            "success": False,
                            "execution_time": 0.0,
                        }
                    )

            # ç»Ÿè®¡æ‰§è¡Œç»“æœ
            successful_calls = sum(1 for output in tool_outputs if output["success"])
            total_time = sum(output["execution_time"] for output in tool_outputs)

            logger.info(
                f"âœ… å·¥å…·æ‰§è¡Œå®Œæˆ: {successful_calls}/{len(tool_outputs)} æˆåŠŸ, "
                f"æ€»è€—æ—¶: {total_time:.2f}s"
            )

        final_result: McpState = {
            "messages": [],  # å·¥å…·æ‰§è¡ŒèŠ‚ç‚¹ä¸è¿”å›æ¶ˆæ¯ï¼Œé¿å…é‡å¤ç´¯ç§¯
            "llm": state["llm"],  # ä¼ é€’LLMå®ä¾‹
            "mcp_client": mcp_client,
            "available_tools": state.get("available_tools", []),
            "tool_outputs": tool_outputs,
            "llm_response": state.get("llm_response"),
            "parsed_tool_calls": parsed_tool_calls,
        }
        return final_result

    except Exception as e:
        logger.error(f"å·¥å…·æ‰§è¡ŒèŠ‚ç‚¹é”™è¯¯: {e}")
        # å³ä½¿æ‰§è¡Œå¤±è´¥ï¼Œä¹Ÿè¦è¿”å›çŠ¶æ€ä»¥ç»§ç»­æµç¨‹
        error_result: McpState = {
            "messages": [],
            "llm": state["llm"],  # ä¼ é€’LLMå®ä¾‹
            "mcp_client": state.get("mcp_client"),
            "available_tools": state.get("available_tools", []),
            "tool_outputs": [
                {
                    "tool": "ç³»ç»Ÿ",
                    "args": {},
                    "result": f"å·¥å…·æ‰§è¡ŒèŠ‚ç‚¹å‘ç”Ÿé”™è¯¯: {str(e)}",
                    "success": False,
                    "execution_time": 0.0,
                }
            ],
            "llm_response": state.get("llm_response"),
            "parsed_tool_calls": state.get("parsed_tool_calls", []),
        }
        return error_result


############################################################################################################
async def _llm_re_invoke_node(state: McpState) -> McpState:
    """
    äºŒæ¬¡æ¨ç†èŠ‚ç‚¹ï¼šåŸºäºå·¥å…·æ‰§è¡Œç»“æœé‡æ–°è°ƒç”¨LLMè¿›è¡Œæ™ºèƒ½åˆ†æ

    è¿™æ˜¯æ–°æ¶æ„çš„æ ¸å¿ƒèŠ‚ç‚¹ï¼Œè§£å†³äº†å·¥å…·ç»“æœåªæ˜¯ç®€å•æ‹¼æ¥çš„é—®é¢˜ã€‚
    è®©AIèƒ½å¤ŸåŸºäºå·¥å…·ç»“æœè¿›è¡Œæ·±åº¦åˆ†æå’Œä¸ªæ€§åŒ–å›ç­”ã€‚

    Args:
        state: å½“å‰çŠ¶æ€

    Returns:
        McpState: æ›´æ–°åçš„çŠ¶æ€
    """
    try:
        llm = state["llm"]
        tool_outputs = state.get("tool_outputs", [])
        original_messages = state.get("enhanced_messages", state["messages"])

        assert llm is not None, "LLM instance is None in state"

        if not tool_outputs:
            # æ²¡æœ‰å·¥å…·è¾“å‡ºï¼Œç›´æ¥ä½¿ç”¨åŸå§‹LLMå“åº”
            original_response = state.get("llm_response")
            if original_response:
                no_tool_result: McpState = {
                    "messages": [original_response],
                    "llm": llm,
                    "mcp_client": state.get("mcp_client"),
                    "available_tools": state.get("available_tools", []),
                    "tool_outputs": [],
                    "final_response": original_response,  # æ ‡è®°ä¸ºæœ€ç»ˆå“åº”
                }
                return no_tool_result

        # æ„å»ºåŒ…å«å·¥å…·ç»“æœçš„ä¸Šä¸‹æ–‡æ¶ˆæ¯
        tool_context_parts = []

        for i, output in enumerate(tool_outputs, 1):
            tool_name = output.get("tool", "æœªçŸ¥å·¥å…·")
            success = output.get("success", False)
            result_data = output.get("result", "æ— ç»“æœ")
            exec_time = output.get("execution_time", 0.0)

            status = "æˆåŠŸ" if success else "å¤±è´¥"
            tool_context_parts.append(
                f"å·¥å…·{i}: {tool_name} (æ‰§è¡Œ{status}, è€—æ—¶{exec_time:.2f}s)\n"
                f"ç»“æœ: {result_data}"
            )

        tool_context = "\n\n".join(tool_context_parts)

        # æ„å»ºäºŒæ¬¡æ¨ç†çš„æç¤ºï¼ˆä¸åŒ…å«è§’è‰²è®¾å®šï¼Œåªä¸“æ³¨å·¥å…·ç»“æœåˆ†æï¼‰
        tool_analysis_prompt = f"""
å·¥å…·å·²ç»æ‰§è¡Œå®Œæ¯•ï¼Œè¯·ç›´æ¥åŸºäºä»¥ä¸‹ç»“æœå›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼š

{tool_context}

âŒ é‡è¦ï¼šä¸è¦å†è°ƒç”¨ä»»ä½•å·¥å…·ï¼å·¥å…·æ‰§è¡Œå·²å®Œæˆï¼
âŒ ä¸è¦è¾“å‡ºä»»ä½•JSONæ ¼å¼çš„å†…å®¹ï¼
âœ… è¯·ç›´æ¥ç”¨è‡ªç„¶è¯­è¨€å›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼
âœ… æ ¹æ®å·¥å…·æä¾›çš„ä¿¡æ¯è¿›è¡Œåˆ†æå’Œæ€»ç»“ï¼
âœ… ä¿æŒä½ çš„è§’è‰²è®¾å®šå’Œè¯­è¨€é£æ ¼ï¼

ç°åœ¨è¯·ç›´æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚
"""

        # åˆ›å»ºäºŒæ¬¡æ¨ç†çš„æ¶ˆæ¯åˆ—è¡¨ï¼Œä¿æŒåŸæœ‰çš„è§’è‰²è®¾å®š
        re_invoke_messages: List[BaseMessage] = []

        # ä»åŸå§‹æ¶ˆæ¯ä¸­æå–å·²æœ‰çš„è§’è‰²è®¾å®š
        for msg in original_messages:
            if isinstance(msg, SystemMessage):
                # ä¿æŒåŸæœ‰çš„è§’è‰²è®¾å®š
                re_invoke_messages.append(msg)

        # åœ¨è§’è‰²è®¾å®šåæ’å…¥å·¥å…·åˆ†ææç¤º
        re_invoke_messages.append(SystemMessage(content=tool_analysis_prompt))

        # æ·»åŠ ç”¨æˆ·çš„é—®é¢˜
        for msg in original_messages:
            if isinstance(msg, HumanMessage):
                re_invoke_messages.append(msg)

        # äºŒæ¬¡è°ƒç”¨ LLM
        logger.info("ğŸ”„ å¼€å§‹äºŒæ¬¡æ¨ç†ï¼ŒåŸºäºå·¥å…·ç»“æœç”Ÿæˆæ™ºèƒ½å›ç­”...")
        re_invoke_response = llm.invoke(re_invoke_messages)

        logger.info("âœ… äºŒæ¬¡æ¨ç†å®Œæˆ")

        re_invoke_result: McpState = {
            "messages": [re_invoke_response],
            "llm": llm,
            "mcp_client": state.get("mcp_client"),
            "available_tools": state.get("available_tools", []),
            "tool_outputs": tool_outputs,
            "final_response": re_invoke_response,  # æ ‡è®°ä¸ºæœ€ç»ˆå“åº”
        }
        return re_invoke_result

    except Exception as e:
        logger.error(f"äºŒæ¬¡æ¨ç†èŠ‚ç‚¹é”™è¯¯: {e}")
        # é™çº§å¤„ç†ï¼šä½¿ç”¨åŸå§‹å“åº”åˆæˆ
        original_response = state.get("llm_response")
        if original_response and state.get("tool_outputs"):
            from ..mcp.response import synthesize_response_with_tools

            synthesized_content = synthesize_response_with_tools(
                str(original_response.content) if original_response.content else "",
                state.get("tool_outputs", []),
                state.get("parsed_tool_calls", []),
            )
            original_response.content = synthesized_content

        error_fallback_response = original_response or AIMessage(
            content=f"æŠ±æ­‰ï¼ŒäºŒæ¬¡æ¨ç†æ—¶å‘ç”Ÿé”™è¯¯ï¼š{str(e)}"
        )

        error_result: McpState = {
            "messages": [error_fallback_response],
            "llm": state["llm"],
            "mcp_client": state.get("mcp_client"),
            "available_tools": state.get("available_tools", []),
            "tool_outputs": state.get("tool_outputs", []),
        }
        return error_result


############################################################################################################
async def _response_synthesis_node(state: McpState) -> McpState:
    """
    å“åº”åˆæˆèŠ‚ç‚¹ï¼šå¤„ç†æœ€ç»ˆå“åº”è¾“å‡º

    åœ¨æ–°æ¶æ„ä¸­ï¼Œè¿™ä¸ªèŠ‚ç‚¹ä¸»è¦è´Ÿè´£ï¼š
    1. å¯¹äºæœ‰å·¥å…·æ‰§è¡Œçš„æƒ…å†µï¼Œæ¥æ”¶äºŒæ¬¡æ¨ç†çš„ç»“æœ
    2. å¯¹äºæ— å·¥å…·æ‰§è¡Œçš„æƒ…å†µï¼Œç›´æ¥ä½¿ç”¨åŸå§‹LLMå“åº”
    3. ç¡®ä¿æœ€ç»ˆå“åº”çš„æ ¼å¼æ­£ç¡®

    Args:
        state: å½“å‰çŠ¶æ€

    Returns:
        McpState: æ›´æ–°åçš„çŠ¶æ€
    """
    try:
        # æ£€æŸ¥æ˜¯å¦æœ‰æ¥è‡ªäºŒæ¬¡æ¨ç†çš„æœ€ç»ˆå“åº”
        final_response = state.get("final_response")
        if final_response:
            # æœ‰äºŒæ¬¡æ¨ç†ç»“æœï¼Œç›´æ¥ä½¿ç”¨
            final_result: McpState = {
                "messages": [final_response],
                "llm": state["llm"],
                "mcp_client": state.get("mcp_client"),
                "available_tools": state.get("available_tools", []),
                "tool_outputs": state.get("tool_outputs", []),
            }
            return final_result

        # æ²¡æœ‰äºŒæ¬¡æ¨ç†ç»“æœï¼Œä½¿ç”¨åŸå§‹LLMå“åº”
        llm_response = state.get("llm_response")
        tool_outputs = state.get("tool_outputs", [])
        parsed_tool_calls = state.get("parsed_tool_calls", [])

        if not llm_response:
            error_message = AIMessage(content="æŠ±æ­‰ï¼Œæ²¡æœ‰æ”¶åˆ°LLMå“åº”ã€‚")
            synthesis_error_result: McpState = {
                "messages": [error_message],
                "llm": state["llm"],
                "mcp_client": state.get("mcp_client"),
                "available_tools": state.get("available_tools", []),
                "tool_outputs": tool_outputs,
            }
            return synthesis_error_result

        response_content = str(llm_response.content) if llm_response.content else ""

        # å¦‚æœæœ‰å·¥å…·è¢«æ‰§è¡Œä½†æ²¡æœ‰äºŒæ¬¡æ¨ç†ç»“æœï¼Œä½¿ç”¨é™çº§å¤„ç†
        if tool_outputs:
            logger.warning("âš ï¸ å‘ç°å·¥å…·è¾“å‡ºä½†æ²¡æœ‰äºŒæ¬¡æ¨ç†ç»“æœï¼Œä½¿ç”¨é™çº§å¤„ç†")
            from ..mcp.response import synthesize_response_with_tools

            synthesized_content = synthesize_response_with_tools(
                response_content, tool_outputs, parsed_tool_calls
            )
            llm_response.content = synthesized_content

        synthesis_result: McpState = {
            "messages": [llm_response],
            "llm": state["llm"],
            "mcp_client": state.get("mcp_client"),
            "available_tools": state.get("available_tools", []),
            "tool_outputs": tool_outputs,
        }
        return synthesis_result

    except Exception as e:
        logger.error(f"å“åº”åˆæˆèŠ‚ç‚¹é”™è¯¯: {e}")
        error_message = AIMessage(content=f"æŠ±æ­‰ï¼Œåˆæˆå“åº”æ—¶å‘ç”Ÿé”™è¯¯ï¼š{str(e)}")
        synthesis_exception_result: McpState = {
            "messages": [error_message],
            "llm": state["llm"],
            "mcp_client": state.get("mcp_client"),
            "available_tools": state.get("available_tools", []),
            "tool_outputs": [],
        }
        return synthesis_exception_result


############################################################################################################
def _should_execute_tools(state: McpState) -> str:
    """
    æ¡ä»¶è·¯ç”±ï¼šåˆ¤æ–­æ˜¯å¦éœ€è¦æ‰§è¡Œå·¥å…·

    Args:
        state: å½“å‰çŠ¶æ€

    Returns:
        str: ä¸‹ä¸€ä¸ªèŠ‚ç‚¹åç§°
    """
    needs_tool_execution = state.get("needs_tool_execution", False)
    return "tool_execution" if needs_tool_execution else "response_synthesis"


############################################################################################################
def _should_re_invoke_llm(state: McpState) -> str:
    """
    æ¡ä»¶è·¯ç”±ï¼šåˆ¤æ–­æ˜¯å¦éœ€è¦äºŒæ¬¡æ¨ç†

    - å¦‚æœæœ‰å·¥å…·è¾“å‡ºï¼Œéœ€è¦è¿›è¡ŒäºŒæ¬¡æ¨ç†
    - å¦‚æœæ²¡æœ‰å·¥å…·è¾“å‡ºï¼Œç›´æ¥è¿›è¡Œå“åº”åˆæˆ

    Args:
        state: å½“å‰çŠ¶æ€

    Returns:
        str: ä¸‹ä¸€ä¸ªèŠ‚ç‚¹åç§°
    """
    tool_outputs = state.get("tool_outputs", [])
    return "llm_re_invoke" if tool_outputs else "response_synthesis"


############################################################################################################
async def create_compiled_mcp_stage_graph(
    node_name: str,
    mcp_client: McpClient,
) -> CompiledStateGraph[McpState, Any, McpState, McpState]:
    """
    åˆ›å»ºå¸¦ MCP æ”¯æŒçš„ç¼–è¯‘çŠ¶æ€å›¾ï¼ˆå¤šèŠ‚ç‚¹æ¶æ„ï¼‰

    Args:
        node_name: åŸºç¡€èŠ‚ç‚¹åç§°å‰ç¼€
        mcp_client: MCPå®¢æˆ·ç«¯å®ä¾‹

    Returns:
        CompiledStateGraph: ç¼–è¯‘åçš„çŠ¶æ€å›¾
    """
    assert node_name != "", "node_name is empty"
    assert mcp_client is not None, "mcp_client is required"

    # åˆ›å»ºæ–°çš„ ChatDeepSeek å®ä¾‹
    llm = create_deepseek_llm()
    assert llm is not None, "ChatDeepSeek instance is not available"

    # åˆå§‹åŒ– MCP å·¥å…·
    available_tools = []
    try:
        tools_result = await mcp_client.list_tools()
        available_tools = tools_result if tools_result is not None else []
        logger.info(f"MCP å·¥å…·åˆå§‹åŒ–å®Œæˆï¼Œå¯ç”¨å·¥å…·æ•°é‡: {len(available_tools)}")
    except Exception as e:
        logger.error(f"MCP å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
        # MCP åˆå§‹åŒ–å¤±è´¥ï¼Œä½†ç»§ç»­è¿è¡Œï¼ˆåªæ˜¯æ²¡æœ‰å·¥å…·æ”¯æŒï¼‰

    # åˆ›å»ºåŒ…è£…å‡½æ•°ï¼Œä¼ é€’å¿…è¦çš„ä¸Šä¸‹æ–‡
    async def preprocess_wrapper(state: McpState) -> McpState:
        # ç¡®ä¿çŠ¶æ€åŒ…å«å¿…è¦ä¿¡æ¯ï¼ŒåŒ…æ‹¬LLMå®ä¾‹
        state_with_context: McpState = {
            "messages": state.get("messages", []),
            "llm": state.get("llm", llm),  # ç¡®ä¿LLMå®ä¾‹å­˜åœ¨
            "mcp_client": state.get("mcp_client", mcp_client),
            "available_tools": state.get("available_tools", available_tools),
            "tool_outputs": state.get("tool_outputs", []),
        }
        return await _preprocess_node(state_with_context)

    async def error_fallback_wrapper(state: McpState) -> McpState:
        """é”™è¯¯å¤„ç†åŒ…è£…å™¨ï¼Œç¡®ä¿æ€»èƒ½è¿”å›æœ‰æ•ˆå“åº”"""
        try:
            # å¦‚æœä¹‹å‰çš„èŠ‚ç‚¹éƒ½å¤±è´¥äº†ï¼Œæä¾›ä¸€ä¸ªåŸºæœ¬çš„é”™è¯¯å“åº”
            if not state.get("messages"):
                error_message = AIMessage(content="æŠ±æ­‰ï¼Œå¤„ç†è¯·æ±‚æ—¶å‘ç”Ÿé”™è¯¯ã€‚")
                fallback_result: McpState = {
                    "messages": [error_message],
                    "llm": llm,  # ç¡®ä¿LLMå®ä¾‹å­˜åœ¨
                    "mcp_client": mcp_client,
                    "available_tools": available_tools,
                    "tool_outputs": [],
                }
                return fallback_result
            return state
        except Exception as e:
            logger.error(f"é”™è¯¯å¤„ç†åŒ…è£…å™¨å¤±è´¥: {e}")
            error_message = AIMessage(content="æŠ±æ­‰ï¼Œç³»ç»Ÿå‘ç”ŸæœªçŸ¥é”™è¯¯ã€‚")
            fallback_exception_result: McpState = {
                "messages": [error_message],
                "llm": llm,  # ç¡®ä¿LLMå®ä¾‹å­˜åœ¨
                "mcp_client": mcp_client,
                "available_tools": available_tools,
                "tool_outputs": [],
            }
            return fallback_exception_result

    # æ„å»ºå¤šèŠ‚ç‚¹çŠ¶æ€å›¾
    graph_builder = StateGraph(McpState)

    # æ·»åŠ å„ä¸ªèŠ‚ç‚¹
    graph_builder.add_node("preprocess", preprocess_wrapper)
    graph_builder.add_node("llm_invoke", _llm_invoke_node)
    graph_builder.add_node("tool_parse", _tool_parse_node)
    graph_builder.add_node("tool_execution", _tool_execution_node)
    graph_builder.add_node("llm_re_invoke", _llm_re_invoke_node)  # æ–°å¢äºŒæ¬¡æ¨ç†èŠ‚ç‚¹
    graph_builder.add_node("response_synthesis", _response_synthesis_node)
    graph_builder.add_node("error_fallback", error_fallback_wrapper)

    # è®¾ç½®æµç¨‹è·¯å¾„
    graph_builder.set_entry_point("preprocess")
    graph_builder.add_edge("preprocess", "llm_invoke")
    graph_builder.add_edge("llm_invoke", "tool_parse")

    # æ·»åŠ æ¡ä»¶è·¯ç”±ï¼šå·¥å…·è§£æååˆ¤æ–­æ˜¯å¦éœ€è¦æ‰§è¡Œå·¥å…·
    graph_builder.add_conditional_edges(
        "tool_parse",
        _should_execute_tools,
        {
            "tool_execution": "tool_execution",
            "response_synthesis": "response_synthesis",
        },
    )

    # æ–°æ¶æ„ï¼šå·¥å…·æ‰§è¡Œåè¿›å…¥äºŒæ¬¡æ¨ç†
    graph_builder.add_edge("tool_execution", "llm_re_invoke")

    # äºŒæ¬¡æ¨ç†åç›´æ¥åˆ°å“åº”åˆæˆ
    graph_builder.add_edge("llm_re_invoke", "response_synthesis")

    graph_builder.set_finish_point("response_synthesis")

    return graph_builder.compile()  # type: ignore[return-value]


############################################################################################################
async def stream_mcp_graph_updates(
    state_compiled_graph: CompiledStateGraph[McpState, Any, McpState, McpState],
    chat_history_state: McpState,
    user_input_state: McpState,
) -> List[BaseMessage]:
    """
    æµå¼å¤„ç† MCP å›¾æ›´æ–°

    Args:
        state_compiled_graph: ç¼–è¯‘åçš„çŠ¶æ€å›¾
        chat_history_state: èŠå¤©å†å²çŠ¶æ€
        user_input_state: ç”¨æˆ·è¾“å…¥çŠ¶æ€

    Returns:
        List[BaseMessage]: å“åº”æ¶ˆæ¯åˆ—è¡¨
    """
    ret: List[BaseMessage] = []

    # åˆå¹¶çŠ¶æ€ï¼Œä¿æŒ MCP ç›¸å…³ä¿¡æ¯
    llm_instance = user_input_state.get("llm") or chat_history_state.get("llm")
    if not llm_instance:
        # å¦‚æœä¸¤ä¸ªçŠ¶æ€éƒ½æ²¡æœ‰LLMå®ä¾‹ï¼Œåˆ›å»ºä¸€ä¸ªæ–°çš„
        llm_instance = create_deepseek_llm()

    merged_message_context: McpState = {
        "messages": chat_history_state["messages"] + user_input_state["messages"],
        "llm": llm_instance,  # ç¡®ä¿LLMå®ä¾‹å­˜åœ¨
        "mcp_client": user_input_state.get(
            "mcp_client", chat_history_state.get("mcp_client")
        ),
        "available_tools": user_input_state.get(
            "available_tools", chat_history_state.get("available_tools", [])
        ),
        "tool_outputs": chat_history_state.get("tool_outputs", []),
    }

    try:
        final_messages = []
        async for event in state_compiled_graph.astream(merged_message_context):
            for node_name, value in event.items():
                # åªæ”¶é›†æ¥è‡ªæœ€ç»ˆèŠ‚ç‚¹çš„æ¶ˆæ¯ï¼Œé¿å…é‡å¤
                if node_name == "response_synthesis" and value.get("messages"):
                    final_messages = value["messages"]
                # è®°å½•å·¥å…·æ‰§è¡Œä¿¡æ¯ï¼ˆç”¨äºè°ƒè¯•ï¼‰
                if value.get("tool_outputs"):
                    logger.info(f"å·¥å…·æ‰§è¡Œè®°å½•: {value['tool_outputs']}")

        # è¿”å›æœ€ç»ˆæ¶ˆæ¯
        ret.extend(final_messages)
    except Exception as e:
        logger.error(f"Stream processing error: {e}")
        error_message = AIMessage(content="æŠ±æ­‰ï¼Œå¤„ç†æ¶ˆæ¯æ—¶å‘ç”Ÿé”™è¯¯ã€‚")
        ret.append(error_message)

    return ret
