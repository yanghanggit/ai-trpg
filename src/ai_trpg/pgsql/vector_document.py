"""
PostgreSQL + pgvector å‘é‡æ“ä½œå·¥å…·é›†
æä¾›å‘é‡å­˜å‚¨ã€æ£€ç´¢ã€ç›¸ä¼¼åº¦æœç´¢ç­‰åŠŸèƒ½
"""

import json
from datetime import datetime
from typing import Any, Dict, List, Optional, Tuple
from loguru import logger
from pgvector.sqlalchemy import Vector  # type: ignore
from sqlalchemy import DateTime, Index, Integer, String, Text, func, text
from sqlalchemy.orm import Mapped, mapped_column
from .base import UUIDBase
from .client import SessionLocal


class VectorDocumentDB(UUIDBase):
    """å‘é‡æ–‡æ¡£å­˜å‚¨è¡¨ - ç”¨äºRAGåŠŸèƒ½çš„æ–‡æ¡£å‘é‡åŒ–å­˜å‚¨"""

    __tablename__ = "vector_documents"

    # æ–‡æ¡£å†…å®¹
    content: Mapped[str] = mapped_column(Text, nullable=False)

    # æ–‡æ¡£æ ‡é¢˜/æ‘˜è¦
    title: Mapped[Optional[str]] = mapped_column(String(200), nullable=True)

    # æ–‡æ¡£æ¥æº/è·¯å¾„
    source: Mapped[Optional[str]] = mapped_column(String(500), nullable=True)

    # æ–‡æ¡£ç±»å‹/åˆ†ç±»
    doc_type: Mapped[Optional[str]] = mapped_column(String(50), nullable=True)

    # å‘é‡ç»´åº¦ (æ”¯æŒå¯é…ç½®ç»´åº¦: 384, 768, 1536ç­‰)
    embedding_dim: Mapped[int] = mapped_column(
        Integer, nullable=False, default=1536, index=True
    )

    # å‘é‡åµŒå…¥ (æ”¯æŒå¯é…ç½®ç»´åº¦ï¼Œä¸å†ç¡¬ç¼–ç 1536)
    embedding: Mapped[Optional[List[float]]] = mapped_column(Vector(), nullable=True)

    # æ–‡æ¡£å¤§å°/å­—ç¬¦æ•°
    content_length: Mapped[Optional[int]] = mapped_column(Integer, nullable=True)

    # å…ƒæ•°æ®å­—æ®µï¼ˆé‡å‘½åä»¥é¿å…ä¸SQLAlchemyçš„metadataå†²çªï¼‰
    doc_metadata: Mapped[Optional[str]] = mapped_column(
        Text, nullable=True
    )  # JSONå­—ç¬¦ä¸²å­˜å‚¨é¢å¤–ä¿¡æ¯

    # åˆ›å»ºæ—¶é—´
    created_at: Mapped[datetime] = mapped_column(
        DateTime(timezone=True), server_default=func.now(), nullable=False
    )

    # æ›´æ–°æ—¶é—´
    updated_at: Mapped[datetime] = mapped_column(
        DateTime(timezone=True),
        server_default=func.now(),
        onupdate=func.now(),
        nullable=False,
    )

    # ç´¢å¼•é…ç½® (ç§»é™¤å‘é‡ç´¢å¼•ä»¥æ”¯æŒå¤šç»´åº¦çµæ´»æ€§)
    # æ³¨æ„: å¯¹äºå°è§„æ¨¡æ•°æ®(<10000æ–‡æ¡£), æ— å‘é‡ç´¢å¼•çš„æ€§èƒ½å½±å“å¯å¿½ç•¥
    # å¦‚éœ€ä¼˜åŒ–å¤§è§„æ¨¡æŸ¥è¯¢, å¯ä¸ºç‰¹å®šç»´åº¦æ·»åŠ æ¡ä»¶ç´¢å¼•
    # embedding_dim ç´¢å¼•å·²åœ¨å­—æ®µå®šä¹‰ä¸­é€šè¿‡ index=True åˆ›å»º
    __table_args__ = (
        Index("ix_vector_documents_doc_type", "doc_type"),
        Index("ix_vector_documents_source", "source"),
    )


##################################################################################################################
# å‘é‡æ–‡æ¡£æ“ä½œ
##################################################################################################################


def save_vector_document(
    content: str,
    embedding: List[float],
    title: Optional[str] = None,
    source: Optional[str] = None,
    doc_type: Optional[str] = None,
    metadata: Optional[Dict[str, Any]] = None,
) -> VectorDocumentDB:
    """
    ä¿å­˜æ–‡æ¡£åŠå…¶å‘é‡åµŒå…¥åˆ°æ•°æ®åº“

    å‚æ•°:
        content: æ–‡æ¡£å†…å®¹
        embedding: å‘é‡åµŒå…¥ (æ”¯æŒä»»æ„ç»´åº¦: 384, 768, 1536ç­‰)
        title: æ–‡æ¡£æ ‡é¢˜
        source: æ–‡æ¡£æ¥æº
        doc_type: æ–‡æ¡£ç±»å‹
        metadata: å…ƒæ•°æ®å­—å…¸

    è¿”å›:
        VectorDocumentDB: ä¿å­˜çš„æ–‡æ¡£å¯¹è±¡
    """
    with SessionLocal() as db:
        try:
            # è‡ªåŠ¨æ£€æµ‹å‘é‡ç»´åº¦
            embedding_dim = len(embedding)

            if embedding_dim == 0:
                raise ValueError("å‘é‡ç»´åº¦ä¸èƒ½ä¸º0")

            document = VectorDocumentDB(
                content=content,
                embedding=embedding,
                embedding_dim=embedding_dim,
                title=title,
                source=source,
                doc_type=doc_type,
                content_length=len(content),
                doc_metadata=json.dumps(metadata) if metadata else None,
            )

            db.add(document)
            db.commit()
            db.refresh(document)

            logger.info(
                f"âœ… å‘é‡æ–‡æ¡£å·²ä¿å­˜: ID={document.id}, ç»´åº¦={embedding_dim}, å†…å®¹é•¿åº¦={len(content)}"
            )
            return document

        except Exception as e:
            db.rollback()
            logger.error(f"âŒ ä¿å­˜å‘é‡æ–‡æ¡£å¤±è´¥: {e}")
            raise e


def clear_all_vector_documents() -> bool:
    """
    æ¸…ç©º vector_documents è¡¨ä¸­çš„æ‰€æœ‰æ–‡æ¡£

    æ³¨æ„ï¼šæ­¤æ“ä½œä¸å¯é€†ï¼Œä»…é€‚ç”¨äºå¼€å‘ç¯å¢ƒé‡ç½®æˆ–æ•°æ®è¿ç§»åœºæ™¯

    è¿”å›:
        bool: æ¸…ç©ºæ˜¯å¦æˆåŠŸ
    """
    logger.info("ğŸ—‘ï¸ [CLEAR] å¼€å§‹æ¸…ç©º vector_documents è¡¨...")

    with SessionLocal() as db:
        try:
            from sqlalchemy import func

            count_before = db.query(func.count(VectorDocumentDB.id)).scalar()
            logger.info(f"ğŸ“Š [CLEAR] æ¸…ç©ºå‰æ–‡æ¡£æ•°é‡: {count_before}")

            db.query(VectorDocumentDB).delete()
            db.commit()

            count_after = db.query(func.count(VectorDocumentDB.id)).scalar()
            logger.success(
                f"âœ… [CLEAR] è¡¨æ•°æ®å·²æ¸…ç©º (åˆ é™¤äº† {count_before} æ¡æ–‡æ¡£ï¼Œå‰©ä½™ {count_after} æ¡)"
            )
            return True

        except Exception as e:
            logger.error(f"âŒ [CLEAR] æ¸…ç©ºè¡¨æ•°æ®å¤±è´¥: {e}")
            db.rollback()
            return False


def search_similar_documents(
    query_embedding: List[float],
    limit: int,
    similarity_threshold: float,
    doc_type_filter: Optional[str] = None,
) -> List[Tuple[VectorDocumentDB, float]]:
    """
    åŸºäºå‘é‡ç›¸ä¼¼åº¦æœç´¢æ–‡æ¡£

    å‚æ•°:
        query_embedding: æŸ¥è¯¢å‘é‡ (æ”¯æŒä»»æ„ç»´åº¦)
        limit: è¿”å›ç»“æœæ•°é‡é™åˆ¶
        similarity_threshold: ç›¸ä¼¼åº¦é˜ˆå€¼
        doc_type_filter: æ–‡æ¡£ç±»å‹è¿‡æ»¤

    è¿”å›:
        List[Tuple[VectorDocumentDB, float]]: (æ–‡æ¡£å¯¹è±¡, ç›¸ä¼¼åº¦åˆ†æ•°) çš„åˆ—è¡¨
    """
    with SessionLocal() as db:
        try:
            # è‡ªåŠ¨æ£€æµ‹æŸ¥è¯¢å‘é‡ç»´åº¦
            query_dim = len(query_embedding)

            if query_dim == 0:
                raise ValueError("æŸ¥è¯¢å‘é‡ç»´åº¦ä¸èƒ½ä¸º0")

            # æ„å»ºSQLæ¡ä»¶
            conditions = [
                "embedding IS NOT NULL",
                f"embedding_dim = {query_dim}",  # åªæœç´¢ç›¸åŒç»´åº¦çš„æ–‡æ¡£
            ]

            # å°†å‘é‡è½¬æ¢ä¸ºPostgreSQLå‘é‡æ ¼å¼çš„å­—ç¬¦ä¸²
            vector_str = "[" + ",".join(map(str, query_embedding)) + "]"
            params = {
                "query_vector": vector_str,
                "threshold": similarity_threshold,
                "limit": limit,
            }

            if doc_type_filter:
                conditions.append("doc_type = :doc_type_filter")
                params["doc_type_filter"] = doc_type_filter

            where_clause = " AND ".join(conditions)

            # ç›´æ¥ä½¿ç”¨åŸç”ŸSQLè¿›è¡Œå‘é‡æœç´¢
            sql = f"""
                SELECT *, (1 - (embedding <=> :query_vector)) as similarity
                FROM vector_documents 
                WHERE {where_clause}
                    AND (1 - (embedding <=> :query_vector)) >= :threshold
                ORDER BY embedding <=> :query_vector
                LIMIT :limit
            """

            results = db.execute(text(sql), params).fetchall()

            # è½¬æ¢ç»“æœ
            documents_with_scores = []
            for row in results:
                doc = db.get(VectorDocumentDB, row.id)
                if doc:
                    documents_with_scores.append((doc, float(row.similarity)))

            logger.info(
                f"ğŸ” æ‰¾åˆ° {len(documents_with_scores)} ä¸ªç›¸ä¼¼æ–‡æ¡£ (ç»´åº¦={query_dim})"
            )
            return documents_with_scores

        except Exception as e:
            logger.error(f"âŒ å‘é‡æœç´¢å¤±è´¥: {e}")
            raise e
