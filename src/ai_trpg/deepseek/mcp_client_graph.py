"""
MCP Client Graph - åŸºäº LangGraph çš„ MCP å·¥å…·è°ƒç”¨å·¥ä½œæµ

## å·¥ä½œæµæ¶æ„
preprocess â†’ llm_invoke â†’ tool_parse â†’ [æ¡ä»¶åˆ¤æ–­]
                                          â†“ (éœ€è¦å·¥å…·)
                                    tool_execution â†’ llm_re_invoke â†’ response_synthesis
                                          â†“ (ä¸éœ€è¦å·¥å…·)
                                    response_synthesis

## ä¸Šä¸‹æ–‡å˜åŒ–é“¾è·¯ï¼ˆContext Chainï¼‰

### æ ¸å¿ƒæ”¹è¿›ï¼šäºŒæ¬¡æ¨ç†ï¼ˆRe-invokeï¼‰æ¨¡å¼
è®©AIåŸºäºå·¥å…·ç»“æœè¿›è¡Œæ·±åº¦åˆ†æï¼Œè€Œä¸æ˜¯ç®€å•æ‹¼æ¥ã€‚

### ä¸Šä¸‹æ–‡æ¼”å˜ï¼ˆ6ä¸ªé˜¶æ®µï¼‰
1. **åˆå§‹ä¸Šä¸‹æ–‡**: `context["messages"] + request["messages"]`
2. **é¢„å¤„ç†å¢å¼º**: æ·»åŠ å·¥å…·æŒ‡ä»¤ â†’ ç›´æ¥ä¿å­˜åˆ° `messages`
3. **ç¬¬ä¸€æ¬¡æ¨ç†**: LLMå†³å®šè°ƒç”¨å·¥å…· â†’ `llm_response`
4. **å·¥å…·æ‰§è¡Œ**: å¹¶å‘æ‰§è¡Œå·¥å…· â†’ `tool_outputs`
5. **äºŒæ¬¡æ¨ç†** â­: ä¿æŒå®Œæ•´å¯¹è¯å†å²ï¼Œè¿½åŠ å·¥å…·ç»“æœ
   ```
   [SystemMessage(è§’è‰²), SystemMessage(å·¥å…·è¯´æ˜),
    HumanMessage(ç”¨æˆ·é—®é¢˜1), AIMessage(AIå›ç­”1),  # â† ä¿ç•™å®Œæ•´å†å²
    HumanMessage(ç”¨æˆ·é—®é¢˜2), AIMessage(AIå›ç­”2),  # â† ä¿ç•™å®Œæ•´å†å²
    HumanMessage(å½“å‰é—®é¢˜), AIMessage(å·¥å…·è°ƒç”¨å†³ç­–),
    AIMessage(å·¥å…·æ‰§è¡Œç»“æœ)]  # â† å…³é”®ï¼šä½¿ç”¨AIMessageè€ŒéSystemMessage
   ```
6. **æœ€ç»ˆå“åº”**: åŸºäºå®Œæ•´ä¸Šä¸‹æ–‡å’Œå·¥å…·ç»“æœçš„æ™ºèƒ½å›ç­” â†’ `final_response`

### å…³é”®è®¾è®¡
- **æ¶ˆæ¯ç±»å‹**: å·¥å…·ç»“æœç”¨ `AIMessage`ï¼ˆAIçš„è§‚å¯Ÿï¼‰è€Œé `SystemMessage`
- **æ¶ˆæ¯é¡ºåº**: ç”¨æˆ·é—®é¢˜ â†’ AIå“åº” â†’ å·¥å…·ç»“æœï¼ˆç¬¦åˆå› æœå…³ç³»ï¼‰
- **è°ƒè¯•åŠŸèƒ½**: `_print_full_context_chain()` æ‰“å°å®Œæ•´é“¾è·¯ï¼ˆDEBUGçº§åˆ«ï¼‰
"""

from dotenv import load_dotenv

# åŠ è½½ .env æ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡
load_dotenv()

import asyncio
from typing import Annotated, Any, Dict, List, Optional
from langchain.schema import AIMessage, SystemMessage, HumanMessage
from langchain_core.messages import BaseMessage
from langchain_deepseek import ChatDeepSeek
from langgraph.graph import StateGraph
from langgraph.graph.message import add_messages
from langgraph.graph.state import CompiledStateGraph
from typing_extensions import TypedDict
from ..mcp import (
    McpClient,
    McpToolInfo,
    ToolCallParser,
    execute_mcp_tool,
    build_json_tool_example,
    format_tool_description_simple,
)
from loguru import logger
import json


############################################################################################################
class McpState(TypedDict, total=False):
    """
    MCP å¢å¼ºçš„çŠ¶æ€ï¼ŒåŒ…å«æ¶ˆæ¯å’Œ MCP å®¢æˆ·ç«¯ç›¸å…³ä¿¡æ¯
    """

    messages: Annotated[List[BaseMessage], add_messages]
    llm: ChatDeepSeek  # DeepSeek LLMå®ä¾‹ï¼Œæ•´ä¸ªgraphæµç¨‹å…±äº«ï¼ˆå¿…éœ€ï¼‰
    mcp_client: McpClient  # MCP å®¢æˆ·ç«¯ï¼ˆå¿…éœ€ï¼‰
    available_tools: List[McpToolInfo]  # å¯ç”¨çš„ MCP å·¥å…·
    tool_outputs: List[Dict[str, Any]]  # å·¥å…·æ‰§è¡Œç»“æœ

    # å·¥ä½œæµç¨‹å­—æ®µ
    first_llm_response: AIMessage  # ç¬¬ä¸€æ¬¡æ¨ç†ç»“æœï¼ˆå†³å®šæ˜¯å¦è°ƒç”¨å·¥å…·ï¼‰
    parsed_tool_calls: List[Dict[str, Any]]  # è§£æå‡ºçš„å·¥å…·è°ƒç”¨
    needs_tool_execution: bool  # æ˜¯å¦éœ€è¦æ‰§è¡Œå·¥å…·

    # æœ€ç»ˆç»“æœ
    final_response: Optional[BaseMessage]  # æœ€ç»ˆå“åº”ï¼ˆæ¥è‡ªäºŒæ¬¡æ¨ç†æˆ–ç¬¬ä¸€æ¬¡æ¨ç†ï¼‰


############################################################################################################
def _build_tool_instruction_prompt(available_tools: List[McpToolInfo]) -> str:
    """
    æ„å»ºç³»ç»Ÿæç¤ºï¼Œä»…æ”¯æŒJSONæ ¼å¼å·¥å…·è°ƒç”¨

    Args:
        available_tools: å¯ç”¨å·¥å…·åˆ—è¡¨

    Returns:
        str: æ„å»ºå¥½çš„ç³»ç»Ÿæç¤º
    """
    # å…ˆæ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·ï¼Œæ²¡æœ‰å·¥å…·å°±ç›´æ¥è¿”å›ç®€å•æç¤º
    if not available_tools:
        return "âš ï¸ å½“å‰æ²¡æœ‰å¯ç”¨å·¥å…·ï¼Œè¯·ä»…ä½¿ç”¨ä½ çš„çŸ¥è¯†å›ç­”é—®é¢˜ã€‚"

    # æœ‰å·¥å…·æ—¶ï¼Œæ‰æ„å»ºå®Œæ•´çš„å·¥å…·è°ƒç”¨è¯´æ˜
    tool_instruction_prompt = """å½“ä½ éœ€è¦è·å–å®æ—¶ä¿¡æ¯æˆ–æ‰§è¡Œç‰¹å®šæ“ä½œæ—¶ï¼Œå¯ä»¥è°ƒç”¨ç›¸åº”çš„å·¥å…·ã€‚

## å·¥å…·è°ƒç”¨æ ¼å¼

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è°ƒç”¨å·¥å…·ï¼ˆæ”¯æŒåŒæ—¶è°ƒç”¨å¤šä¸ªï¼‰ï¼š

```json
{
  "tool_call": {
    "name": "å·¥å…·åç§°1",
    "arguments": {
      "å‚æ•°å": "å‚æ•°å€¼1"
    }
  }
}

{
  "tool_call": {
    "name": "å·¥å…·åç§°2",
    "arguments": {
      "å‚æ•°å": "å‚æ•°å€¼2"
    }
  }
}
```

## ä½¿ç”¨æŒ‡å—

- å½“ä»»åŠ¡æ˜ç¡®è¦æ±‚ä½ è°ƒç”¨å·¥å…·æ—¶ï¼Œä½ å¿…é¡»è°ƒç”¨ç›¸åº”çš„å·¥å…·

**å·¥å…·è°ƒç”¨æµç¨‹**ï¼š
1. åˆ†æä»»åŠ¡éœ€æ±‚ï¼Œç¡®å®šéœ€è¦è°ƒç”¨å“ªäº›å·¥å…·
2. æŒ‰ç…§JSONæ ¼å¼è°ƒç”¨å·¥å…·ï¼ˆå¯åŒæ—¶è°ƒç”¨å¤šä¸ªï¼‰

**ç¦æ­¢è¡Œä¸º**ï¼š
- âŒ ä¸è¦åœ¨æœªè°ƒç”¨å·¥å…·çš„æƒ…å†µä¸‹å‡è®¾æˆ–æ¨æµ‹å·¥å…·æ‰§è¡Œç»“æœ"""

    # æ„å»ºå·¥å…·æè¿° - ç®€åŒ–ç‰ˆæœ¬ï¼Œç»Ÿä¸€ä½¿ç”¨çº¿æ€§å±•ç¤º
    tool_instruction_prompt += "\n\n## å¯ç”¨å·¥å…·"

    # ç›´æ¥åˆ—è¡¨å±•ç¤ºæ‰€æœ‰å·¥å…·ï¼Œæ— éœ€åˆ†ç±»
    for tool in available_tools:
        tool_desc = format_tool_description_simple(tool)
        tool_instruction_prompt += f"\n{tool_desc}"

    # æ·»åŠ å·¥å…·è°ƒç”¨ç¤ºä¾‹
    example_tool = available_tools[0]
    tool_instruction_prompt += f"\n\n## è°ƒç”¨ç¤ºä¾‹\n\n"
    tool_instruction_prompt += build_json_tool_example(example_tool)

    return tool_instruction_prompt


############################################################################################################
async def _preprocess_node(state: McpState) -> McpState:
    """
    é¢„å¤„ç†èŠ‚ç‚¹ï¼šå‡†å¤‡ç³»ç»Ÿæç¤ºå’Œå¢å¼ºæ¶ˆæ¯

    å…³é”®èŒè´£ï¼šç›´æ¥ä¿®æ”¹ messages ä¸Šä¸‹æ–‡ï¼Œæ³¨å…¥å·¥å…·è¯´æ˜
    åç»­èŠ‚ç‚¹åªèƒ½è¯»å– messagesï¼Œä¸èƒ½å†æ·»åŠ ä»»ä½•å†…å®¹

    Args:
        state: å½“å‰çŠ¶æ€

    Returns:
        McpState: æ›´æ–°åçš„çŠ¶æ€
    """
    messages = state["messages"]
    available_tools = state.get("available_tools", [])

    # æ„å»ºç³»ç»Ÿæç¤º
    tool_instruction_prompt = _build_tool_instruction_prompt(available_tools)
    logger.debug(f"ğŸ› ï¸ å·¥å…·æŒ‡ä»¤æç¤º:\n{tool_instruction_prompt}")

    # æ™ºèƒ½æ·»åŠ ç³»ç»Ÿæ¶ˆæ¯ï¼šå¦‚æœå·²æœ‰ç³»ç»Ÿæ¶ˆæ¯åˆ™è¿½åŠ ï¼Œå¦åˆ™æ’å…¥åˆ°å¼€å¤´
    enhanced_messages = messages.copy()
    if enhanced_messages and isinstance(enhanced_messages[0], SystemMessage):
        # å·²ç»æœ‰ç³»ç»Ÿæ¶ˆæ¯åœ¨å¼€å¤´ï¼Œè¿½åŠ æ–°çš„å·¥å…·è¯´æ˜
        enhanced_messages.insert(1, SystemMessage(content=tool_instruction_prompt))
    else:
        # æ²¡æœ‰ç³»ç»Ÿæ¶ˆæ¯ï¼Œæ’å…¥é»˜è®¤è§’è‰²è®¾å®šå’Œå·¥å…·è¯´æ˜åˆ°å¼€å¤´
        default_role_prompt = (
            "ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ï¼Œå…·æœ‰ä½¿ç”¨å·¥å…·çš„èƒ½åŠ›ã€‚\n\n" + tool_instruction_prompt
        )
        enhanced_messages.insert(0, SystemMessage(content=default_role_prompt))

        # èµ°åˆ°è¿™é‡ŒåŸºæœ¬å°±æ˜¯é”™äº†ï¼Œè­¦å‘Šä¸‹ï¼Œå› ä¸ºä¼šå½±å“è§’è‰²è®¾å®šï¼
        logger.warning(
            "âš ï¸ ç³»ç»Ÿæ¶ˆæ¯ç¼ºå¤±ï¼Œå·²è‡ªåŠ¨æ·»åŠ é»˜è®¤è§’è‰²è®¾å®šå’Œå·¥å…·è¯´æ˜ï¼Œèµ°åˆ°è¿™é‡ŒåŸºæœ¬å°±æ˜¯é”™äº†ï¼Œè­¦å‘Šä¸‹ï¼Œå› ä¸ºä¼šå½±å“è§’è‰²è®¾å®šï¼"
        )

    # å…³é”®æ”¹å˜ï¼šç›´æ¥å°†å¢å¼ºåçš„æ¶ˆæ¯ä¿å­˜åˆ° messages ä¸­
    result: McpState = {
        "messages": enhanced_messages,  # ç›´æ¥ä¿å­˜å¢å¼ºåçš„æ¶ˆæ¯
        "llm": state["llm"],
        "mcp_client": state["mcp_client"],
        "available_tools": available_tools,
        "tool_outputs": state.get("tool_outputs", []),
    }
    return result


############################################################################################################
async def _llm_invoke_node(state: McpState) -> McpState:
    """
    LLMè°ƒç”¨èŠ‚ç‚¹ï¼šç¬¬ä¸€æ¬¡æ¨ç†ï¼Œå†³å®šæ˜¯å¦è°ƒç”¨å·¥å…·

    çº¦æŸï¼š
    - æ­£å¸¸æ—¶ï¼šè®¾ç½® first_llm_response å¹¶åŠ å…¥ messages
    - å¼‚å¸¸æ—¶ï¼šè®©å¼‚å¸¸å‘ä¸Šä¼ æ’­åˆ° execute_mcp_workflowï¼Œfinal_response ä¿æŒ None

    Args:
        state: å½“å‰çŠ¶æ€

    Returns:
        McpState: æ›´æ–°åçš„çŠ¶æ€
    """
    llm = state["llm"]
    messages = state["messages"]

    # è°ƒç”¨ LLMï¼ˆå¦‚æœå¼‚å¸¸ï¼Œç›´æ¥å‘ä¸Šä¼ æ’­ï¼‰
    response = llm.invoke(messages)
    assert isinstance(response, AIMessage), "LLM è¿”å›çš„å“åº”å¿…é¡»æ˜¯ AIMessage ç±»å‹"

    return {
        "messages": [response],  # åŠ å…¥ messagesï¼Œä¿æŒä¸Šä¸‹æ–‡è¿è´¯
        "first_llm_response": response,  # ä¿å­˜å¼•ç”¨ä¾›åç»­èŠ‚ç‚¹ä½¿ç”¨
    }


############################################################################################################
async def _tool_parse_node(state: McpState) -> McpState:
    """
    å·¥å…·è§£æèŠ‚ç‚¹ï¼šè§£æLLMå“åº”ä¸­çš„å·¥å…·è°ƒç”¨

    çº¦æŸï¼š
    - first_llm_response å¿…é¡»å­˜åœ¨ï¼ˆä» llm_invoke_node ä¼ æ¥ï¼‰
    - è§£æå¤±è´¥æ—¶å¼‚å¸¸å‘ä¸Šä¼ æ’­

    Args:
        state: å½“å‰çŠ¶æ€

    Returns:
        McpState: æ›´æ–°åçš„çŠ¶æ€ï¼ˆä»…åŒ…å« parsed_tool_calls å’Œ needs_tool_executionï¼‰
    """
    first_llm_response = state.get("first_llm_response")
    assert first_llm_response is not None, "first_llm_response å¿…é¡»å­˜åœ¨"

    available_tools = state.get("available_tools", [])
    parsed_tool_calls = []

    # åªæœ‰åœ¨æœ‰å¯ç”¨å·¥å…·æ—¶æ‰è§£æ
    if available_tools:
        response_content = str(first_llm_response.content or "")

        # ä½¿ç”¨å¢å¼ºçš„å·¥å…·è°ƒç”¨è§£æå™¨ï¼ˆå¦‚æœè§£æå¤±è´¥ï¼Œè®©å¼‚å¸¸å‘ä¸Šä¼ æ’­ï¼‰
        parser = ToolCallParser(available_tools)
        parsed_tool_calls = parser.parse_tool_calls(response_content)

        logger.info(f"ğŸ“‹ è§£æåˆ° {len(parsed_tool_calls)} ä¸ªå·¥å…·è°ƒç”¨")
        for call in parsed_tool_calls:
            logger.debug(f"   - {call['name']}: {call['args']}")

    # åªè¿”å›æ”¹å˜çš„å­—æ®µï¼ŒLangGraph è‡ªåŠ¨ç»§æ‰¿å…¶ä»–å­—æ®µ
    return {
        "parsed_tool_calls": parsed_tool_calls,
        "needs_tool_execution": len(parsed_tool_calls) > 0,
    }


############################################################################################################
async def _tool_execution_node(state: McpState) -> McpState:
    """
    å·¥å…·æ‰§è¡ŒèŠ‚ç‚¹ï¼šå¹¶å‘æ‰§è¡Œå·¥å…·è°ƒç”¨ï¼Œè¿”å›æ‰§è¡Œç»“æœ

    æ ¸å¿ƒèŒè´£ï¼šæ”¹å˜ tool_outputs å­—æ®µ
    çº¦æŸï¼š
    - asyncio.gather(return_exceptions=True) å·²å¤„ç†å•ä¸ªå·¥å…·å¼‚å¸¸
    - å¼‚å¸¸å‘ä¸Šä¼ æ’­åˆ° execute_mcp_workflow

    Args:
        state: å½“å‰çŠ¶æ€

    Returns:
        McpState: æ›´æ–°åçš„çŠ¶æ€ï¼ˆä»…åŒ…å« tool_outputsï¼‰
    """
    parsed_tool_calls = state.get("parsed_tool_calls", [])
    mcp_client = state["mcp_client"]

    # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œè¿”å›ç©ºç»“æœ
    if not parsed_tool_calls:
        return {"tool_outputs": []}

    # å¹¶å‘æ‰§è¡Œæ‰€æœ‰å·¥å…·
    logger.info(f"ğŸ”§ å¼€å§‹æ‰§è¡Œ {len(parsed_tool_calls)} ä¸ªå·¥å…·è°ƒç”¨")

    tasks = [
        execute_mcp_tool(
            call["name"],
            call["args"],
            mcp_client,
            timeout=30.0,
            max_retries=2,
        )
        for call in parsed_tool_calls
    ]

    # asyncio.gather å·²ç»å¤„ç†å¼‚å¸¸ (return_exceptions=True)
    results = await asyncio.gather(*tasks, return_exceptions=True)

    # æ„å»º tool_outputs
    tool_outputs = []
    for call, result in zip(parsed_tool_calls, results):
        if isinstance(result, Exception):
            logger.error(f"å·¥å…·æ‰§è¡Œå¤±è´¥: {call['name']}, é”™è¯¯: {result}")
            tool_outputs.append(
                {
                    "tool": call["name"],
                    "args": call["args"],
                    "result": f"æ‰§è¡Œå¤±è´¥: {str(result)}",
                    "success": False,
                    "execution_time": 0.0,
                }
            )
        elif isinstance(result, tuple) and len(result) == 3:
            success, task_result, exec_time = result
            tool_outputs.append(
                {
                    "tool": call["name"],
                    "args": call["args"],
                    "result": task_result,
                    "success": success,
                    "execution_time": exec_time,
                }
            )
        else:
            # æ„å¤–çš„ç»“æœç±»å‹ï¼Œè®°å½•é”™è¯¯
            logger.error(f"å·¥å…·è¿”å›æ„å¤–ç»“æœç±»å‹: {call['name']}, ç»“æœ: {result}")
            tool_outputs.append(
                {
                    "tool": call["name"],
                    "args": call["args"],
                    "result": f"æ„å¤–ç»“æœç±»å‹: {type(result)}",
                    "success": False,
                    "execution_time": 0.0,
                }
            )

    # ç»Ÿè®¡æ—¥å¿—
    successful = sum(1 for o in tool_outputs if o["success"])
    total_time = sum(o["execution_time"] for o in tool_outputs)
    logger.info(
        f"âœ… å·¥å…·æ‰§è¡Œå®Œæˆ: {successful}/{len(tool_outputs)} æˆåŠŸ, æ€»è€—æ—¶: {total_time:.2f}s"
    )
    logger.debug(
        f"å·¥å…·æ‰§è¡Œè®°å½•: {json.dumps(tool_outputs, indent=2, ensure_ascii=False)}"
    )

    # åªè¿”å›æ”¹å˜çš„å­—æ®µ
    return {"tool_outputs": tool_outputs}


############################################################################################################
async def _llm_re_invoke_node(state: McpState) -> McpState:
    """
    äºŒæ¬¡æ¨ç†èŠ‚ç‚¹ï¼šåŸºäºå·¥å…·æ‰§è¡Œç»“æœé‡æ–°è°ƒç”¨LLMè¿›è¡Œæ™ºèƒ½åˆ†æ

    è¿™æ˜¯æ–°æ¶æ„çš„æ ¸å¿ƒèŠ‚ç‚¹ï¼Œè§£å†³äº†å·¥å…·ç»“æœåªæ˜¯ç®€å•æ‹¼æ¥çš„é—®é¢˜ã€‚
    è®©AIèƒ½å¤ŸåŸºäºå·¥å…·ç»“æœè¿›è¡Œæ·±åº¦åˆ†æå’Œä¸ªæ€§åŒ–å›ç­”ã€‚

    çº¦æŸï¼šåªè¯»å– messagesï¼Œä¸æ·»åŠ ä»»ä½•å†…å®¹

    Args:
        state: å½“å‰çŠ¶æ€

    Returns:
        McpState: æ›´æ–°åçš„çŠ¶æ€
    """
    try:
        llm = state["llm"]
        tool_outputs = state.get("tool_outputs", [])
        # ç›´æ¥ä½¿ç”¨ messagesï¼ˆå·²åœ¨é¢„å¤„ç†ä¸­å¢å¼ºï¼‰
        original_messages = state["messages"]

        if not tool_outputs:
            # æ²¡æœ‰å·¥å…·è¾“å‡ºï¼Œç›´æ¥ä½¿ç”¨ç¬¬ä¸€æ¬¡æ¨ç†å“åº”
            original_response = state.get("first_llm_response")
            if original_response:
                no_tool_result: McpState = {
                    "messages": state["messages"],  # ä¿æŒä¸å˜
                    "llm": llm,
                    "mcp_client": state["mcp_client"],
                    "available_tools": state.get("available_tools", []),
                    "tool_outputs": [],
                    "final_response": original_response,  # æ ‡è®°ä¸ºæœ€ç»ˆå“åº”
                }
                return no_tool_result

        # æ„å»ºåŒ…å«å·¥å…·ç»“æœçš„ä¸Šä¸‹æ–‡æ¶ˆæ¯
        tool_context_parts = []

        for i, output in enumerate(tool_outputs, 1):
            tool_name = output.get("tool", "æœªçŸ¥å·¥å…·")
            success = output.get("success", False)
            result_data = output.get("result", "æ— ç»“æœ")
            exec_time = output.get("execution_time", 0.0)

            status = "æˆåŠŸ" if success else "å¤±è´¥"
            tool_context_parts.append(
                f"å·¥å…·{i}: {tool_name} (æ‰§è¡Œ{status}, è€—æ—¶{exec_time:.2f}s)\n"
                f"ç»“æœ: {result_data}"
            )

        tool_context = "\n\n".join(tool_context_parts)

        # æ„å»ºäºŒæ¬¡æ¨ç†çš„æç¤ºï¼ˆçµæ´»å¤„ç†ï¼Œé€‚ç”¨äºæ¸¸æˆåœºæ™¯çš„å¤šæ ·åŒ–äº¤äº’ï¼‰
        tool_analysis_prompt = f"""
## ğŸ“Š å·¥å…·æ‰§è¡Œç»“æœ

{tool_context}

---

## âš ï¸ çº¦æŸæ¡ä»¶

- **ç¦æ­¢å†æ¬¡è°ƒç”¨å·¥å…·** - æ‰€æœ‰å·¥å…·å·²æ‰§è¡Œå®Œæˆ
- **ç¦æ­¢è¾“å‡ºå·¥å…·è°ƒç”¨æ ¼å¼** - ä¸è¦ç”Ÿæˆ {{"tool_call": ...}} è¿™æ ·çš„JSONç»“æ„

## âœ… å“åº”è¦æ±‚

1. **å†…å®¹**: åŸºäºä¸Šè¿°å·¥å…·ç»“æœç›´æ¥å“åº”ç”¨æˆ·è¾“å…¥ï¼Œä¿æŒä½ çš„è§’è‰²è®¾å®šå’Œè¯­è¨€é£æ ¼
2. **æ ¼å¼**: å¦‚æœç”¨æˆ·æ˜ç¡®è¦æ±‚ç‰¹å®šè¾“å‡ºæ ¼å¼(JSON/Markdown/è¡¨æ ¼ç­‰)ï¼Œä¸¥æ ¼éµå®ˆ
3. **é£æ ¼**: æ ¹æ®ä¸Šä¸‹æ–‡çµæ´»å“åº”ï¼Œæ— éœ€è§£é‡Šå·¥å…·è°ƒç”¨è¿‡ç¨‹

ğŸ’¡ **æç¤º**: ç”¨æˆ·è¾“å…¥å¯èƒ½æ˜¯é—®é¢˜ã€æŒ‡ä»¤ã€å¯¹è¯æˆ–è¡ŒåŠ¨æè¿°ï¼Œè¯·è‡ªç„¶åœ°èåˆå·¥å…·ç»“æœè¿›è¡Œå›åº”ã€‚"""

        # åˆ›å»ºäºŒæ¬¡æ¨ç†çš„æ¶ˆæ¯åˆ—è¡¨ï¼Œä¿æŒå®Œæ•´çš„å¯¹è¯å†å²
        re_invoke_messages: List[BaseMessage] = []

        # å…³é”®æ”¹è¿›ï¼šä¿ç•™å®Œæ•´çš„åŸå§‹æ¶ˆæ¯åºåˆ—ï¼Œç»´æŒå¯¹è¯è¿è´¯æ€§
        # ä¸å†é€‰æ‹©æ€§è¿‡æ»¤æ¶ˆæ¯ç±»å‹ï¼Œé¿å…ä¸¢å¤±å†å² AIMessage
        # åŸå§‹æ¶ˆæ¯åŒ…å«ï¼šSystemMessage(è§’è‰²+å·¥å…·è¯´æ˜) + å®Œæ•´çš„å†å²å¯¹è¯
        for msg in original_messages:
            re_invoke_messages.append(msg)

        # æ³¨æ„ï¼šoriginal_messages é€šå¸¸ä¸åŒ…å«ç¬¬ä¸€æ¬¡ LLM å“åº”ï¼ˆfirst_llm_responseï¼‰
        # å› ä¸º original_messages æ¥è‡ª messagesï¼ˆåœ¨é¢„å¤„ç†èŠ‚ç‚¹æ„å»ºï¼‰ï¼Œ
        # ä¸åŒ…æ‹¬ç¬¬ä¸€æ¬¡ LLM è°ƒç”¨çš„ç»“æœ
        # å› æ­¤æˆ‘ä»¬éœ€è¦æ˜¾å¼æ·»åŠ ç¬¬ä¸€æ¬¡æ¨ç†çš„å“åº”

        # æ£€æŸ¥æ˜¯å¦éœ€è¦æ·»åŠ ç¬¬ä¸€æ¬¡ LLM å“åº”ï¼ˆå·¥å…·è°ƒç”¨å†³ç­–ï¼‰
        # è¿™ä¸€æ­¥å¾ˆé‡è¦ï¼šå±•ç¤º AI å†³å®šè°ƒç”¨å“ªäº›å·¥å…·çš„è¿‡ç¨‹
        llm_first_response = state.get("first_llm_response")
        if llm_first_response:
            # å®‰å…¨æ£€æŸ¥ï¼šç¡®ä¿ä¸é‡å¤æ·»åŠ ï¼ˆè™½ç„¶é€šå¸¸ä¸ä¼šé‡å¤ï¼‰
            if not re_invoke_messages or re_invoke_messages[-1] != llm_first_response:
                re_invoke_messages.append(llm_first_response)

        # æœ€åæ·»åŠ å·¥å…·æ‰§è¡Œç»“æœä½œä¸º AIMessageï¼ˆè€Œä¸æ˜¯ SystemMessageï¼‰
        # è¡¨ç¤º"AIè§‚å¯Ÿåˆ°å·¥å…·æ‰§è¡Œçš„ç»“æœ"ï¼Œè€Œä¸æ˜¯ç³»ç»Ÿçº§æŒ‡ä»¤
        # è¿™æ ·ä¿æŒäº†å¯¹è¯æµçš„è¿è´¯æ€§ï¼šå†å²å¯¹è¯ â†’ User(é—®é¢˜) â†’ AI(è°ƒç”¨å·¥å…·) â†’ AI(è§‚å¯Ÿç»“æœ) â†’ AI(æœ€ç»ˆå›ç­”)
        re_invoke_messages.append(AIMessage(content=tool_analysis_prompt))

        # äºŒæ¬¡è°ƒç”¨ LLM
        logger.info("ğŸ”„ å¼€å§‹äºŒæ¬¡æ¨ç†ï¼ŒåŸºäºå·¥å…·ç»“æœç”Ÿæˆæ™ºèƒ½å›ç­”...")
        re_invoke_response = llm.invoke(re_invoke_messages)

        logger.info("âœ… äºŒæ¬¡æ¨ç†å®Œæˆ")

        re_invoke_result: McpState = {
            "messages": state["messages"],  # ä¿æŒä¸å˜ï¼Œä¸æ·»åŠ å†…å®¹
            "llm": llm,
            "mcp_client": state["mcp_client"],
            "available_tools": state.get("available_tools", []),
            "tool_outputs": tool_outputs,
            "final_response": re_invoke_response,  # æ ‡è®°ä¸ºæœ€ç»ˆå“åº”
        }
        return re_invoke_result

    except Exception as e:
        logger.error(f"äºŒæ¬¡æ¨ç†èŠ‚ç‚¹é”™è¯¯: {e}")
        # é™çº§å¤„ç†ï¼šä½¿ç”¨ç¬¬ä¸€æ¬¡æ¨ç†å“åº”åˆæˆ
        original_response = state.get("first_llm_response")
        if original_response and state.get("tool_outputs"):
            from ..mcp.response import synthesize_response_with_tools

            synthesized_content = synthesize_response_with_tools(
                str(original_response.content) if original_response.content else "",
                state.get("tool_outputs", []),
                state.get("parsed_tool_calls", []),
            )
            original_response.content = synthesized_content

        error_fallback_response = original_response or AIMessage(
            content=f"æŠ±æ­‰ï¼ŒäºŒæ¬¡æ¨ç†æ—¶å‘ç”Ÿé”™è¯¯ï¼š{str(e)}"
        )

        error_result: McpState = {
            "messages": state["messages"],  # ä¿æŒåŸæ¶ˆæ¯ä¸å˜
            "llm": state["llm"],
            "mcp_client": state["mcp_client"],
            "available_tools": state.get("available_tools", []),
            "tool_outputs": state.get("tool_outputs", []),
            "final_response": error_fallback_response,  # æ·»åŠ  final_response
        }
        return error_result


############################################################################################################
############################################################################################################
async def _response_synthesis_node(state: McpState) -> McpState:
    """
    å“åº”åˆæˆèŠ‚ç‚¹ï¼šå¤„ç†æœ€ç»ˆå“åº”è¾“å‡º

    æ ¹æ®è®¾è®¡å“²å­¦ï¼š
    1. ä¼˜å…ˆä½¿ç”¨ final_responseï¼ˆæ¥è‡ªäºŒæ¬¡æ¨ç†ï¼‰
    2. å¦‚æœæ²¡æœ‰ final_responseï¼Œå›é€€åˆ° first_llm_response
    3. first_llm_response å¿…é¡»å­˜åœ¨ï¼ˆæ¥è‡ª llm_invoke_nodeï¼‰

    çº¦æŸï¼š
    - åªè¯»å– messagesï¼Œä¸æ·»åŠ ä»»ä½•å†…å®¹
    - æ‰€æœ‰ AIMessage å¿…é¡»æ¥è‡ªçœŸå®çš„ LLM æ¨ç†ï¼Œä¸å…è®¸æ¨¡æ‹Ÿ

    Args:
        state: å½“å‰çŠ¶æ€

    Returns:
        McpState: æ›´æ–°åçš„çŠ¶æ€ï¼ŒåŒ…å« final_response
    """
    # ä¼˜å…ˆä½¿ç”¨ final_responseï¼ˆæ¥è‡ªäºŒæ¬¡æ¨ç†æˆ– llm_re_invoke çš„ no_tool åˆ†æ”¯ï¼‰
    final_response = state.get("final_response")

    if final_response:
        # å·²ç»æœ‰æœ€ç»ˆå“åº”ï¼Œç›´æ¥è¿”å›
        return {
            "messages": [final_response],
            "final_response": final_response,
        }

    # å›é€€åˆ° first_llm_responseï¼ˆæœªè°ƒç”¨å·¥å…·çš„æƒ…å†µï¼‰
    first_llm_response = state.get("first_llm_response")
    assert first_llm_response is not None, (
        "first_llm_response å¿…é¡»å­˜åœ¨ã€‚"
        "æ‰€æœ‰ AIMessage å¿…é¡»æ¥è‡ªçœŸå®çš„ LLM æ¨ç†ï¼Œä¸å…è®¸æ¨¡æ‹Ÿã€‚"
    )

    # ä½¿ç”¨ç¬¬ä¸€æ¬¡æ¨ç†ç»“æœä½œä¸ºæœ€ç»ˆå“åº”
    return {
        "messages": [first_llm_response],
        "final_response": first_llm_response,
    }


############################################################################################################
def _should_execute_tools(state: McpState) -> str:
    """
    æ¡ä»¶è·¯ç”±ï¼šåˆ¤æ–­æ˜¯å¦éœ€è¦æ‰§è¡Œå·¥å…·

    Args:
        state: å½“å‰çŠ¶æ€

    Returns:
        str: ä¸‹ä¸€ä¸ªèŠ‚ç‚¹åç§°
    """
    needs_tool_execution = state.get("needs_tool_execution", False)
    return "tool_execution" if needs_tool_execution else "response_synthesis"


############################################################################################################
def create_mcp_workflow() -> CompiledStateGraph[McpState, Any, McpState, McpState]:
    """
    åˆ›å»ºå¸¦ MCP æ”¯æŒçš„ç¼–è¯‘çŠ¶æ€å›¾ï¼ˆå¤šèŠ‚ç‚¹æ¶æ„ï¼‰

    Args:
        workflow_name: å·¥ä½œæµåç§°æ ‡è¯†
        mcp_client: MCPå®¢æˆ·ç«¯å®ä¾‹

    Returns:
        CompiledStateGraph: ç¼–è¯‘åçš„çŠ¶æ€å›¾
    """

    # æ„å»ºå¤šèŠ‚ç‚¹çŠ¶æ€å›¾
    graph_builder = StateGraph(McpState)

    # æ·»åŠ å„ä¸ªèŠ‚ç‚¹
    graph_builder.add_node("preprocess", _preprocess_node)
    graph_builder.add_node("llm_invoke", _llm_invoke_node)
    graph_builder.add_node("tool_parse", _tool_parse_node)
    graph_builder.add_node("tool_execution", _tool_execution_node)
    graph_builder.add_node("llm_re_invoke", _llm_re_invoke_node)
    graph_builder.add_node("response_synthesis", _response_synthesis_node)

    # è®¾ç½®æµç¨‹è·¯å¾„
    graph_builder.set_entry_point("preprocess")
    graph_builder.add_edge("preprocess", "llm_invoke")
    graph_builder.add_edge("llm_invoke", "tool_parse")

    # æ·»åŠ æ¡ä»¶è·¯ç”±ï¼šå·¥å…·è§£æååˆ¤æ–­æ˜¯å¦éœ€è¦æ‰§è¡Œå·¥å…·
    graph_builder.add_conditional_edges(
        "tool_parse",
        _should_execute_tools,
        {
            "tool_execution": "tool_execution",
            "response_synthesis": "response_synthesis",
        },
    )

    # æ–°æ¶æ„ï¼šå·¥å…·æ‰§è¡Œåè¿›å…¥äºŒæ¬¡æ¨ç†
    graph_builder.add_edge("tool_execution", "llm_re_invoke")

    # äºŒæ¬¡æ¨ç†åç›´æ¥åˆ°å“åº”åˆæˆ
    graph_builder.add_edge("llm_re_invoke", "response_synthesis")

    graph_builder.set_finish_point("response_synthesis")

    return graph_builder.compile()  # type: ignore[return-value]


############################################################################################################
async def execute_mcp_workflow(
    work_flow: CompiledStateGraph[McpState, Any, McpState, McpState],
    context: List[BaseMessage],
    request: HumanMessage,
    llm: ChatDeepSeek,
    mcp_client: McpClient,
) -> List[BaseMessage]:
    """æ‰§è¡ŒMCPå·¥ä½œæµå¹¶è¿”å›æ‰€æœ‰å“åº”æ¶ˆæ¯

    å°†èŠå¤©å†å²å’Œç”¨æˆ·è¾“å…¥åˆå¹¶åï¼Œé€šè¿‡ç¼–è¯‘å¥½çš„çŠ¶æ€å›¾è¿›è¡ŒMCPå·¥å…·è°ƒç”¨å¤„ç†ï¼Œ
    æ”¶é›†å¹¶è¿”å›æ‰€æœ‰ç”Ÿæˆçš„æ¶ˆæ¯ã€‚McpState çš„åˆ›å»ºè¢«å°è£…åœ¨å‡½æ•°å†…éƒ¨ã€‚

    Args:
        work_flow: å·²ç¼–è¯‘çš„ LangGraph çŠ¶æ€å›¾
        context: å†å²æ¶ˆæ¯åˆ—è¡¨
        request: ç”¨æˆ·å½“å‰è¾“å…¥çš„æ¶ˆæ¯
        llm: ChatDeepSeek LLM å®ä¾‹
        mcp_client: MCP å®¢æˆ·ç«¯å®ä¾‹

    Returns:
        åŒ…å«æ‰€æœ‰ç”Ÿæˆæ¶ˆæ¯çš„åˆ—è¡¨
    """
    ret: List[BaseMessage] = []

    # åœ¨å‡½æ•°å†…éƒ¨è·å–å¯ç”¨å·¥å…·åˆ—è¡¨
    available_tools = await mcp_client.list_tools()
    if available_tools is None:
        available_tools = []

    # åœ¨å†…éƒ¨æ„é€  McpStateï¼ˆå°è£…å®ç°ç»†èŠ‚ï¼‰
    merged_message_context: McpState = {
        "messages": context + [request],
        "llm": llm,
        "mcp_client": mcp_client,
        "available_tools": available_tools,
        "tool_outputs": [],
    }

    try:

        # æœ€ç»ˆçŠ¶æ€
        final_state = None

        # æµå¼å¤„ç†æ‰€æœ‰èŠ‚ç‚¹çš„æ›´æ–°
        async for event in work_flow.astream(merged_message_context):
            for node_name, value in event.items():
                # æŒç»­æ›´æ–°çŠ¶æ€ï¼Œæœ€åä¸€ä¸ªå°±æ˜¯æœ€ç»ˆçŠ¶æ€
                final_state = value

        # âœ… å…³é”®æ”¹è¿›ï¼šä»æœ€ç»ˆçŠ¶æ€çš„ final_response å­—æ®µè·å–ç»“æœï¼Œä¸ä¾èµ–èŠ‚ç‚¹åç§°
        if final_state:
            final_response = final_state.get("final_response")
            if final_response:
                logger.info("âœ… ä»çŠ¶æ€çš„ final_response å­—æ®µè·å–æœ€ç»ˆå“åº”")
                ret.append(final_response)
            else:
                logger.error(
                    "âŒ final_response ä¸å­˜åœ¨ï¼Œè¿™ä¸åº”è¯¥å‘ç”Ÿï¼ˆæ‰€æœ‰èŠ‚ç‚¹éƒ½åº”è¯¥è®¾ç½® final_responseï¼‰"
                )
        else:
            logger.error("âŒ æœªè·å–åˆ°æœ€ç»ˆçŠ¶æ€")

    except Exception as e:
        logger.error(f"Stream processing error: {e}")

    return ret


############################################################################################################
