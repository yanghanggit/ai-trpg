"""
RAG (Retrieval-Augmented Generation) å·¥ä½œæµå®ç°

æœ¬æ¨¡å—å®ç°äº†åŸºäº LangGraph çš„ RAG æ£€ç´¢å¢å¼ºç”Ÿæˆå·¥ä½œæµï¼Œç”¨äºç»“åˆçŸ¥è¯†åº“æ£€ç´¢å’Œ
å¤§è¯­è¨€æ¨¡å‹ç”Ÿæˆæ¥æä¾›æ›´å‡†ç¡®ã€æ›´æœ‰ä¾æ®çš„ AI å›ç­”ã€‚

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“Š RAG WORKFLOW æµç¨‹å›¾
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

å·¥ä½œæµç¨‹ï¼š
    [START] â†’ retrieval â†’ enhancement â†’ llm â†’ [END]

èŠ‚ç‚¹è¯´æ˜ï¼š
    - retrieval (_retrieval_node): å‘é‡æ£€ç´¢èŠ‚ç‚¹ï¼Œè·å–ç›¸å…³æ–‡æ¡£
    - enhancement (_context_enhancement_node): ä¸Šä¸‹æ–‡å¢å¼ºèŠ‚ç‚¹ï¼Œæ„å»ºå¢å¼ºæç¤ºè¯
    - llm (_rag_llm_node): LLMç”ŸæˆèŠ‚ç‚¹ï¼Œç”Ÿæˆæœ€ç»ˆå“åº”


â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ”§ æ ¸å¿ƒç»„ä»¶è¯´æ˜
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1. RAGState (TypedDict):
   - æ•´ä¸ªå·¥ä½œæµçš„çŠ¶æ€å®¹å™¨
   - ä½¿ç”¨ total=False å…è®¸éƒ¨åˆ†å­—æ®µæ›´æ–°
   - èŠ‚ç‚¹é—´é€šè¿‡çŠ¶æ€ä¼ é€’æ•°æ®

2. èŠ‚ç‚¹è®¾è®¡åŸåˆ™:
   - è¾“å…¥: RAGState
   - è¾“å‡º: RAGState (éƒ¨åˆ†æ›´æ–°)
   - èŒè´£å•ä¸€: æ¯ä¸ªèŠ‚ç‚¹åªè´Ÿè´£ä¸€ä¸ªæ˜ç¡®çš„ä»»åŠ¡
   - Fail-fast: é‡åˆ°æ— æ³•å¤„ç†çš„æƒ…å†µç«‹å³æŠ›å‡ºå¼‚å¸¸

3. é…ç½®å‚æ•°:
   - min_similarity_threshold: æ§åˆ¶æ£€ç´¢è´¨é‡
   - top_k_documents: æ§åˆ¶æ£€ç´¢æ•°é‡
   - æ”¯æŒè¿è¡Œæ—¶åŠ¨æ€é…ç½® (user_input_state ä¼˜å…ˆçº§æœ€é«˜)

4. é”™è¯¯å¤„ç†:
   - èŠ‚ç‚¹å†…éƒ¨: æ•è·å¹¶è®°å½•é”™è¯¯ï¼Œè¿”å›é™çº§æ•°æ®æˆ–æŠ›å‡ºå¼‚å¸¸
   - æ‰§è¡Œå±‚: ä¸æ•è·å¼‚å¸¸ï¼Œç”±è°ƒç”¨æ–¹å¤„ç†

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“¦ ä¸»è¦ API
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

- create_rag_workflow() -> CompiledStateGraph
    åˆ›å»ºå¹¶ç¼–è¯‘ RAG å·¥ä½œæµçŠ¶æ€å›¾

- execute_rag_workflow(workflow, context, request, llm, retriever, ...) -> List[BaseMessage]
    æ‰§è¡Œ RAG å·¥ä½œæµå¹¶è¿”å› AI å›ç­”
    æ³¨æ„: å¼‚å¸¸ä¼šå‘ä¸Šä¼ æ’­ï¼Œç”±è°ƒç”¨æ–¹å¤„ç†

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

from dotenv import load_dotenv


# åŠ è½½ .env æ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡
load_dotenv()

import traceback
from typing import Annotated, Any, Final, List, Optional
from langchain.schema import AIMessage, HumanMessage
from langchain_core.messages import BaseMessage
from langchain_deepseek import ChatDeepSeek
from langgraph.graph import StateGraph
from langgraph.graph.message import add_messages
from langgraph.graph.state import CompiledStateGraph
from typing_extensions import TypedDict
from loguru import logger

from .document_retriever import DocumentRetriever


############################################################################################################
# é…ç½®å¸¸é‡
############################################################################################################
# ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆä½äºæ­¤å€¼çš„æ–‡æ¡£å°†è¢«è¿‡æ»¤ï¼‰
# æ³¨æ„ï¼šä½¿ç”¨ 1/(1+distance) è½¬æ¢å…¬å¼æ—¶ï¼Œç›¸ä¼¼åº¦é€šå¸¸åœ¨ 0.04-0.15 ä¹‹é—´
# å› æ­¤é˜ˆå€¼è®¾ç½®ä¸º 0.05 è¾ƒä¸ºåˆç†ï¼Œå¯ä»¥è¿‡æ»¤æ‰å®Œå…¨ä¸ç›¸å…³çš„æ–‡æ¡£
DEFAULT_SIMILARITY_SCORE: Final[float] = 0.05

# æ£€ç´¢æ–‡æ¡£æ•°é‡ï¼ˆé¢„ç•™ç»™åç»­çœŸå®æ£€ç´¢ä½¿ç”¨ï¼‰
DEFAULT_RETRIEVAL_LIMIT: Final[int] = 3


############################################################################################################
class RAGState(TypedDict, total=False):
    messages: Annotated[List[BaseMessage], add_messages]
    llm: Optional[ChatDeepSeek]  # DeepSeek LLMå®ä¾‹ï¼Œæ•´ä¸ªRAGæµç¨‹å…±äº«
    document_retriever: Optional[DocumentRetriever]  # æ–‡æ¡£æ£€ç´¢å™¨å®ä¾‹ï¼Œæ”¯æŒä¾èµ–æ³¨å…¥
    retrieved_docs: List[str]  # æ£€ç´¢åˆ°çš„æ–‡æ¡£
    enhanced_context: str  # å¢å¼ºåçš„ä¸Šä¸‹æ–‡
    similarity_scores: List[float]  # ç›¸ä¼¼åº¦åˆ†æ•°ï¼ˆç”¨äºè°ƒè¯•å’Œåˆ†æï¼‰
    min_similarity_threshold: float  # ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆä½äºæ­¤å€¼çš„æ–‡æ¡£å°†è¢«è¿‡æ»¤ï¼‰
    top_k_documents: int  # æ£€ç´¢æ–‡æ¡£æ•°é‡


############################################################################################################
def _extract_user_query(state: RAGState) -> str:
    """ä»æ¶ˆæ¯åˆ—è¡¨ä¸­æå–ç”¨æˆ·æŸ¥è¯¢

    Args:
        state: RAGçŠ¶æ€å¯¹è±¡

    Returns:
        ç”¨æˆ·æŸ¥è¯¢å­—ç¬¦ä¸²ï¼Œå¦‚æœæ— æ³•æå–åˆ™è¿”å›ç©ºå­—ç¬¦ä¸²
    """
    if state.get("messages"):
        last_message = state["messages"][-1]
        if isinstance(last_message, HumanMessage):
            content = last_message.content
            return content if isinstance(content, str) else str(content)
    return ""


############################################################################################################
############################################################################################################
############################################################################################################
def _retrieval_node(state: RAGState) -> RAGState:
    """
    å‘é‡æ£€ç´¢èŠ‚ç‚¹

    åŠŸèƒ½ï¼š
    1. ä½¿ç”¨ Mock æ•°æ®è¿›è¡Œæµ‹è¯•æ£€ç´¢
    2. ç›¸ä¼¼åº¦è¿‡æ»¤å’Œæ’åº
    3. å®Œæ•´çš„é”™è¯¯å¤„ç†å’Œæ—¥å¿—è®°å½•

    Args:
        state: RAGçŠ¶æ€å¯¹è±¡

    Returns:
        æ›´æ–°åçš„ RAGStateï¼ŒåŒ…å«ï¼š
        - retrieved_docs: æ£€ç´¢åˆ°çš„æ–‡æ¡£åˆ—è¡¨
        - similarity_scores: å¯¹åº”çš„ç›¸ä¼¼åº¦åˆ†æ•°åˆ—è¡¨

    Note:
        é€šè¿‡ä¾èµ–æ³¨å…¥çš„ DocumentRetriever è¿›è¡Œæ£€ç´¢ï¼ˆæ”¯æŒ ChromaDBRetriever æˆ– MockDocumentRetrieverï¼‰
    """
    try:
        logger.info("ğŸ” [RETRIEVAL] å¼€å§‹å‘é‡è¯­ä¹‰æ£€ç´¢...")

        # ä»æ¶ˆæ¯åˆ—è¡¨ä¸­æå–ç”¨æˆ·æŸ¥è¯¢
        user_query = _extract_user_query(state)
        logger.info(f"ğŸ” [RETRIEVAL] ç”¨æˆ·æŸ¥è¯¢: {user_query}")

        # ä»çŠ¶æ€ä¸­è·å–é…ç½®å€¼ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤å€¼
        min_threshold = state.get("min_similarity_threshold", DEFAULT_SIMILARITY_SCORE)
        top_k = state.get("top_k_documents", DEFAULT_RETRIEVAL_LIMIT)

        logger.info(
            f"ğŸ” [RETRIEVAL] ä½¿ç”¨é…ç½® - ç›¸ä¼¼åº¦é˜ˆå€¼: {min_threshold}, Top-K: {top_k}"
        )

        # è·å–æ–‡æ¡£æ£€ç´¢å™¨å®ä¾‹ï¼ˆä¸¥æ ¼æ£€æŸ¥ï¼Œå¿…é¡»æä¾›ï¼‰
        document_retriever = state.get("document_retriever")
        if document_retriever is None:
            error_msg = (
                "ğŸ” [RETRIEVAL] ä¸¥é‡é”™è¯¯: æœªæä¾› DocumentRetriever å®ä¾‹ï¼\n"
                "RAG å·¥ä½œæµå¿…é¡»æ³¨å…¥ DocumentRetriever å®ä¾‹æ‰èƒ½è¿è¡Œã€‚\n"
                "è¯·åœ¨è°ƒç”¨ execute_rag_workflow æ—¶æä¾› 'document_retriever' å‚æ•°ã€‚"
            )
            logger.error(error_msg)
            raise ValueError(
                "DocumentRetriever is required but not provided in RAGState. "
                "Please inject a DocumentRetriever instance (e.g., ChromaDBRetriever or MockDocumentRetriever) "
                "when calling execute_rag_workflow."
            )

        # ä½¿ç”¨æ³¨å…¥çš„æ£€ç´¢å™¨å®ä¾‹
        logger.info(f"ğŸ” [RETRIEVAL] ä½¿ç”¨æ£€ç´¢å™¨: {type(document_retriever).__name__}")
        retrieved_docs, similarity_scores = document_retriever.retrieve_documents(
            user_query=user_query, top_k=top_k, min_similarity=min_threshold
        )

        # è¿‡æ»¤ä½ç›¸ä¼¼åº¦ç»“æœ
        filtered_docs = []
        filtered_scores = []

        for doc, score in zip(retrieved_docs, similarity_scores):
            if score >= min_threshold:
                filtered_docs.append(doc)
                filtered_scores.append(score)

        # å¦‚æœè¿‡æ»¤åæ²¡æœ‰æ–‡æ¡£ï¼Œè‡³å°‘ä¿ç•™æœ€é«˜åˆ†çš„æ–‡æ¡£
        if not filtered_docs and retrieved_docs:
            filtered_docs = [retrieved_docs[0]]
            filtered_scores = [similarity_scores[0]]
            logger.info(
                f"ğŸ” [RETRIEVAL] æ‰€æœ‰ç»“æœä½äºé˜ˆå€¼({min_threshold})ï¼Œ"
                f"ä¿ç•™æœ€é«˜åˆ†æ–‡æ¡£ (ç›¸ä¼¼åº¦: {similarity_scores[0]:.3f})"
            )

        logger.success(f"ğŸ” [RETRIEVAL] æ£€ç´¢å®Œæˆï¼Œå…±è¿”å› {len(filtered_docs)} ä¸ªæ–‡æ¡£")

        # è®°å½•è¯¦ç»†ä¿¡æ¯
        for i, (doc, score) in enumerate(zip(filtered_docs, filtered_scores), 1):
            logger.info(f"  ğŸ“„ [{i}] ç›¸ä¼¼åº¦: {score:.3f}, å†…å®¹: {doc[:60]}...")

        return {
            "retrieved_docs": filtered_docs,
            "similarity_scores": filtered_scores,
        }

    except Exception as e:
        logger.error(f"ğŸ” [RETRIEVAL] æ£€ç´¢èŠ‚ç‚¹é”™è¯¯: {e}\n{traceback.format_exc()}")
        return {
            "retrieved_docs": ["æ£€ç´¢è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ï¼Œå°†ä½¿ç”¨é»˜è®¤å›å¤ã€‚"],
            "similarity_scores": [0.0],
        }


############################################################################################################
def _context_enhancement_node(state: RAGState) -> RAGState:
    """
    ä¸Šä¸‹æ–‡å¢å¼ºèŠ‚ç‚¹ï¼ˆæ”¯æŒç›¸ä¼¼åº¦ä¿¡æ¯ï¼‰

    åŠŸèƒ½å¢å¼ºï¼š
    1. ä¿æŒåŸæœ‰çš„ä¸Šä¸‹æ–‡æ„å»ºé€»è¾‘
    2. æ·»åŠ ç›¸ä¼¼åº¦åˆ†æ•°ä¿¡æ¯åˆ°ä¸Šä¸‹æ–‡ä¸­
    3. æä¾›æ›´ä¸°å¯Œçš„æ£€ç´¢è´¨é‡ä¿¡æ¯
    4. ä¸ºLLMæä¾›æ›´å¥½çš„å‚è€ƒä¾æ®

    Args:
        state: RAGçŠ¶æ€å¯¹è±¡

    Returns:
        æ›´æ–°åçš„ RAGStateï¼ŒåŒ…å«ï¼š
        - enhanced_context: å¢å¼ºåçš„ä¸Šä¸‹æ–‡
    """
    try:
        logger.info("ğŸ“ [ENHANCEMENT] å¼€å§‹å¢å¼ºä¸Šä¸‹æ–‡...")

        # ä»æ¶ˆæ¯åˆ—è¡¨ä¸­æå–ç”¨æˆ·æŸ¥è¯¢
        user_query = _extract_user_query(state)
        retrieved_docs = state.get("retrieved_docs", [])
        similarity_scores = state.get("similarity_scores", [])

        logger.info(f"ğŸ“ [ENHANCEMENT] å¤„ç†æŸ¥è¯¢: {user_query}")
        logger.info(f"ğŸ“ [ENHANCEMENT] æ£€ç´¢åˆ°çš„æ–‡æ¡£æ•°é‡: {len(retrieved_docs)}")

        if similarity_scores:
            avg_similarity = sum(similarity_scores) / len(similarity_scores)
            max_similarity = max(similarity_scores)
            logger.info(
                f"ğŸ“ [ENHANCEMENT] å¹³å‡ç›¸ä¼¼åº¦: {avg_similarity:.3f}, æœ€é«˜ç›¸ä¼¼åº¦: {max_similarity:.3f}"
            )

        # æ„å»ºæ–‡æ¡£åˆ—è¡¨ï¼ˆæŒ‰ç›¸ä¼¼åº¦æ’åºï¼‰
        doc_list_items = []
        if similarity_scores and len(similarity_scores) == len(retrieved_docs):
            # å°†æ–‡æ¡£å’Œç›¸ä¼¼åº¦åˆ†æ•°é…å¯¹ï¼Œå¹¶æŒ‰ç›¸ä¼¼åº¦é™åºæ’åº
            doc_score_pairs = list(zip(retrieved_docs, similarity_scores))
            doc_score_pairs.sort(key=lambda x: x[1], reverse=True)

            for i, (doc, score) in enumerate(doc_score_pairs, 1):
                doc_list_items.append(f"{i}. [ç›¸ä¼¼åº¦: {score:.3f}] {doc}")
        else:
            # å›é€€åˆ°åŸæ¥çš„æ ¼å¼ï¼ˆæ²¡æœ‰ç›¸ä¼¼åº¦ä¿¡æ¯ï¼‰
            for i, doc in enumerate(retrieved_docs, 1):
                doc_list_items.append(f"{i}. {doc}")

        docs_section = "\n".join(doc_list_items)

        # ä½¿ç”¨ f-string å¤šè¡Œå­—ç¬¦ä¸²æ„å»ºå¢å¼ºä¸Šä¸‹æ–‡
        enhanced_context = f"""è¯·åŸºäºä»¥ä¸‹ç›¸å…³ä¿¡æ¯å“åº”ç”¨æˆ·:

ç›¸å…³ä¿¡æ¯ (æŒ‰ç›¸ä¼¼åº¦æ’åº):
{docs_section}

ç”¨æˆ·è¾“å…¥: {user_query}

## å“åº”è¦æ±‚
- åŸºäºä¸Šè¿°ç›¸å…³ä¿¡æ¯ç»™å‡ºå‡†ç¡®ã€æœ‰å¸®åŠ©çš„å“åº”
- å¯¹äºç¡®å®šçš„ä¿¡æ¯ï¼Œç›´æ¥è‡ªä¿¡åœ°è¡¨è¾¾
- å¯¹äºä¸ç¡®å®šæˆ–ä¿¡æ¯ä¸è¶³çš„éƒ¨åˆ†ï¼Œè¯šå®è¯´æ˜
- ç”¨æˆ·çš„è¾“å…¥å¯èƒ½æ˜¯é—®é¢˜ã€æŒ‡ä»¤ã€å¯¹è¯ã€ä¿¡æ¯æˆ–è¡ŒåŠ¨æè¿°ç­‰ï¼Œè¯·æ ¹æ®ä¸Šä¸‹æ–‡çµæ´»å¤„ç†

## å“åº”åŸåˆ™
âœ… å†…å®¹å±‚é¢ï¼šä¿æŒä½ çš„è§’è‰²è®¾å®šå’Œè¯­è¨€é£æ ¼ï¼ˆåŸºäºå†å²ä¸Šä¸‹æ–‡å’Œè§’è‰²äººæ ¼ï¼‰
âœ… æ ¼å¼å±‚é¢ï¼šå¦‚æœç”¨æˆ·åœ¨æœ€æ–°è¾“å…¥ä¸­æ˜ç¡®è¦æ±‚ç‰¹å®šæ ¼å¼ï¼ˆå¦‚JSONã€Markdownã€è¡¨æ ¼ç­‰ï¼‰ï¼Œè¯·ä¸¥æ ¼æŒ‰ç…§è¦æ±‚è¾“å‡º"""

        logger.info("ğŸ“ [ENHANCEMENT] ä¸Šä¸‹æ–‡å¢å¼ºå®Œæˆ")
        logger.debug(f"ğŸ“ [ENHANCEMENT] å¢å¼ºåçš„ä¸Šä¸‹æ–‡:\n{enhanced_context}")

        return {"enhanced_context": enhanced_context}

    except Exception as e:
        logger.error(
            f"ğŸ“ [ENHANCEMENT] ä¸Šä¸‹æ–‡å¢å¼ºèŠ‚ç‚¹é”™è¯¯: {e}\n{traceback.format_exc()}"
        )
        # ä»æ¶ˆæ¯åˆ—è¡¨ä¸­æå–ç”¨æˆ·æŸ¥è¯¢ï¼ˆç”¨äº fallbackï¼‰
        user_query = _extract_user_query(state)
        fallback_context = f"è¯·å“åº”ç”¨æˆ·ä»¥ä¸‹è¾“å…¥: {user_query}\n\næ³¨æ„ï¼šç”±äºæ£€ç´¢æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·åŸºäºä½ çš„çŸ¥è¯†å›ç­”ã€‚"
        return {"enhanced_context": fallback_context}


############################################################################################################
def _rag_llm_node(state: RAGState) -> RAGState:
    """
    RAGç‰ˆæœ¬çš„LLMèŠ‚ç‚¹

    åŠŸèƒ½ï¼š
    ä½¿ç”¨å¢å¼ºåçš„ä¸Šä¸‹æ–‡è°ƒç”¨ DeepSeek LLM ç”Ÿæˆå›ç­”

    Args:
        state: RAGçŠ¶æ€å¯¹è±¡

    Returns:
        æ›´æ–°åçš„ RAGStateï¼ŒåŒ…å«ï¼š
        - messages: åŒ…å«LLMç”Ÿæˆçš„å›ç­”æ¶ˆæ¯
    """
    try:
        logger.info("ğŸ¤– [LLM] å¼€å§‹ç”Ÿæˆå›ç­”...")

        # ä½¿ç”¨çŠ¶æ€ä¸­çš„ DeepSeek LLM å®ä¾‹
        llm = state["llm"]
        assert llm is not None, "LLM instance is None in state"

        # ä½¿ç”¨å¢å¼ºçš„ä¸Šä¸‹æ–‡æ›¿æ¢åŸå§‹æ¶ˆæ¯
        enhanced_context = state.get("enhanced_context", "")
        if not enhanced_context:
            error_msg = "ğŸ¤– [LLM] å¢å¼ºä¸Šä¸‹æ–‡ä¸ºç©ºï¼ŒRAGæµç¨‹å¼‚å¸¸ï¼Œæ— æ³•ç»§ç»­"
            logger.error(error_msg)
            raise ValueError(
                "Enhanced context is empty. RAG workflow failed in context enhancement node."
            )

        # åˆ›å»ºå¢å¼ºæ¶ˆæ¯
        enhanced_message = HumanMessage(content=enhanced_context)

        # æ„å»ºå®Œæ•´æ¶ˆæ¯åˆ—è¡¨ï¼šå†å²æ¶ˆæ¯ï¼ˆæ’é™¤æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯ï¼‰+ å¢å¼ºæ¶ˆæ¯
        history_messages = state.get("messages", [])[:-1]
        full_messages = history_messages + [enhanced_message]

        logger.info("ğŸ¤– [LLM] ä½¿ç”¨å®Œæ•´å¯¹è¯ä¸Šä¸‹æ–‡è°ƒç”¨DeepSeek")

        # è°ƒç”¨LLM
        response = llm.invoke(full_messages)
        logger.success("ğŸ¤– [LLM] DeepSeekå›ç­”ç”Ÿæˆå®Œæˆ")

        return {"messages": [response]}

    except Exception as e:
        logger.error(f"ğŸ¤– [LLM] LLMèŠ‚ç‚¹é”™è¯¯: {e}\n{traceback.format_exc()}")
        error_response = AIMessage(content="æŠ±æ­‰ï¼Œç”Ÿæˆå›ç­”æ—¶å‘ç”Ÿé”™è¯¯ï¼Œè¯·ç¨åé‡è¯•ã€‚")
        return {"messages": [error_response]}


############################################################################################################
def create_rag_workflow() -> CompiledStateGraph[RAGState, Any, RAGState, RAGState]:
    """åˆ›å»ºRAGæµ‹è¯•ç‰ˆæœ¬çš„çŠ¶æ€å›¾"""
    # åˆ›å»ºçŠ¶æ€å›¾
    graph_builder = StateGraph(RAGState)

    # æ·»åŠ ä¸‰ä¸ªèŠ‚ç‚¹
    graph_builder.add_node("retrieval", _retrieval_node)
    graph_builder.add_node("enhancement", _context_enhancement_node)
    graph_builder.add_node("llm", _rag_llm_node)

    # è®¾ç½®èŠ‚ç‚¹æµç¨‹: retrieval â†’ enhancement â†’ llm
    graph_builder.add_edge("retrieval", "enhancement")
    graph_builder.add_edge("enhancement", "llm")

    # è®¾ç½®å…¥å£å’Œå‡ºå£ç‚¹
    graph_builder.set_entry_point("retrieval")
    graph_builder.set_finish_point("llm")

    compiled_graph = graph_builder.compile()
    logger.success("ğŸ—ï¸ RAGçŠ¶æ€å›¾æ„å»ºå®Œæˆ")

    # æ˜ç¡®ç±»å‹è½¬æ¢ä»¥æ»¡è¶³mypyè¦æ±‚
    return compiled_graph  # type: ignore[return-value]


############################################################################################################
async def execute_rag_workflow(
    work_flow: CompiledStateGraph[RAGState, Any, RAGState, RAGState],
    context: List[BaseMessage],
    request: HumanMessage,
    llm: ChatDeepSeek,
    document_retriever: DocumentRetriever,
    min_similarity_threshold: float = DEFAULT_SIMILARITY_SCORE,
    top_k_documents: int = DEFAULT_RETRIEVAL_LIMIT,
) -> List[BaseMessage]:
    """æ‰§è¡ŒRAGå·¥ä½œæµå¹¶è¿”å›æ‰€æœ‰å“åº”æ¶ˆæ¯

    å°†èŠå¤©å†å²å’Œç”¨æˆ·è¾“å…¥åˆå¹¶åï¼Œé€šè¿‡ç¼–è¯‘å¥½çš„çŠ¶æ€å›¾è¿›è¡ŒRAGæ£€ç´¢å¢å¼ºå¤„ç†ï¼Œ
    æ”¶é›†å¹¶è¿”å›æ‰€æœ‰ç”Ÿæˆçš„æ¶ˆæ¯ã€‚RAGState çš„åˆ›å»ºè¢«å°è£…åœ¨å‡½æ•°å†…éƒ¨ã€‚

    Args:
        work_flow: å·²ç¼–è¯‘çš„ LangGraph çŠ¶æ€å›¾
        context: å†å²æ¶ˆæ¯åˆ—è¡¨
        request: ç”¨æˆ·å½“å‰è¾“å…¥çš„æ¶ˆæ¯
        llm: ChatDeepSeek LLM å®ä¾‹
        document_retriever: æ–‡æ¡£æ£€ç´¢å™¨å®ä¾‹
        min_similarity_threshold: ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆé»˜è®¤ä½¿ç”¨å…¨å±€é…ç½® MIN_SIMILARITY_THRESHOLDï¼‰
        top_k_documents: æ£€ç´¢æ–‡æ¡£æ•°é‡ï¼ˆé»˜è®¤ä½¿ç”¨å…¨å±€é…ç½® TOP_K_DOCUMENTSï¼‰

    Returns:
        åŒ…å«æ‰€æœ‰ç”Ÿæˆæ¶ˆæ¯çš„åˆ—è¡¨

    Raises:
        ä»»ä½•åœ¨RAGæµç¨‹ä¸­å‘ç”Ÿçš„å¼‚å¸¸éƒ½ä¼šå‘ä¸Šä¼ æ’­ï¼Œç”±è°ƒç”¨æ–¹å¤„ç†
    """
    logger.info("ğŸš€ å¼€å§‹æ‰§è¡ŒRAGæµç¨‹...")

    # åœ¨å†…éƒ¨æ„é€  RAGStateï¼ˆå°è£…å®ç°ç»†èŠ‚ï¼‰
    rag_state: RAGState = {
        "messages": context + [request],
        "retrieved_docs": [],
        "enhanced_context": "",
        "similarity_scores": [],
        "llm": llm,
        "document_retriever": document_retriever,
        "min_similarity_threshold": min_similarity_threshold,
        "top_k_documents": top_k_documents,
    }

    logger.info(f"ğŸš€ RAGè¾“å…¥çŠ¶æ€å‡†å¤‡å®Œæˆï¼Œç”¨æˆ·æŸ¥è¯¢: {request.content}")

    # æ‰§è¡ŒRAGæµç¨‹
    ret: List[BaseMessage] = []
    async for event in work_flow.astream(rag_state):
        logger.debug(f"ğŸš€ RAGæµç¨‹äº‹ä»¶: {list(event.keys())}")
        for node_name, node_output in event.items():
            if "messages" in node_output:
                ret.extend(node_output["messages"])
                logger.info(
                    f"ğŸš€ èŠ‚ç‚¹ [{node_name}] è¾“å‡ºæ¶ˆæ¯æ•°é‡: {len(node_output['messages'])}"
                )

    logger.success("ğŸš€ RAGæµç¨‹æ‰§è¡Œå®Œæˆ")
    return ret


############################################################################################################
