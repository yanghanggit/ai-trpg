"""
RAG (Retrieval-Augmented Generation) å·¥ä½œæµå®ç°

åŸºäº LangGraph çš„ RAG æ£€ç´¢å¢å¼ºç”Ÿæˆå·¥ä½œæµ,ç»“åˆå‘é‡æ£€ç´¢å’Œ LLM ç”Ÿæˆæä¾›å‡†ç¡®å›ç­”ã€‚

å·¥ä½œæµç¨‹:
    [START] â†’ retrieval â†’ enhancement â†’ llm â†’ [END]

æ ¸å¿ƒç‰¹æ€§:
    - ä¸‰é˜¶æ®µå¤„ç†: æ£€ç´¢ â†’ ä¸Šä¸‹æ–‡å¢å¼º â†’ LLMç”Ÿæˆ
    - å®Œæ•´æ¶ˆæ¯ä¸Šä¸‹æ–‡: messages ä¿ç•™æ‰€æœ‰å†å²å¯¹è¯
    - å¤–å±‚é”™è¯¯å¤„ç†: èŠ‚ç‚¹ä¸“æ³¨ä¸šåŠ¡é€»è¾‘,å¼‚å¸¸ç”±æ‰§è¡Œå±‚ç»Ÿä¸€å¤„ç†
    - å“åº”è¿½è¸ª: llm_response å­—æ®µè®°å½•æœ€ç»ˆ AI å“åº”

ä¸»è¦ API:
    - create_rag_workflow(): åˆ›å»ºå¹¶ç¼–è¯‘å·¥ä½œæµçŠ¶æ€å›¾
    - execute_rag_workflow(): æ‰§è¡Œå·¥ä½œæµå¹¶è¿”å› AI å“åº”
"""

from dotenv import load_dotenv


# åŠ è½½ .env æ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡
load_dotenv()

import traceback
from typing import Annotated, Any, Final, List, Optional
from langchain.schema import AIMessage, HumanMessage
from langchain_core.messages import BaseMessage
from langchain_deepseek import ChatDeepSeek
from langgraph.graph import StateGraph
from langgraph.graph.message import add_messages
from langgraph.graph.state import CompiledStateGraph
from typing_extensions import TypedDict
from loguru import logger

from .document_retriever import DocumentRetriever


############################################################################################################
# é…ç½®å¸¸é‡
############################################################################################################
# ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆä½äºæ­¤å€¼çš„æ–‡æ¡£å°†è¢«è¿‡æ»¤ï¼‰
# æ³¨æ„ï¼šä½¿ç”¨ 1/(1+distance) è½¬æ¢å…¬å¼æ—¶ï¼Œç›¸ä¼¼åº¦é€šå¸¸åœ¨ 0.04-0.15 ä¹‹é—´
# å› æ­¤é˜ˆå€¼è®¾ç½®ä¸º 0.05 è¾ƒä¸ºåˆç†ï¼Œå¯ä»¥è¿‡æ»¤æ‰å®Œå…¨ä¸ç›¸å…³çš„æ–‡æ¡£
DEFAULT_SIMILARITY_SCORE: Final[float] = 0.05

# æ£€ç´¢æ–‡æ¡£æ•°é‡ï¼ˆé¢„ç•™ç»™åç»­çœŸå®æ£€ç´¢ä½¿ç”¨ï¼‰
DEFAULT_RETRIEVAL_LIMIT: Final[int] = 3


############################################################################################################
class RAGState(TypedDict, total=False):
    """RAG å·¥ä½œæµçŠ¶æ€å®šä¹‰

    Attributes:
        messages: å®Œæ•´æ¶ˆæ¯åˆ—è¡¨(å†å²+å½“å‰),ä½¿ç”¨ add_messages è‡ªåŠ¨åˆå¹¶
        llm: DeepSeek LLM å®ä¾‹
        document_retriever: æ–‡æ¡£æ£€ç´¢å™¨å®ä¾‹
        retrieved_docs: æ£€ç´¢åˆ°çš„æ–‡æ¡£åˆ—è¡¨
        enhanced_context: å¢å¼ºåçš„ä¸Šä¸‹æ–‡æç¤ºè¯
        similarity_scores: æ–‡æ¡£ç›¸ä¼¼åº¦åˆ†æ•°
        similarity_threshold: ç›¸ä¼¼åº¦è¿‡æ»¤é˜ˆå€¼
        retrieval_limit: æ£€ç´¢æ–‡æ¡£æ•°é‡ä¸Šé™
        llm_response: LLM ç”Ÿæˆçš„å“åº”æ¶ˆæ¯
    """

    messages: Annotated[List[BaseMessage], add_messages]
    llm: ChatDeepSeek
    document_retriever: DocumentRetriever
    retrieved_docs: List[str]
    enhanced_context: str
    similarity_scores: List[float]
    similarity_threshold: float
    retrieval_limit: int
    llm_response: AIMessage


############################################################################################################
def _retrieval_node(state: RAGState) -> RAGState:
    """å‘é‡æ£€ç´¢èŠ‚ç‚¹

    ä»æ–‡æ¡£åº“ä¸­æ£€ç´¢ä¸ç”¨æˆ·æŸ¥è¯¢ç›¸å…³çš„æ–‡æ¡£,å¹¶æŒ‰ç›¸ä¼¼åº¦è¿‡æ»¤å’Œæ’åºã€‚

    Args:
        state: RAGçŠ¶æ€å¯¹è±¡

    Returns:
        æ›´æ–°åçš„çŠ¶æ€,åŒ…å« retrieved_docs å’Œ similarity_scores
    """
    logger.info("ğŸ” [RETRIEVAL] å¼€å§‹å‘é‡è¯­ä¹‰æ£€ç´¢...")

    # æå–ç”¨æˆ·æŸ¥è¯¢
    messages = state.get("messages", [])
    assert len(messages) > 0, "æ¶ˆæ¯åˆ—è¡¨ä¸èƒ½ä¸ºç©º"
    if not messages:
        logger.warning("ğŸ” [RETRIEVAL] æ¶ˆæ¯åˆ—è¡¨ä¸ºç©º")
        return {
            "messages": [],
            "retrieved_docs": [],
            "similarity_scores": [],
        }

    last_message = messages[-1]
    assert isinstance(
        last_message, HumanMessage
    ), "æœ€åä¸€æ¡æ¶ˆæ¯å¿…é¡»æ˜¯ HumanMessage ç±»å‹"
    user_query = str(last_message.content)
    logger.info(f"ğŸ” [RETRIEVAL] ç”¨æˆ·æŸ¥è¯¢: {user_query}")

    # ä»çŠ¶æ€ä¸­è·å–é…ç½®å€¼ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤å€¼
    min_threshold = state.get("similarity_threshold", DEFAULT_SIMILARITY_SCORE)
    top_k = state.get("retrieval_limit", DEFAULT_RETRIEVAL_LIMIT)

    logger.info(
        f"ğŸ” [RETRIEVAL] ä½¿ç”¨é…ç½® - ç›¸ä¼¼åº¦é˜ˆå€¼: {min_threshold}, Top-K: {top_k}"
    )

    # è·å–æ–‡æ¡£æ£€ç´¢å™¨å®ä¾‹
    document_retriever = state["document_retriever"]
    logger.info(f"ğŸ” [RETRIEVAL] ä½¿ç”¨æ£€ç´¢å™¨: {type(document_retriever).__name__}")

    retrieved_docs, similarity_scores = document_retriever.retrieve_documents(
        user_query=user_query, top_k=top_k, min_similarity=min_threshold
    )

    # è¿‡æ»¤ä½ç›¸ä¼¼åº¦ç»“æœ
    filtered_docs = []
    filtered_scores = []

    for doc, score in zip(retrieved_docs, similarity_scores):
        if score >= min_threshold:
            filtered_docs.append(doc)
            filtered_scores.append(score)

    # å¦‚æœè¿‡æ»¤åæ²¡æœ‰æ–‡æ¡£ï¼Œè‡³å°‘ä¿ç•™æœ€é«˜åˆ†çš„æ–‡æ¡£
    if not filtered_docs and retrieved_docs:
        filtered_docs = [retrieved_docs[0]]
        filtered_scores = [similarity_scores[0]]
        logger.info(
            f"ğŸ” [RETRIEVAL] æ‰€æœ‰ç»“æœä½äºé˜ˆå€¼({min_threshold})ï¼Œ"
            f"ä¿ç•™æœ€é«˜åˆ†æ–‡æ¡£ (ç›¸ä¼¼åº¦: {similarity_scores[0]:.3f})"
        )

    logger.success(f"ğŸ” [RETRIEVAL] æ£€ç´¢å®Œæˆï¼Œå…±è¿”å› {len(filtered_docs)} ä¸ªæ–‡æ¡£")

    # è®°å½•è¯¦ç»†ä¿¡æ¯
    for i, (doc, score) in enumerate(zip(filtered_docs, filtered_scores), 1):
        logger.info(f"  ğŸ“„ [{i}] ç›¸ä¼¼åº¦: {score:.3f}, å†…å®¹: {doc[:60]}...")

    # âœ… ä¿æŒæ‰€æœ‰å¿…è¦å­—æ®µï¼Œç¡®ä¿çŠ¶æ€å®Œæ•´ä¼ é€’åˆ°ä¸‹ä¸€ä¸ªèŠ‚ç‚¹
    return {
        "messages": state.get("messages", []),
        "llm": state["llm"],
        "document_retriever": state["document_retriever"],
        "similarity_threshold": state.get(
            "similarity_threshold", DEFAULT_SIMILARITY_SCORE
        ),
        "retrieval_limit": state.get("retrieval_limit", DEFAULT_RETRIEVAL_LIMIT),
        "retrieved_docs": filtered_docs,  # æ–°å¢å­—æ®µ
        "similarity_scores": filtered_scores,  # æ–°å¢å­—æ®µ
    }


############################################################################################################
def _context_enhancement_node(state: RAGState) -> RAGState:
    """ä¸Šä¸‹æ–‡å¢å¼ºèŠ‚ç‚¹

    å°†æ£€ç´¢åˆ°çš„æ–‡æ¡£å’Œç›¸ä¼¼åº¦ä¿¡æ¯æ„å»ºä¸ºç»“æ„åŒ–çš„å¢å¼ºæç¤ºè¯ã€‚

    Args:
        state: RAGçŠ¶æ€å¯¹è±¡

    Returns:
        æ›´æ–°åçš„çŠ¶æ€,åŒ…å« enhanced_context
    """
    logger.info("ğŸ“ [ENHANCEMENT] å¼€å§‹å¢å¼ºä¸Šä¸‹æ–‡...")

    # ä»æ¶ˆæ¯åˆ—è¡¨ä¸­æå–ç”¨æˆ·æŸ¥è¯¢
    retrieved_docs = state.get("retrieved_docs", [])
    similarity_scores = state.get("similarity_scores", [])

    # æ„å»ºæ–‡æ¡£åˆ—è¡¨ï¼ˆæŒ‰ç›¸ä¼¼åº¦æ’åºï¼‰
    doc_list_items = []
    if similarity_scores and len(similarity_scores) == len(retrieved_docs):
        # å°†æ–‡æ¡£å’Œç›¸ä¼¼åº¦åˆ†æ•°é…å¯¹ï¼Œå¹¶æŒ‰ç›¸ä¼¼åº¦é™åºæ’åº
        doc_score_pairs = list(zip(retrieved_docs, similarity_scores))
        doc_score_pairs.sort(key=lambda x: x[1], reverse=True)

        for i, (doc, score) in enumerate(doc_score_pairs, 1):
            doc_list_items.append(f"{i}. [ç›¸ä¼¼åº¦: {score:.3f}] {doc}")
    else:
        # å›é€€åˆ°åŸæ¥çš„æ ¼å¼ï¼ˆæ²¡æœ‰ç›¸ä¼¼åº¦ä¿¡æ¯ï¼‰
        for i, doc in enumerate(retrieved_docs, 1):
            doc_list_items.append(f"{i}. {doc}")

    docs_section = "\n".join(doc_list_items)

    enhanced_context = f"""# æ ¹æ®ç”¨æˆ·è¾“å…¥ï¼ŒæŸ¥è¯¢åˆ°ä»¥ä¸‹ç›¸å…³ä¿¡æ¯ï¼š

{docs_section}

## å“åº”è¦æ±‚

- åŸºäºä¸Šè¿°ç›¸å…³ä¿¡æ¯ç»™å‡ºå‡†ç¡®ã€æœ‰å¸®åŠ©çš„å“åº”
- å¯¹äºç¡®å®šçš„ä¿¡æ¯ï¼Œç›´æ¥è‡ªä¿¡åœ°è¡¨è¾¾
- å¯¹äºä¸ç¡®å®šæˆ–ä¿¡æ¯ä¸è¶³çš„éƒ¨åˆ†ï¼Œè¯šå®è¯´æ˜
- ç”¨æˆ·çš„è¾“å…¥å¯èƒ½æ˜¯é—®é¢˜ã€æŒ‡ä»¤ã€å¯¹è¯ã€ä¿¡æ¯æˆ–è¡ŒåŠ¨æè¿°ç­‰ï¼Œè¯·æ ¹æ®ä¸Šä¸‹æ–‡çµæ´»å¤„ç†

## å“åº”åŸåˆ™

âœ… å†…å®¹å±‚é¢ï¼šä¿æŒä½ çš„è§’è‰²è®¾å®šå’Œè¯­è¨€é£æ ¼ï¼ˆåŸºäºå†å²ä¸Šä¸‹æ–‡å’Œè§’è‰²äººæ ¼ï¼‰
âœ… æ ¼å¼å±‚é¢ï¼šå¦‚æœç”¨æˆ·åœ¨æœ€æ–°è¾“å…¥ä¸­æ˜ç¡®è¦æ±‚ç‰¹å®šæ ¼å¼ï¼ˆå¦‚JSONã€Markdownã€è¡¨æ ¼ç­‰ï¼‰ï¼Œè¯·ä¸¥æ ¼æŒ‰ç…§è¦æ±‚è¾“å‡º"""

    logger.info("ğŸ“ [ENHANCEMENT] ä¸Šä¸‹æ–‡å¢å¼ºå®Œæˆ")

    # âœ… ä¿æŒæ‰€æœ‰å¿…è¦å­—æ®µï¼Œç¡®ä¿çŠ¶æ€å®Œæ•´ä¼ é€’åˆ°ä¸‹ä¸€ä¸ªèŠ‚ç‚¹
    return {
        "messages": state.get("messages", []),
        "llm": state["llm"],
        "document_retriever": state["document_retriever"],
        "retrieved_docs": state.get("retrieved_docs", []),
        "similarity_scores": state.get("similarity_scores", []),
        "similarity_threshold": state.get(
            "similarity_threshold", DEFAULT_SIMILARITY_SCORE
        ),
        "retrieval_limit": state.get("retrieval_limit", DEFAULT_RETRIEVAL_LIMIT),
        "enhanced_context": enhanced_context,  # æ–°å¢å­—æ®µ
    }


############################################################################################################
def _rag_llm_node(state: RAGState) -> RAGState:
    """LLM ç”ŸæˆèŠ‚ç‚¹

    ä½¿ç”¨å®Œæ•´å¯¹è¯ä¸Šä¸‹æ–‡(messages)å’Œå¢å¼ºä¿¡æ¯è°ƒç”¨ DeepSeek LLM ç”Ÿæˆå“åº”ã€‚

    Args:
        state: RAGçŠ¶æ€å¯¹è±¡

    Returns:
        æ›´æ–°åçš„çŠ¶æ€,åŒ…å« messages å’Œ llm_response
    """
    logger.info("ğŸ¤– [LLM] å¼€å§‹ç”Ÿæˆå›ç­”...")

    # ä½¿ç”¨çŠ¶æ€ä¸­çš„ DeepSeek LLM å®ä¾‹
    llm = state["llm"]

    # éªŒè¯å¢å¼ºä¸Šä¸‹æ–‡
    enhanced_context = state.get("enhanced_context", "")
    if not enhanced_context:
        logger.error("ğŸ¤– [LLM] å¢å¼ºä¸Šä¸‹æ–‡ä¸ºç©ºï¼ŒRAGæµç¨‹å¼‚å¸¸ï¼Œæ— æ³•ç»§ç»­")
        raise ValueError(
            "Enhanced context is empty. RAG workflow failed in context enhancement node."
        )

    # æ„å»ºå®Œæ•´æ¶ˆæ¯åˆ—è¡¨: ä¿ç•™æ‰€æœ‰å†å²æ¶ˆæ¯(messages) + å¢å¼ºä¿¡æ¯
    enhanced_message = HumanMessage(content=enhanced_context)
    full_messages = state.get("messages", []) + [enhanced_message]

    logger.info("ğŸ¤– [LLM] ä½¿ç”¨å®Œæ•´å¯¹è¯ä¸Šä¸‹æ–‡è°ƒç”¨DeepSeek")

    # è°ƒç”¨LLM
    response = llm.invoke(full_messages)
    assert isinstance(response, AIMessage), "LLMå“åº”å¿…é¡»æ˜¯ AIMessage ç±»å‹"
    logger.success("ğŸ¤– [LLM] DeepSeekå›ç­”ç”Ÿæˆå®Œæˆ")

    # âœ… ä¿æŒæ‰€æœ‰å¿…è¦å­—æ®µï¼Œç¡®ä¿çŠ¶æ€å®Œæ•´ä¼ é€’åˆ°ç»ˆç‚¹
    return {
        "messages": [response],  # add_messages ä¼šè‡ªåŠ¨åˆå¹¶
        "llm": llm,
        "document_retriever": state["document_retriever"],
        "retrieved_docs": state.get("retrieved_docs", []),
        "enhanced_context": state.get("enhanced_context", ""),
        "similarity_scores": state.get("similarity_scores", []),
        "similarity_threshold": state.get(
            "similarity_threshold", DEFAULT_SIMILARITY_SCORE
        ),
        "retrieval_limit": state.get("retrieval_limit", DEFAULT_RETRIEVAL_LIMIT),
        "llm_response": response,  # æ–°å¢å­—æ®µ
    }


############################################################################################################
def create_rag_workflow() -> CompiledStateGraph[RAGState, Any, RAGState, RAGState]:
    """åˆ›å»ºå¹¶ç¼–è¯‘ RAG å·¥ä½œæµçŠ¶æ€å›¾"""
    graph_builder = StateGraph(RAGState)

    # æ·»åŠ ä¸‰ä¸ªèŠ‚ç‚¹
    graph_builder.add_node("retrieval", _retrieval_node)
    graph_builder.add_node("enhancement", _context_enhancement_node)
    graph_builder.add_node("llm", _rag_llm_node)

    # è®¾ç½®èŠ‚ç‚¹æµç¨‹: retrieval â†’ enhancement â†’ llm
    graph_builder.add_edge("retrieval", "enhancement")
    graph_builder.add_edge("enhancement", "llm")

    # è®¾ç½®å…¥å£å’Œå‡ºå£ç‚¹
    graph_builder.set_entry_point("retrieval")
    graph_builder.set_finish_point("llm")

    compiled_graph = graph_builder.compile()
    logger.success("ğŸ—ï¸ RAGçŠ¶æ€å›¾æ„å»ºå®Œæˆ")

    # æ˜ç¡®ç±»å‹è½¬æ¢ä»¥æ»¡è¶³mypyè¦æ±‚
    return compiled_graph  # type: ignore[return-value]


############################################################################################################
def print_full_message_chain(state: RAGState) -> None:
    """æ‰“å°å®Œæ•´æ¶ˆæ¯é“¾è·¯ç”¨äºè°ƒè¯•

    Args:
        state: RAGçŠ¶æ€å¯¹è±¡
    """
    messages = state.get("messages", [])
    logger.info(f"ğŸ“œ å®Œæ•´æ¶ˆæ¯é“¾è·¯ (å…± {len(messages)} æ¡æ¶ˆæ¯)")
    for i, msg in enumerate(messages, 0):
        logger.debug(
            f"[{i}] å®Œæ•´å†…å®¹:\n{msg.model_dump_json(indent=2, ensure_ascii=False)}\n"
        )


############################################################################################################
async def execute_rag_workflow(
    work_flow: CompiledStateGraph[RAGState, Any, RAGState, RAGState],
    context: List[BaseMessage],
    request: HumanMessage,
    llm: ChatDeepSeek,
    document_retriever: DocumentRetriever,
    similarity_threshold: float = DEFAULT_SIMILARITY_SCORE,
    retrieval_limit: int = DEFAULT_RETRIEVAL_LIMIT,
) -> List[BaseMessage]:
    """æ‰§è¡Œ RAG å·¥ä½œæµå¹¶è¿”å› AI å“åº”

    å°†å†å²æ¶ˆæ¯å’Œç”¨æˆ·è¾“å…¥åˆå¹¶ä¸ºå®Œæ•´ä¸Šä¸‹æ–‡,é€šè¿‡ RAG ä¸‰é˜¶æ®µæµç¨‹å¤„ç†,
    æœ€ç»ˆè¿”å› LLM ç”Ÿæˆçš„å“åº”æ¶ˆæ¯ã€‚

    Args:
        work_flow: å·²ç¼–è¯‘çš„ LangGraph çŠ¶æ€å›¾
        context: å†å²æ¶ˆæ¯åˆ—è¡¨(å®Œæ•´å¯¹è¯ä¸Šä¸‹æ–‡)
        request: ç”¨æˆ·å½“å‰è¾“å…¥æ¶ˆæ¯
        llm: ChatDeepSeek LLM å®ä¾‹
        document_retriever: æ–‡æ¡£æ£€ç´¢å™¨å®ä¾‹
        similarity_threshold: ç›¸ä¼¼åº¦é˜ˆå€¼
        retrieval_limit: æ£€ç´¢æ–‡æ¡£æ•°é‡ä¸Šé™

    Returns:
        åŒ…å« AI å“åº”çš„æ¶ˆæ¯åˆ—è¡¨,é€šè¿‡ last_state["llm_response"] è·å–

    Raises:
        å¼‚å¸¸ä¼šè¢«æ•è·å¹¶è®°å½•,ç”±è°ƒç”¨æ–¹æ ¹æ®è¿”å›ç©ºåˆ—è¡¨åˆ¤æ–­å¤±è´¥
    """
    logger.info("ğŸš€ å¼€å§‹æ‰§è¡ŒRAGæµç¨‹...")

    # æ„é€  RAGState: messages åŒ…å«å®Œæ•´å†å²ä¸Šä¸‹æ–‡ + å½“å‰è¯·æ±‚
    rag_state: RAGState = {
        "messages": context + [request],
        "retrieved_docs": [],
        "enhanced_context": "",
        "similarity_scores": [],
        "llm": llm,
        "document_retriever": document_retriever,
        "similarity_threshold": similarity_threshold,
        "retrieval_limit": retrieval_limit,
    }

    logger.info(f"ğŸš€ RAGè¾“å…¥çŠ¶æ€å‡†å¤‡å®Œæˆï¼Œç”¨æˆ·æŸ¥è¯¢: {request.content}")

    ret: List[BaseMessage] = []

    try:

        last_state: Optional[RAGState] = None

        async for event in work_flow.astream(rag_state):
            for value in event.values():
                last_state = value

        # ä» last_state ä¸­æå– llm_response
        if last_state and "llm_response" in last_state:
            assert isinstance(last_state["llm_response"], AIMessage)
            ret = [last_state["llm_response"]]
            print_full_message_chain(last_state)

    except Exception as e:
        logger.error(f"ğŸš€ RAGæµç¨‹æ‰§è¡Œé”™è¯¯: {e}\n{traceback.format_exc()}")

    return ret


############################################################################################################
