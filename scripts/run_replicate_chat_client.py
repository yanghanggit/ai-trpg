#!/usr/bin/env python3
"""
Replicate å¯¹è¯å·¥å…·
ä¸€ä¸ªç®€å•æ˜“ç”¨çš„å¯¹è¯è„šæœ¬ï¼Œæ”¯æŒå¤šç§LLMæ¨¡å‹è¿›è¡Œå¯¹è¯
"""

import argparse
import os
from pathlib import Path
import sys
import time
from typing import Dict, Final, List

import replicate

from magic_book.replicate import (
    ReplicateModelsConfig,
    test_replicate_api_connection,
    load_replicate_config,
)

# å…¨å±€å˜é‡
API_TOKEN: str = os.getenv("REPLICATE_API_TOKEN") or ""

replicate_config = load_replicate_config(Path("replicate_models.json"))


CHAT_MODELS: Dict[str, Dict[str, str]] = replicate_config.chat_models.model_dump(
    by_alias=True, exclude_none=True
)
DEFAULT_MODEL: Final[str] = "gpt-4o-mini"


def chat_single(
    prompt: str,
    model_name: str = DEFAULT_MODEL,
    system_prompt: str = "You are a helpful assistant.",
    max_tokens: int = 1000,
    temperature: float = 0.7,
    stream: bool = False,
) -> str:
    """
    å•æ¬¡å¯¹è¯

    Args:
        prompt: ç”¨æˆ·è¾“å…¥çš„æ¶ˆæ¯
        model_name: æ¨¡å‹åç§°
        system_prompt: ç³»ç»Ÿæç¤ºè¯
        max_tokens: æœ€å¤§tokenæ•°
        temperature: æ¸©åº¦å‚æ•°ï¼ˆ0-2ï¼‰
        stream: æ˜¯å¦æµå¼è¾“å‡º

    Returns:
        æ¨¡å‹å›å¤
    """
    if model_name not in CHAT_MODELS:
        raise ValueError(
            f"ä¸æ”¯æŒçš„æ¨¡å‹: {model_name}. å¯ç”¨æ¨¡å‹: {list(CHAT_MODELS.keys())}"
        )

    model_info = CHAT_MODELS[model_name]
    model_version = model_info["version"]
    cost_estimate = model_info["cost_estimate"]

    print(f"\nğŸ¤– ä½¿ç”¨æ¨¡å‹: {model_name}")
    print(f"ğŸ’° é¢„ä¼°æˆæœ¬: {cost_estimate}")
    print(f"ğŸ“ ç”¨æˆ·è¾“å…¥: {prompt[:80]}{'...' if len(prompt) > 80 else ''}")
    print("ğŸ”„ æ€è€ƒä¸­...")

    start_time = time.time()

    try:
        # æ„å»ºè¾“å…¥å‚æ•°
        input_params = {
            "prompt": prompt,
            "system_prompt": system_prompt,
            "max_completion_tokens": max_tokens,
            "temperature": temperature,
        }

        if stream:
            # æµå¼è¾“å‡º
            print("\nğŸ¯ AI å›å¤:")
            print("-" * 50)

            iterator = replicate.run(model_version, input=input_params)
            full_response = ""

            for text in iterator:
                print(text, end="", flush=True)
                full_response += text

            print()  # æ¢è¡Œ
            print("-" * 50)

            elapsed_time = time.time() - start_time
            print(f"â±ï¸  å®Œæˆæ—¶é—´: {elapsed_time:.2f}ç§’")

            return full_response
        else:
            # ä¸€æ¬¡æ€§è¾“å‡º
            output = replicate.run(model_version, input=input_params)

            response = ""
            if isinstance(output, list):
                response = "".join(str(item) for item in output)
            else:
                response = str(output)

            elapsed_time = time.time() - start_time
            print(f"\nğŸ¯ AI å›å¤:")
            print("-" * 50)
            print(response)
            print("-" * 50)
            print(f"â±ï¸  å®Œæˆæ—¶é—´: {elapsed_time:.2f}ç§’")

            return response

    except Exception as e:
        print(f"âŒ å¯¹è¯å¤±è´¥: {e}")
        raise


def chat_interactive(
    model_name: str = DEFAULT_MODEL,
    system_prompt: str = "You are a helpful assistant.",
    stream: bool = True,
) -> None:
    """
    äº¤äº’å¼å¯¹è¯æ¨¡å¼

    Args:
        model_name: æ¨¡å‹åç§°
        system_prompt: ç³»ç»Ÿæç¤ºè¯
        stream: æ˜¯å¦æµå¼è¾“å‡º
    """
    print("=" * 60)
    print("ğŸ® Replicate äº¤äº’å¼å¯¹è¯")
    print("=" * 60)
    print(f"ğŸ¤– å½“å‰æ¨¡å‹: {model_name}")
    print(f"ğŸ“‹ æ¨¡å‹æè¿°: {CHAT_MODELS[model_name]['description']}")
    print(f"ğŸ’° æˆæœ¬ä¼°ç®—: {CHAT_MODELS[model_name]['cost_estimate']}")
    print("\nğŸ’¡ ä½¿ç”¨è¯´æ˜:")
    print("   - ç›´æ¥è¾“å…¥æ¶ˆæ¯å¼€å§‹å¯¹è¯")
    print("   - è¾“å…¥ 'quit' æˆ– 'exit' é€€å‡º")
    print("   - è¾“å…¥ 'clear' æ¸…ç©ºå¯¹è¯å†å²")
    print("   - è¾“å…¥ 'help' æŸ¥çœ‹å¸®åŠ©")
    print("=" * 60)

    conversation_history: List[str] = []

    while True:
        try:
            # è·å–ç”¨æˆ·è¾“å…¥
            user_input = input("\nğŸ‘¤ ä½ : ").strip()

            if not user_input:
                continue

            # å¤„ç†ç‰¹æ®Šå‘½ä»¤
            if user_input.lower() in ["quit", "exit"]:
                print("ğŸ‘‹ å†è§!")
                break
            elif user_input.lower() == "clear":
                conversation_history.clear()
                print("ğŸ§¹ å¯¹è¯å†å²å·²æ¸…ç©º")
                continue
            elif user_input.lower() == "help":
                print("\nğŸ“– å¯ç”¨å‘½ä»¤:")
                print("   - quit/exit: é€€å‡ºå¯¹è¯")
                print("   - clear: æ¸…ç©ºå¯¹è¯å†å²")
                print("   - help: æ˜¾ç¤ºå¸®åŠ©")
                continue

            # æ·»åŠ åˆ°å¯¹è¯å†å²
            conversation_history.append(f"ç”¨æˆ·: {user_input}")

            # æ„å»ºå®Œæ•´çš„å¯¹è¯ä¸Šä¸‹æ–‡
            if len(conversation_history) > 1:
                context = "\n".join(conversation_history[-10:])  # ä¿ç•™æœ€è¿‘10è½®å¯¹è¯
                full_prompt = f"å¯¹è¯å†å²:\n{context}\n\nè¯·å›å¤æœ€æ–°çš„ç”¨æˆ·æ¶ˆæ¯ã€‚"
            else:
                full_prompt = user_input

            # å‘é€ç»™AI
            response = chat_single(
                prompt=full_prompt,
                model_name=model_name,
                system_prompt=system_prompt,
                stream=stream,
            )

            # æ·»åŠ AIå›å¤åˆ°å†å²
            conversation_history.append(f"AI: {response}")

        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ ç”¨æˆ·ä¸­æ–­ï¼Œå†è§!")
            break
        except Exception as e:
            print(f"\nâŒ å¯¹è¯å‡ºé”™: {e}")


def run_demo() -> None:
    """è¿è¡Œæ¼”ç¤ºç¤ºä¾‹"""
    print("=" * 60)
    print("ğŸ® Replicate å¯¹è¯æ¼”ç¤º")
    print("=" * 60)

    # 1. æµ‹è¯•è¿æ¥
    if not test_replicate_api_connection():
        print("âŒ è¿æ¥æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè®¾ç½®")
        return

        # 2. éªŒè¯JSONé…ç½®æ ¼å¼
        # rint("\nğŸ“‹ JSONé…ç½®éªŒè¯:")
        # validate_json_file()

    # 3. æŸ¥çœ‹å¯ç”¨æ¨¡å‹
    print("\nğŸ“‹ å¯ç”¨å¯¹è¯æ¨¡å‹:")
    for name, info in CHAT_MODELS.items():
        cost = info["cost_estimate"]
        description = info["description"]
        print(f"  - {name}:")
        print(f"    ğŸ’° {cost}")
        print(f"    ğŸ“ {description}")

    # 4. æµ‹è¯•å¯¹è¯
    print("\nğŸ¤– æµ‹è¯•å¯¹è¯åŠŸèƒ½...")

    try:
        test_prompt = "ä½ å¥½ï¼è¯·ç®€å•ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ã€‚"

        response = chat_single(
            prompt=test_prompt, model_name=DEFAULT_MODEL, stream=False
        )

        print(f"\nğŸ‰ æ¼”ç¤ºå®Œæˆ!")
        print("ğŸ’¡ æ‚¨å¯ä»¥ä½¿ç”¨ --interactive æ¨¡å¼è¿›è¡Œè¿ç»­å¯¹è¯")

    except Exception as e:
        print(f"âŒ æ¼”ç¤ºå¤±è´¥: {e}")


def test_pydantic_validation() -> None:
    """æµ‹è¯• Pydantic æ•°æ®éªŒè¯åŠŸèƒ½"""
    print("=" * 60)
    print("ğŸ§ª Pydantic æ•°æ®éªŒè¯æµ‹è¯•")
    print("=" * 60)

    # æ˜¾ç¤ºSchema
    print("\n3. Pydantic Schema:")
    try:
        schema = ReplicateModelsConfig.model_json_schema()
        print("ğŸ“‹ Pydantic æ•°æ®æ¨¡å‹ Schema:")
        print("=" * 60)
        import json

        print(json.dumps(schema, indent=2, ensure_ascii=False)[:1000] + "...")
    except Exception as e:
        print(f"âŒ è·å– Schema å¤±è´¥: {e}")

    print("\nğŸ‰ Pydantic éªŒè¯æµ‹è¯•å®Œæˆ!")


def run_validation_demo() -> None:
    """è¿è¡ŒéªŒè¯åŠŸèƒ½æ¼”ç¤º"""
    print("=" * 60)
    print("ğŸ” é…ç½®éªŒè¯åŠŸèƒ½æ¼”ç¤º")
    print("=" * 60)

    print("\nğŸ‰ éªŒè¯æ¼”ç¤ºå®Œæˆ!")


def main() -> None:
    """ä¸»å‡½æ•° - å‘½ä»¤è¡Œæ¥å£"""

    # æ£€æŸ¥å¯¹è¯æ¨¡å‹é…ç½®æ˜¯å¦æ­£ç¡®åŠ è½½
    if not CHAT_MODELS:
        print("âŒ é”™è¯¯: å¯¹è¯æ¨¡å‹é…ç½®æœªæ­£ç¡®åŠ è½½")
        print("ğŸ’¡ è¯·æ£€æŸ¥:")
        print("   1. replicate_models.json æ–‡ä»¶æ˜¯å¦å­˜åœ¨")
        print("   2. JSON æ–‡ä»¶æ ¼å¼æ˜¯å¦æ­£ç¡®")
        print("   3. chat_models éƒ¨åˆ†æ˜¯å¦é…ç½®æ­£ç¡®")
        sys.exit(1)

    parser = argparse.ArgumentParser(description="Replicate å¯¹è¯å·¥å…·")
    parser.add_argument("prompt", nargs="?", help="å¯¹è¯å†…å®¹")
    parser.add_argument(
        "--model",
        "-m",
        default=DEFAULT_MODEL,
        choices=list(CHAT_MODELS.keys()),
        help=f"ä½¿ç”¨çš„æ¨¡å‹ (é»˜è®¤: {DEFAULT_MODEL})",
    )
    parser.add_argument(
        "--system", "-s", default="You are a helpful assistant.", help="ç³»ç»Ÿæç¤ºè¯"
    )
    parser.add_argument(
        "--max-tokens", "-t", type=int, default=1000, help="æœ€å¤§tokenæ•° (é»˜è®¤: 1000)"
    )
    parser.add_argument(
        "--temperature", type=float, default=0.7, help="æ¸©åº¦å‚æ•° 0-2 (é»˜è®¤: 0.7)"
    )
    parser.add_argument("--no-stream", action="store_true", help="ç¦ç”¨æµå¼è¾“å‡º")
    parser.add_argument(
        "--interactive", "-i", action="store_true", help="è¿›å…¥äº¤äº’å¼å¯¹è¯æ¨¡å¼"
    )
    parser.add_argument("--list-models", action="store_true", help="åˆ—å‡ºå¯ç”¨æ¨¡å‹")
    parser.add_argument("--demo", action="store_true", help="è¿è¡Œæ¼”ç¤º")
    parser.add_argument("--test", action="store_true", help="æµ‹è¯•è¿æ¥")
    parser.add_argument("--validate", action="store_true", help="éªŒè¯é…ç½®å’ŒJSONæ ¼å¼")
    parser.add_argument(
        "--test-pydantic", action="store_true", help="æµ‹è¯•Pydanticæ•°æ®éªŒè¯"
    )
    parser.add_argument(
        "--schema", action="store_true", help="æ˜¾ç¤ºPydanticæ•°æ®æ¨¡å‹Schema"
    )

    args = parser.parse_args()

    try:
        print("âœ… Replicate å®¢æˆ·ç«¯åˆå§‹åŒ–å®Œæˆ")

        # è¿è¡Œæ¼”ç¤º
        if args.demo:
            run_demo()
            return

        # æµ‹è¯•è¿æ¥
        if args.test:
            test_replicate_api_connection()
            return

        # éªŒè¯é…ç½®å’ŒJSONæ ¼å¼
        if args.validate:
            run_validation_demo()
            return

        # æµ‹è¯•PydanticéªŒè¯
        if args.test_pydantic:
            test_pydantic_validation()
            return

        # æ˜¾ç¤ºSchema
        if args.schema:
            try:
                schema = ReplicateModelsConfig.model_json_schema()
                print("ğŸ“‹ Pydantic æ•°æ®æ¨¡å‹ Schema:")
                print("=" * 60)
                import json

                print(json.dumps(schema, indent=2, ensure_ascii=False))
            except Exception as e:
                print(f"âŒ è·å– Schema å¤±è´¥: {e}")
            return

        # åˆ—å‡ºæ¨¡å‹
        if args.list_models:
            print("ğŸ¤– å¯ç”¨å¯¹è¯æ¨¡å‹:")
            for name, info in CHAT_MODELS.items():
                cost = info["cost_estimate"]
                description = info["description"]
                print(f"  - {name}:")
                print(f"    ğŸ’° {cost}")
                print(f"    ğŸ“ {description}")
            return

        # äº¤äº’å¼æ¨¡å¼
        if args.interactive:
            chat_interactive(
                model_name=args.model,
                system_prompt=args.system,
                stream=not args.no_stream,
            )
            return

        # å¦‚æœæ²¡æœ‰æä¾›promptï¼Œæ˜¾ç¤ºå¸®åŠ©
        if not args.prompt:
            print("ğŸ¤– Replicate å¯¹è¯å·¥å…·")
            print("\nå¿«é€Ÿå¼€å§‹:")
            print("  python run_replicate_chat.py --demo              # è¿è¡Œæ¼”ç¤º")
            print("  python run_replicate_chat.py --test              # æµ‹è¯•è¿æ¥")
            print("  python run_replicate_chat.py --validate          # éªŒè¯é…ç½®æ ¼å¼")
            print(
                "  python run_replicate_chat.py --test-pydantic     # æµ‹è¯•PydanticéªŒè¯"
            )
            print(
                "  python run_replicate_chat.py --schema            # æ˜¾ç¤ºæ•°æ®æ¨¡å‹Schema"
            )
            print("  python run_replicate_chat.py --list-models       # æŸ¥çœ‹å¯ç”¨æ¨¡å‹")
            print("  python run_replicate_chat.py --interactive       # äº¤äº’å¼å¯¹è¯")
            print('  python run_replicate_chat.py "ä½ å¥½ï¼Œä»‹ç»ä¸€ä¸‹è‡ªå·±"   # å•æ¬¡å¯¹è¯')
            print("\næ¨¡å‹é€‰æ‹©:")
            for name, info in CHAT_MODELS.items():
                print(f"  --model {name:<15} # {info['description']}")
            print("\nè¯¦ç»†å¸®åŠ©:")
            print("  python run_replicate_chat.py -h")
            return

        # å•æ¬¡å¯¹è¯
        response = chat_single(
            prompt=args.prompt,
            model_name=args.model,
            system_prompt=args.system,
            max_tokens=args.max_tokens,
            temperature=args.temperature,
            stream=not args.no_stream,
        )

        print(f"\nğŸ‰ å¯¹è¯å®Œæˆ!")

    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
