# #!/usr/bin/env python3
# """
# DeepSeek Chat Serverå¯åŠ¨è„šæœ¬

# åŠŸèƒ½ï¼š
# 1. åŸºäºFastAPIæ„å»ºçš„DeepSeekèŠå¤©æœåŠ¡å™¨
# 2. æä¾›RESTful APIæ¥å£
# 3. æ”¯æŒèŠå¤©å†å²å’Œä¸Šä¸‹æ–‡è®°å¿†
# 4. å¼‚æ­¥å¤„ç†èŠå¤©è¯·æ±‚

# ä½¿ç”¨æ–¹æ³•ï¼š
#     python scripts/run_deepseek_chat_server.py

# æˆ–è€…åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹ï¼š
#     python -m scripts.run_deepseek_chat_server

# APIç«¯ç‚¹ï¼š
#     GET  /                    - å¥åº·æ£€æŸ¥
#     POST /api/chat/v1/        - æ ‡å‡†èŠå¤©
#     POST /api/chat/rag/v1/    - RAGèŠå¤©
#     POST /api/chat/undefined/v1/ - æœªå®šä¹‰ç±»å‹èŠå¤©
#     POST /api/chat/mcp/v1/    - MCPèŠå¤©
# """

# import os
# import sys
# import asyncio
# from typing import Any, Dict

# # å°† src ç›®å½•æ·»åŠ åˆ°æ¨¡å—æœç´¢è·¯å¾„
# sys.path.insert(
#     0, os.path.join(os.path.dirname(os.path.abspath(__file__)), "..", "src")
# )

# from fastapi import FastAPI
# from loguru import logger

# from magic_book.chat_services.protocol import ChatRequest, ChatResponse
# from magic_book.deepseek import (
#     State,
#     create_compiled_stage_graph,
#     stream_graph_updates,
#     create_deepseek_llm,
#     create_rag_compiled_graph,
#     stream_rag_graph_updates,
#     create_unified_chat_graph,
#     stream_unified_graph_updates,
#     McpState,
#     create_mcp_workflow,
#     execute_mcp_workflow,
# )

# from magic_book.configuration import (
#     server_configuration,
# )

# # å¯¼å…¥è·¯ç”±ç®¡ç†å™¨ç›¸å…³æ¨¡å—
# from magic_book.rag.routing import (
#     KeywordRouteStrategy,
#     SemanticRouteStrategy,
#     RouteDecisionManager,
#     FallbackRouteStrategy,
#     RouteConfigBuilder,
# )
# from magic_book.demo.campaign_setting import (
#     FANTASY_WORLD_RPG_TEST_ROUTE_KEYWORDS,
#     FANTASY_WORLD_RPG_TEST_RAG_TOPICS,
# )

# # å¯¼å…¥ MCP ç›¸å…³æ¨¡å—
# from magic_book.mcp import (
#     McpToolInfo,
#     initialize_mcp_client,
#     mcp_config,
#     McpClient,
# )
# from typing import List, Optional, Dict, Any
# from langchain.schema import SystemMessage, BaseMessage
# from contextlib import asynccontextmanager
# from typing import AsyncGenerator

# ##################################################################################################################
# # å…¨å±€ MCP å®¢æˆ·ç«¯å’Œå·¥å…·å˜é‡
# _global_mcp_client: Optional[McpClient] = None
# _global_available_tools: List[McpToolInfo] = []


# ##################################################################################################################
# # MCP ç›¸å…³é…ç½®å’Œåˆå§‹åŒ–å‡½æ•°
# # def _load_mcp_config_for_server() -> McpConfig:
# #     """ä¸ºæœåŠ¡å™¨åŠ è½½ MCP é…ç½®"""
# #     try:
# #         return load_mcp_config(Path("mcp_config.json"))
# #     except Exception as e:
# #         logger.error(f"åŠ è½½ MCP é…ç½®å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
# #         return McpConfig(
# #             mcp_server_host="127.0.0.1",
# #             mcp_server_port=8765,
# #             protocol_version="2024-11-05",
# #             mcp_timeout=30,
# #             server_name="Default MCP Server",
# #             server_version="1.0.0",
# #             server_description="é»˜è®¤ MCP æœåŠ¡å™¨é…ç½®",
# #             transport="streamable-http",
# #             allowed_origins=["http://localhost"],
# #         )


# ##################################################################################################################
# async def _initialize_global_mcp_client() -> None:
#     """å…¨å±€åˆå§‹åŒ– MCP å®¢æˆ·ç«¯ï¼ˆæœåŠ¡å™¨å¯åŠ¨æ—¶è°ƒç”¨ä¸€æ¬¡ï¼‰"""
#     global _global_mcp_client, _global_available_tools

#     try:
#         logger.info("ğŸ”§ å¼€å§‹åˆå§‹å…¨å±€MCPå®¢æˆ·ç«¯...")
#         # mcp_config = _load_mcp_config_for_server()
#         mcp_client = await initialize_mcp_client(
#             mcp_server_url=mcp_config.mcp_server_url,
#             mcp_protocol_version=mcp_config.protocol_version,
#             mcp_timeout=mcp_config.mcp_timeout,
#         )

#         if mcp_client:
#             tools_result = await mcp_client.list_tools()
#             available_tools = tools_result if tools_result is not None else []

#             # è®¾ç½®å…¨å±€å˜é‡
#             _global_mcp_client = mcp_client
#             _global_available_tools = available_tools

#             logger.success(
#                 f"ğŸ”— å…¨å±€MCPå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸï¼Œå¯ç”¨å·¥å…·: {len(available_tools)}"
#             )
#         else:
#             logger.error("âŒ å…¨å±€MCPå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥")
#             _global_mcp_client = None
#             _global_available_tools = []

#     except Exception as e:
#         logger.error(f"âŒ å…¨å±€MCPå®¢æˆ·ç«¯åˆå§‹åŒ–é”™è¯¯: {e}")
#         _global_mcp_client = None
#         _global_available_tools = []


# ##################################################################################################################
# # è·¯ç”±ç®¡ç†å™¨åˆ›å»ºå‡½æ•°
# def _create_keyword_strategy() -> KeywordRouteStrategy:
#     """åˆ›å»ºè‰¾å°”æ³•å°¼äºšä¸–ç•Œä¸“ç”¨çš„å…³é”®è¯ç­–ç•¥"""
#     config = {
#         "keywords": FANTASY_WORLD_RPG_TEST_ROUTE_KEYWORDS,
#         "threshold": 0.1,  # è¾ƒä½é˜ˆå€¼ï¼Œåªè¦åŒ¹é…åˆ°å…³é”®è¯å°±å¯ç”¨RAG
#         "case_sensitive": False,
#     }
#     return KeywordRouteStrategy(config)


# ##################################################################################################################
# def _create_game_semantic_strategy() -> SemanticRouteStrategy:
#     """åˆ›å»ºæ¸¸æˆä¸“ç”¨çš„è¯­ä¹‰è·¯ç”±ç­–ç•¥"""
#     config = {
#         "similarity_threshold": 0.5,  # ä¸­ç­‰ç›¸ä¼¼åº¦é˜ˆå€¼
#         "use_multilingual": True,  # ä½¿ç”¨å¤šè¯­è¨€æ¨¡å‹æ”¯æŒä¸­æ–‡
#         "rag_topics": FANTASY_WORLD_RPG_TEST_RAG_TOPICS,
#     }
#     return SemanticRouteStrategy(config)


# ##################################################################################################################
# def _create_default_route_manager() -> RouteDecisionManager:
#     """åˆ›å»ºé»˜è®¤çš„è·¯ç”±å†³ç­–ç®¡ç†å™¨"""
#     # åˆ›å»ºç­–ç•¥å®ä¾‹
#     keyword_strategy = _create_keyword_strategy()
#     semantic_strategy = _create_game_semantic_strategy()

#     # ä½¿ç”¨æ„å»ºå™¨åˆ›å»ºç®¡ç†å™¨
#     builder = RouteConfigBuilder()
#     builder.add_strategy(keyword_strategy, 0.4)
#     builder.add_strategy(semantic_strategy, 0.6)
#     builder.set_fallback(FallbackRouteStrategy(default_to_rag=False))

#     return builder.build()


# ##################################################################################################################


# @asynccontextmanager
# async def lifespan(app: FastAPI) -> AsyncGenerator[None, None]:
#     """
#     åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†å™¨ï¼ˆç°ä»£åŒ–æ–¹å¼ï¼‰

#     åœ¨åº”ç”¨å¯åŠ¨æ—¶æ‰§è¡Œåˆå§‹åŒ–é€»è¾‘ï¼Œåœ¨å…³é—­æ—¶æ‰§è¡Œæ¸…ç†é€»è¾‘
#     """
#     # å¯åŠ¨æ—¶æ‰§è¡Œ
#     logger.info("ğŸš€ åº”ç”¨å¯åŠ¨ä¸­...")
#     await _initialize_global_mcp_client()
#     logger.success("âœ… åº”ç”¨å¯åŠ¨å®Œæˆ")

#     yield  # åº”ç”¨è¿è¡ŒæœŸé—´

#     # å…³é—­æ—¶æ‰§è¡Œï¼ˆå¦‚æœéœ€è¦æ¸…ç†èµ„æºï¼‰
#     logger.info("ğŸ”„ åº”ç”¨å…³é—­ä¸­...")
#     # è¿™é‡Œå¯ä»¥æ·»åŠ æ¸…ç†é€»è¾‘ï¼Œæ¯”å¦‚å…³é—­æ•°æ®åº“è¿æ¥ç­‰
#     logger.success("âœ… åº”ç”¨å…³é—­å®Œæˆ")


# # åˆå§‹åŒ– FastAPI åº”ç”¨ï¼ˆä½¿ç”¨ç°ä»£åŒ–ç”Ÿå‘½å‘¨æœŸç®¡ç†ï¼‰
# app = FastAPI(
#     title="DeepSeek Chat Server",
#     description="åŸºäºDeepSeekçš„èŠå¤©æœåŠ¡å™¨",
#     version="1.0.0",
#     lifespan=lifespan,
# )


# ##################################################################################################################
# # å¥åº·æ£€æŸ¥ç«¯ç‚¹
# @app.get("/")
# async def health_check() -> Dict[str, Any]:
#     """
#     æœåŠ¡å™¨å¥åº·æ£€æŸ¥ç«¯ç‚¹

#     Returns:
#         dict: åŒ…å«æœåŠ¡å™¨çŠ¶æ€ä¿¡æ¯çš„å­—å…¸
#     """
#     from datetime import datetime

#     return {
#         "service": "DeepSeek Chat Server",
#         "version": "1.0.0",
#         "status": "healthy",
#         "timestamp": datetime.now().isoformat(),
#         "available_endpoints": [
#             "GET /",
#             "POST /api/chat/v1/",
#             "POST /api/chat/rag/v1/",
#             "POST /api/chat/undefined/v1/",
#             "POST /api/chat/mcp/v1/",
#         ],
#         "description": "åŸºäºDeepSeekçš„èŠå¤©æœåŠ¡å™¨æ­£åœ¨æ­£å¸¸è¿è¡Œ",
#     }


# ##################################################################################################################
# # å®šä¹‰ POST è¯·æ±‚å¤„ç†é€»è¾‘
# @app.post(
#     path="/api/chat/v1/",
#     response_model=ChatResponse,
# )
# async def process_chat_request(payload: ChatRequest) -> ChatResponse:
#     """
#     å¤„ç†èŠå¤©è¯·æ±‚

#     Args:
#         request: åŒ…å«èŠå¤©å†å²å’Œç”¨æˆ·æ¶ˆæ¯çš„è¯·æ±‚å¯¹è±¡

#     Returns:
#         ChatResponse: åŒ…å«AIå›å¤æ¶ˆæ¯çš„å“åº”å¯¹è±¡
#     """
#     try:
#         logger.info(f"æ”¶åˆ°èŠå¤©è¯·æ±‚: {payload.message.content}")

#         # ä¸ºæ¯ä¸ªè¯·æ±‚åˆ›å»ºç‹¬ç«‹çš„LLMå®ä¾‹
#         llm = create_deepseek_llm()

#         # ä¸ºæ¯ä¸ªè¯·æ±‚åˆ›å»ºç‹¬ç«‹çš„çŠ¶æ€å›¾å®ä¾‹
#         compiled_state_graph = create_compiled_stage_graph("deepseek_chatbot_node")

#         # èŠå¤©å†å²ï¼ˆåŒ…å«LLMå®ä¾‹ï¼‰
#         chat_history_state: State = {
#             "messages": [message for message in payload.chat_history],
#             "llm": llm,
#         }

#         # ç”¨æˆ·è¾“å…¥
#         user_input_state: State = {"messages": [payload.message], "llm": llm}

#         # è·å–å›å¤ - ä½¿ç”¨ asyncio.to_thread å°†é˜»å¡è°ƒç”¨åŒ…è£…ä¸ºå¼‚æ­¥
#         update_messages = await asyncio.to_thread(
#             stream_graph_updates,
#             state_compiled_graph=compiled_state_graph,
#             chat_history_state=chat_history_state,
#             user_input_state=user_input_state,
#         )

#         logger.success(f"ç”Ÿæˆå›å¤æ¶ˆæ¯æ•°é‡: {len(update_messages)}")

#         # æ‰“å°æ‰€æœ‰æ¶ˆæ¯çš„è¯¦ç»†å†…å®¹
#         for i, message in enumerate(update_messages):
#             logger.success(f"æ¶ˆæ¯ {i+1}: {message.model_dump_json(indent=2)}")

#         # è¿”å›
#         return ChatResponse(messages=update_messages)

#     except Exception as e:
#         logger.error(f"å¤„ç†èŠå¤©è¯·æ±‚æ—¶å‘ç”Ÿé”™è¯¯: {e}")
#         # è¿”å›é”™è¯¯æ¶ˆæ¯
#         from langchain.schema import AIMessage

#         error_message = AIMessage(content=f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
#         return ChatResponse(messages=[error_message])


# ##################################################################################################################
# @app.post(
#     path="/api/chat/rag/v1/",
#     response_model=ChatResponse,
# )
# async def process_chat_rag_request(payload: ChatRequest) -> ChatResponse:
#     """
#     å¤„ç†RAGèŠå¤©è¯·æ±‚

#     Args:
#         request: åŒ…å«èŠå¤©å†å²å’Œç”¨æˆ·æ¶ˆæ¯çš„è¯·æ±‚å¯¹è±¡

#     Returns:
#         ChatResponse: åŒ…å«AIå›å¤æ¶ˆæ¯çš„å“åº”å¯¹è±¡
#     """
#     try:
#         logger.info(f"æ”¶åˆ°RAGèŠå¤©è¯·æ±‚: {payload.message.content}")

#         # ä¸ºæ¯ä¸ªè¯·æ±‚åˆ›å»ºç‹¬ç«‹çš„LLMå®ä¾‹
#         llm = create_deepseek_llm()

#         # ä¸ºæ¯ä¸ªè¯·æ±‚åˆ›å»ºç‹¬ç«‹çš„RAGçŠ¶æ€å›¾å®ä¾‹
#         rag_compiled_graph = create_rag_compiled_graph()

#         # èŠå¤©å†å²ï¼ˆåŒ…å«LLMå®ä¾‹ï¼‰
#         chat_history_state: State = {
#             "messages": [message for message in payload.chat_history],
#             "llm": llm,
#         }

#         # ç”¨æˆ·è¾“å…¥
#         user_input_state: State = {"messages": [payload.message], "llm": llm}

#         # è·å–RAGå›å¤ - ä½¿ç”¨ asyncio.to_thread å°†é˜»å¡è°ƒç”¨åŒ…è£…ä¸ºå¼‚æ­¥
#         update_messages = await asyncio.to_thread(
#             stream_rag_graph_updates,
#             rag_compiled_graph=rag_compiled_graph,
#             chat_history_state=chat_history_state,
#             user_input_state=user_input_state,
#         )

#         logger.success(f"ç”ŸæˆRAGå›å¤æ¶ˆæ¯æ•°é‡: {len(update_messages)}")

#         # æ‰“å°æ‰€æœ‰æ¶ˆæ¯çš„è¯¦ç»†å†…å®¹
#         for i, message in enumerate(update_messages):
#             logger.success(f"RAGæ¶ˆæ¯ {i+1}: {message.model_dump_json(indent=2)}")

#         # è¿”å›
#         return ChatResponse(messages=update_messages)

#     except Exception as e:
#         logger.error(f"å¤„ç†RAGèŠå¤©è¯·æ±‚æ—¶å‘ç”Ÿé”™è¯¯: {e}")
#         # è¿”å›é”™è¯¯æ¶ˆæ¯
#         from langchain.schema import AIMessage

#         error_message = AIMessage(content=f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„RAGè¯·æ±‚æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
#         return ChatResponse(messages=[error_message])


# ##################################################################################################################
# @app.post(
#     path="/api/chat/undefined/v1/",
#     response_model=ChatResponse,
# )
# async def process_chat_undefined_request(payload: ChatRequest) -> ChatResponse:
#     """
#     å¤„ç†ç»Ÿä¸€èŠå¤©è¯·æ±‚ï¼ˆæ™ºèƒ½è·¯ç”±ï¼‰

#     åŠŸèƒ½ç‰¹æ€§ï¼š
#     1. ğŸš¦ æ™ºèƒ½è·¯ç”±ï¼šè‡ªåŠ¨æ£€æµ‹æŸ¥è¯¢ç±»å‹å¹¶é€‰æ‹©æœ€ä½³å¤„ç†æ¨¡å¼
#     2. ğŸ’¬ ç›´æ¥å¯¹è¯ï¼šä¸€èˆ¬æ€§èŠå¤©ä½¿ç”¨DeepSeekç›´æ¥å›ç­”
#     3. ğŸ” RAGå¢å¼ºï¼šè‰¾å°”æ³•å°¼äºšä¸–ç•Œç›¸å…³é—®é¢˜ä½¿ç”¨çŸ¥è¯†åº“å¢å¼º
#     4. ğŸ¯ æ— ç¼åˆ‡æ¢ï¼šç”¨æˆ·æ— éœ€æ‰‹åŠ¨é€‰æ‹©æ¨¡å¼

#     Args:
#         request: åŒ…å«èŠå¤©å†å²å’Œç”¨æˆ·æ¶ˆæ¯çš„è¯·æ±‚å¯¹è±¡

#     Returns:
#         ChatResponse: åŒ…å«AIå›å¤æ¶ˆæ¯çš„å“åº”å¯¹è±¡
#     """
#     try:
#         logger.info(f"æ”¶åˆ°ç»Ÿä¸€èŠå¤©è¯·æ±‚: {payload.message.content}")

#         # åˆ›å»ºç»Ÿä¸€èŠå¤©å›¾
#         unified_graph = create_unified_chat_graph()

#         # åˆ›å»ºè·¯ç”±ç®¡ç†å™¨å®ä¾‹
#         route_manager = _create_default_route_manager()

#         # èŠå¤©å†å²çŠ¶æ€ï¼ˆä½¿ç”¨å­—å…¸æ ¼å¼ï¼Œç¬¦åˆç»Ÿä¸€å›¾çš„è¦æ±‚ï¼‰
#         chat_history_state: Dict[str, List[BaseMessage]] = {
#             "messages": [message for message in payload.chat_history]
#         }

#         # ç”¨æˆ·è¾“å…¥çŠ¶æ€
#         user_input_state: Dict[str, List[BaseMessage]] = {"messages": [payload.message]}

#         # æ‰§è¡Œç»Ÿä¸€èŠå¤©æµç¨‹ - ä½¿ç”¨ asyncio.to_thread å°†é˜»å¡è°ƒç”¨åŒ…è£…ä¸ºå¼‚æ­¥
#         update_messages = await asyncio.to_thread(
#             stream_unified_graph_updates,
#             unified_compiled_graph=unified_graph,
#             chat_history_state=chat_history_state,
#             user_input_state=user_input_state,
#             route_manager=route_manager,
#         )

#         logger.success(f"ç”Ÿæˆç»Ÿä¸€èŠå¤©å›å¤æ¶ˆæ¯æ•°é‡: {len(update_messages)}")

#         # æ‰“å°æ‰€æœ‰æ¶ˆæ¯çš„è¯¦ç»†å†…å®¹
#         for i, message in enumerate(update_messages):
#             logger.success(f"ç»Ÿä¸€èŠå¤©æ¶ˆæ¯ {i+1}: {message.model_dump_json(indent=2)}")

#         # è¿”å›
#         return ChatResponse(messages=update_messages)

#     except Exception as e:
#         logger.error(f"å¤„ç†ç»Ÿä¸€èŠå¤©è¯·æ±‚æ—¶å‘ç”Ÿé”™è¯¯: {e}")
#         # è¿”å›é”™è¯¯æ¶ˆæ¯
#         from langchain.schema import AIMessage

#         error_message = AIMessage(
#             content=f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„ç»Ÿä¸€èŠå¤©è¯·æ±‚æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"
#         )
#         return ChatResponse(messages=[error_message])


# ##################################################################################################################
# @app.post(
#     path="/api/chat/mcp/v1/",
#     response_model=ChatResponse,
# )
# async def process_chat_mcp_request(payload: ChatRequest) -> ChatResponse:
#     """
#     å¤„ç†MCPèŠå¤©è¯·æ±‚

#     åŠŸèƒ½ç‰¹æ€§ï¼š
#     1. ğŸ”§ å·¥å…·è°ƒç”¨ï¼šæ”¯æŒ Model Context Protocol (MCP) å·¥å…·é›†æˆ
#     2. ğŸ¤– æ™ºèƒ½åŠ©æ‰‹ï¼šåŸºäº DeepSeek AI çš„å¼ºå¤§å¯¹è¯èƒ½åŠ›
#     3. ğŸ”— å®æ—¶è¿æ¥ï¼šåŠ¨æ€è¿æ¥å’Œç®¡ç† MCP æœåŠ¡å™¨
#     4. âš¡ å¼‚æ­¥å¤„ç†ï¼šé«˜æ•ˆçš„å¼‚æ­¥å·¥å…·è°ƒç”¨å’Œå“åº”

#     Args:
#         request: åŒ…å«èŠå¤©å†å²å’Œç”¨æˆ·æ¶ˆæ¯çš„è¯·æ±‚å¯¹è±¡

#     Returns:
#         ChatResponse: åŒ…å«AIå›å¤æ¶ˆæ¯çš„å“åº”å¯¹è±¡
#     """
#     try:
#         logger.info(f"æ”¶åˆ°MCPèŠå¤©è¯·æ±‚: {payload.message.content}")

#         # è·å–å…¨å±€ MCP å®¢æˆ·ç«¯å’Œå·¥å…·
#         global _global_mcp_client, _global_available_tools
#         mcp_client, available_tools = _global_mcp_client, _global_available_tools

#         if mcp_client is None:
#             # MCP æœåŠ¡å™¨è¿æ¥å¤±è´¥ï¼Œè¿”å›é”™è¯¯ä¿¡æ¯
#             from langchain.schema import AIMessage

#             error_message = AIMessage(
#                 content="âŒ MCP æœåŠ¡å™¨è¿æ¥å¤±è´¥ã€‚è¯·ç¡®ä¿ MCP æœåŠ¡å™¨æ­£åœ¨è¿è¡Œï¼Œå¯åŠ¨å‘½ä»¤ï¼špython scripts/run_sample_mcp_server.py --config mcp_config.json"
#             )
#             return ChatResponse(messages=[error_message])

#         # è®¾ç½®ç³»ç»Ÿæç¤ºï¼ˆå¯ä»¥æ ¹æ®éœ€è¦è°ƒæ•´ï¼‰
#         system_prompt = """ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½AIåŠ©æ‰‹ï¼Œå…·å¤‡å·¥å…·è°ƒç”¨èƒ½åŠ›ã€‚ä½ å¯ä»¥ä½¿ç”¨å„ç§å·¥å…·æ¥å¸®åŠ©ç”¨æˆ·å®Œæˆä»»åŠ¡ï¼ŒåŒ…æ‹¬è·å–æ—¶é—´ã€ç³»ç»Ÿä¿¡æ¯ç­‰ã€‚å½“ç”¨æˆ·è¯¢é—®ç›¸å…³ä¿¡æ¯æ—¶ï¼Œä½ åº”è¯¥ä¸»åŠ¨ä½¿ç”¨ç›¸åº”çš„å·¥å…·æ¥è·å–å‡†ç¡®çš„ä¿¡æ¯ã€‚"""

#         # åˆ›å»º MCP èŠå¤©å†å²çŠ¶æ€
#         # ç±»å‹æ–­è¨€ï¼šæ­¤æ—¶ mcp_client å·²ç»ç¡®ä¿ä¸ä¸º None
#         assert mcp_client is not None
#         chat_history_state: McpState = {
#             "messages": [SystemMessage(content=system_prompt)]
#             + [message for message in payload.chat_history],
#             "mcp_client": mcp_client,
#             "available_tools": available_tools,
#             "tool_outputs": [],
#         }

#         # ç”¨æˆ·è¾“å…¥çŠ¶æ€
#         user_input_state: McpState = {
#             "messages": [payload.message],
#             "mcp_client": mcp_client,
#             "available_tools": available_tools,
#             "tool_outputs": [],
#         }

#         # åˆ›å»º MCP çŠ¶æ€å›¾å®ä¾‹
#         compiled_mcp_stage_graph = await create_mcp_workflow(
#             # "deepseek_mcp_chatbot_node",
#             # mcp_client,
#         )

#         # è·å– MCP å›å¤ï¼ˆåŒ…å«å¯èƒ½çš„å·¥å…·è°ƒç”¨ï¼‰- ä½¿ç”¨å¼‚æ­¥åŒ…è£…
#         update_messages = await execute_mcp_workflow(
#             state_compiled_graph=compiled_mcp_stage_graph,
#             chat_history_state=chat_history_state,
#             user_input_state=user_input_state,
#         )

#         logger.success(f"ç”ŸæˆMCPå›å¤æ¶ˆæ¯æ•°é‡: {len(update_messages)}")

#         # æ‰“å°æ‰€æœ‰æ¶ˆæ¯çš„è¯¦ç»†å†…å®¹
#         for i, message in enumerate(update_messages):
#             logger.success(f"MCPæ¶ˆæ¯ {i+1}: {message.model_dump_json(indent=2)}")

#         # è¿”å›
#         return ChatResponse(messages=update_messages)

#     except Exception as e:
#         logger.error(f"å¤„ç†MCPèŠå¤©è¯·æ±‚æ—¶å‘ç”Ÿé”™è¯¯: {e}")
#         # è¿”å›é”™è¯¯æ¶ˆæ¯
#         from langchain.schema import AIMessage

#         error_message = AIMessage(content=f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„MCPè¯·æ±‚æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
#         return ChatResponse(messages=[error_message])


# ##################################################################################################################
# def main() -> None:
#     """
#     DeepSeekèŠå¤©æœåŠ¡å™¨ä¸»å‡½æ•°

#     åŠŸèƒ½ï¼š
#     1. å¯åŠ¨FastAPIæœåŠ¡å™¨
#     2. é…ç½®æœåŠ¡å™¨å‚æ•°
#     3. æä¾›èŠå¤©APIæœåŠ¡
#     """
#     logger.info("ğŸš€ å¯åŠ¨DeepSeekèŠå¤©æœåŠ¡å™¨...")

#     # åŠ è½½æœåŠ¡å™¨é…ç½®
#     # server_config = initialize_server_settings_instance(
#     #     Path("server_configuration.json")
#     # )

#     try:
#         import uvicorn

#         # å¯åŠ¨æœåŠ¡å™¨
#         uvicorn.run(
#             app,
#             host="localhost",
#             port=server_configuration.deepseek_chat_server_port,
#             log_level="debug",
#         )

#     except Exception as e:
#         logger.error(f"âŒ å¯åŠ¨æœåŠ¡å™¨å¤±è´¥: {e}")
#         raise


# ##################################################################################################################
# if __name__ == "__main__":
#     main()
