#!/usr/bin/env python3
"""
SentenceTransformer æ¨¡å‹ä¸‹è½½å’Œæœ¬åœ°ç¼“å­˜ç®¡ç†è„šæœ¬

è¯¥è„šæœ¬ç”¨äºï¼š
1. é¢„ä¸‹è½½é¡¹ç›®æ‰€éœ€çš„ SentenceTransformer æ¨¡å‹åˆ°æœ¬åœ°
2. ç®¡ç†æ¨¡å‹çš„æœ¬åœ°ç¼“å­˜
3. æä¾›æ¨¡å‹åŠ è½½çš„ç»Ÿä¸€æ¥å£
4. æ”¯æŒç¦»çº¿ä½¿ç”¨

ä½¿ç”¨æ–¹æ³•ï¼š
    python scripts/download_sentence_transformers_models.py --download-all
    python scripts/download_sentence_transformers_models.py --model paraphrase-multilingual-MiniLM-L12-v2
    python scripts/download_sentence_transformers_models.py --list-models
    python scripts/download_sentence_transformers_models.py --check-cache
"""

import argparse
import json
import shutil
from datetime import datetime
from pathlib import Path
from typing import TYPE_CHECKING, Any, Dict, List, Optional, Tuple

if TYPE_CHECKING:
    from sentence_transformers import SentenceTransformer


from loguru import logger


class SentenceTransformerModelManager:
    """SentenceTransformer æ¨¡å‹ç®¡ç†å™¨"""

    # é¡¹ç›®ä½¿ç”¨çš„æ¨¡å‹é…ç½®
    MODELS_CONFIG = {
        "all-MiniLM-L6-v2": {
            "description": "é€šç”¨è‹±æ–‡å¥å­åµŒå…¥æ¨¡å‹ - å¿«é€Ÿè½»é‡",
            "size_mb": 23,
            "languages": ["en"],
            "use_case": "è‹±æ–‡å†…å®¹å¿«é€Ÿç¼–ç ",
        },
        "paraphrase-multilingual-MiniLM-L12-v2": {
            "description": "å¤šè¯­è¨€é‡Šä¹‰æ£€æµ‹æ¨¡å‹ - æ”¯æŒä¸­æ–‡",
            "size_mb": 135,
            "languages": ["zh", "en", "de", "fr", "ja", "ko", "es", "pt", "ru", "ar"],
            "use_case": "å¤šè¯­è¨€å†…å®¹è¯­ä¹‰æœç´¢ï¼Œé¡¹ç›®ä¸»è¦æ¨¡å‹",
        },
        "all-mpnet-base-v2": {
            "description": "é«˜è´¨é‡è‹±æ–‡å¥å­åµŒå…¥æ¨¡å‹",
            "size_mb": 438,
            "languages": ["en"],
            "use_case": "é«˜ç²¾åº¦è‹±æ–‡è¯­ä¹‰æœç´¢ï¼ˆå¯é€‰ï¼‰",
        },
    }

    def __init__(self, cache_dir: Optional[Path] = None):
        """
        åˆå§‹åŒ–æ¨¡å‹ç®¡ç†å™¨

        Args:
            cache_dir: æ¨¡å‹ç¼“å­˜ç›®å½•ï¼Œé»˜è®¤ä¸ºé¡¹ç›®æ ¹ç›®å½•ä¸‹çš„ .cache/sentence_transformers
        """
        self.project_root = Path(__file__).parent.parent

        if cache_dir is None:
            self.cache_dir = self.project_root / ".cache" / "sentence_transformers"
        else:
            self.cache_dir = Path(cache_dir)

        self.cache_dir.mkdir(parents=True, exist_ok=True)

        # æ¨¡å‹ä¿¡æ¯ç¼“å­˜æ–‡ä»¶
        self.models_info_file = self.cache_dir / "models_info.json"

        logger.info(f"æ¨¡å‹ç¼“å­˜ç›®å½•: {self.cache_dir}")

    def download_model(
        self, model_name: str, force_download: bool = False
    ) -> Tuple[bool, str]:
        """
        ä¸‹è½½æŒ‡å®šæ¨¡å‹åˆ°æœ¬åœ°ç¼“å­˜

        Args:
            model_name: æ¨¡å‹åç§°
            force_download: æ˜¯å¦å¼ºåˆ¶é‡æ–°ä¸‹è½½

        Returns:
            (success, message): ä¸‹è½½ç»“æœå’Œæ¶ˆæ¯
        """
        if model_name not in self.MODELS_CONFIG:
            return False, f"ä¸æ”¯æŒçš„æ¨¡å‹: {model_name}"

        model_cache_path = self.cache_dir / model_name

        # æ£€æŸ¥æ˜¯å¦å·²ç»å­˜åœ¨
        if model_cache_path.exists() and not force_download:
            logger.info(f"æ¨¡å‹ {model_name} å·²å­˜åœ¨äºç¼“å­˜ä¸­: {model_cache_path}")
            return True, f"æ¨¡å‹å·²å­˜åœ¨: {model_cache_path}"

        try:
            from sentence_transformers import SentenceTransformer

            logger.info(f"å¼€å§‹ä¸‹è½½æ¨¡å‹: {model_name}")
            logger.info(f"é¢„è®¡å¤§å°: {self.MODELS_CONFIG[model_name]['size_mb']}MB")

            # ä¸‹è½½æ¨¡å‹ï¼ˆè¿™ä¼šè‡ªåŠ¨ç¼“å­˜åˆ° Hugging Face çš„é»˜è®¤ç¼“å­˜ç›®å½•ï¼‰
            model = SentenceTransformer(model_name)

            # ä¿å­˜æ¨¡å‹åˆ°æˆ‘ä»¬çš„è‡ªå®šä¹‰ç¼“å­˜ç›®å½•
            model_cache_path.mkdir(parents=True, exist_ok=True)
            model.save(str(model_cache_path))

            # æ›´æ–°æ¨¡å‹ä¿¡æ¯
            self._update_model_info(model_name, model_cache_path)

            logger.info(f"âœ… æ¨¡å‹ {model_name} ä¸‹è½½å®Œæˆ: {model_cache_path}")
            return True, f"ä¸‹è½½å®Œæˆ: {model_cache_path}"

        except Exception as e:
            logger.error(f"âŒ ä¸‹è½½æ¨¡å‹ {model_name} å¤±è´¥: {e}")
            # æ¸…ç†å¯èƒ½ä¸å®Œæ•´çš„ä¸‹è½½
            if model_cache_path.exists():
                shutil.rmtree(model_cache_path)
            return False, f"ä¸‹è½½å¤±è´¥: {e}"

    def load_model(
        self, model_name: str, use_cache: bool = True
    ) -> Optional["SentenceTransformer"]:
        """
        åŠ è½½æ¨¡å‹ï¼ˆä¼˜å…ˆä½¿ç”¨æœ¬åœ°ç¼“å­˜ï¼‰

        Args:
            model_name: æ¨¡å‹åç§°
            use_cache: æ˜¯å¦ä½¿ç”¨æœ¬åœ°ç¼“å­˜

        Returns:
            SentenceTransformer æ¨¡å‹å®ä¾‹æˆ– None
        """
        try:
            from sentence_transformers import SentenceTransformer

            if use_cache:
                model_cache_path = self.cache_dir / model_name
                if model_cache_path.exists():
                    logger.info(f"ğŸš€ ä»æœ¬åœ°ç¼“å­˜åŠ è½½æ¨¡å‹: {model_cache_path}")
                    return SentenceTransformer(str(model_cache_path))
                else:
                    logger.warning(f"æœ¬åœ°ç¼“å­˜ä¸å­˜åœ¨ï¼Œå°†ä»ç½‘ç»œä¸‹è½½: {model_name}")

            logger.info(f"ğŸ“¥ ä»ç½‘ç»œåŠ è½½æ¨¡å‹: {model_name}")
            return SentenceTransformer(model_name)

        except Exception as e:
            logger.error(f"âŒ åŠ è½½æ¨¡å‹å¤±è´¥ {model_name}: {e}")
            return None

    def list_cached_models(self) -> List[Dict[str, Any]]:
        """åˆ—å‡ºæ‰€æœ‰å·²ç¼“å­˜çš„æ¨¡å‹"""
        cached_models: List[Dict[str, Any]] = []

        if not self.cache_dir.exists():
            return cached_models

        for model_dir in self.cache_dir.iterdir():
            if model_dir.is_dir() and model_dir.name in self.MODELS_CONFIG:
                model_info = self.MODELS_CONFIG[model_dir.name].copy()
                model_info["name"] = model_dir.name
                model_info["cache_path"] = str(model_dir)
                model_info["cached"] = True

                # è®¡ç®—å®é™…ç¼“å­˜å¤§å°
                try:
                    size_bytes = sum(
                        f.stat().st_size for f in model_dir.rglob("*") if f.is_file()
                    )
                    model_info["actual_size_mb"] = round(size_bytes / (1024 * 1024), 2)
                except Exception:
                    model_info["actual_size_mb"] = "æœªçŸ¥"

                cached_models.append(model_info)

        return cached_models

    def list_all_models(self) -> List[Dict[str, Any]]:
        """åˆ—å‡ºæ‰€æœ‰æ”¯æŒçš„æ¨¡å‹ï¼ˆåŒ…æ‹¬æœªç¼“å­˜çš„ï¼‰"""
        all_models: List[Dict[str, Any]] = []
        cached_models = {m["name"] for m in self.list_cached_models()}

        for model_name, config in self.MODELS_CONFIG.items():
            model_info = config.copy()
            model_info["name"] = model_name
            model_info["cached"] = model_name in cached_models

            if model_info["cached"]:
                cache_path = self.cache_dir / model_name
                model_info["cache_path"] = str(cache_path)

            all_models.append(model_info)

        return all_models

    def download_all_models(
        self, force_download: bool = False
    ) -> Dict[str, Tuple[bool, str]]:
        """ä¸‹è½½æ‰€æœ‰é¡¹ç›®æ¨¡å‹"""
        results = {}

        logger.info("ğŸš€ å¼€å§‹ä¸‹è½½æ‰€æœ‰é¡¹ç›®æ¨¡å‹...")

        for model_name in self.MODELS_CONFIG.keys():
            logger.info(f"\nğŸ“¦ å¤„ç†æ¨¡å‹: {model_name}")
            success, message = self.download_model(model_name, force_download)
            results[model_name] = (success, message)

        return results

    def clear_cache(self, model_name: Optional[str] = None) -> bool:
        """æ¸…ç†æ¨¡å‹ç¼“å­˜"""
        try:
            if model_name:
                # æ¸…ç†ç‰¹å®šæ¨¡å‹
                model_path = self.cache_dir / model_name
                if model_path.exists():
                    shutil.rmtree(model_path)
                    logger.info(f"âœ… å·²æ¸…ç†æ¨¡å‹ç¼“å­˜: {model_name}")
                else:
                    logger.info(f"æ¨¡å‹ç¼“å­˜ä¸å­˜åœ¨: {model_name}")
            else:
                # æ¸…ç†æ‰€æœ‰ç¼“å­˜
                if self.cache_dir.exists():
                    shutil.rmtree(self.cache_dir)
                    self.cache_dir.mkdir(parents=True, exist_ok=True)
                    logger.info("âœ… å·²æ¸…ç†æ‰€æœ‰æ¨¡å‹ç¼“å­˜")

            return True

        except Exception as e:
            logger.error(f"âŒ æ¸…ç†ç¼“å­˜å¤±è´¥: {e}")
            return False

    def _update_model_info(self, model_name: str, model_path: Path) -> None:
        """æ›´æ–°æ¨¡å‹ä¿¡æ¯ç¼“å­˜"""
        try:
            # åŠ è½½ç°æœ‰ä¿¡æ¯
            if self.models_info_file.exists():
                with open(self.models_info_file, "r", encoding="utf-8") as f:
                    models_info = json.load(f)
            else:
                models_info = {}

            # æ›´æ–°æ¨¡å‹ä¿¡æ¯
            models_info[model_name] = {
                "cache_path": str(model_path),
                "downloaded_at": datetime.now().isoformat(),
                "config": self.MODELS_CONFIG.get(model_name, {}),
            }

            # ä¿å­˜æ›´æ–°åçš„ä¿¡æ¯
            with open(self.models_info_file, "w", encoding="utf-8") as f:
                json.dump(models_info, f, indent=2, ensure_ascii=False)

        except Exception as e:
            logger.warning(f"æ›´æ–°æ¨¡å‹ä¿¡æ¯å¤±è´¥: {e}")

    def get_cache_stats(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        stats: Dict[str, Any] = {
            "cache_dir": str(self.cache_dir),
            "total_models": len(self.MODELS_CONFIG),
            "cached_models": 0,
            "total_cache_size_mb": 0.0,
            "models": [],
        }

        if not self.cache_dir.exists():
            return stats

        cached_models = self.list_cached_models()
        stats["cached_models"] = len(cached_models)

        total_size: float = 0.0
        models_list: List[Dict[str, Any]] = []

        for model in cached_models:
            actual_size = model.get("actual_size_mb")
            if isinstance(actual_size, (int, float)):
                total_size += actual_size
            models_list.append(model)

        stats["total_cache_size_mb"] = round(total_size, 2)
        stats["models"] = models_list

        return stats


def print_models_table(models: List[Dict[str, Any]]) -> None:
    """æ‰“å°æ¨¡å‹è¡¨æ ¼"""
    print("\n" + "=" * 120)
    print(f"{'æ¨¡å‹åç§°':<40} {'çŠ¶æ€':<8} {'å¤§å°(MB)':<10} {'è¯­è¨€':<15} {'ç”¨é€”':<45}")
    print("=" * 120)

    for model in models:
        name = model["name"]
        cached = "âœ… å·²ç¼“å­˜" if model.get("cached", False) else "âŒ æœªç¼“å­˜"
        size = f"{model['size_mb']}"
        languages = ", ".join(model["languages"][:3])  # æ˜¾ç¤ºå‰3ç§è¯­è¨€
        if len(model["languages"]) > 3:
            languages += "..."
        use_case = (
            model["use_case"][:40] + "..."
            if len(model["use_case"]) > 40
            else model["use_case"]
        )

        print(f"{name:<40} {cached:<8} {size:<10} {languages:<15} {use_case:<45}")

    print("=" * 120)


def main() -> None:
    parser = argparse.ArgumentParser(
        description="SentenceTransformer æ¨¡å‹ä¸‹è½½å’Œç®¡ç†å·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # ä¸‹è½½æ‰€æœ‰é¡¹ç›®æ¨¡å‹
  python scripts/download_sentence_transformers_models.py --download-all
  
  # ä¸‹è½½ç‰¹å®šæ¨¡å‹
  python scripts/download_sentence_transformers_models.py --model paraphrase-multilingual-MiniLM-L12-v2
  
  # æŸ¥çœ‹æ‰€æœ‰æ¨¡å‹çŠ¶æ€
  python scripts/download_sentence_transformers_models.py --list-models
  
  # æŸ¥çœ‹ç¼“å­˜ç»Ÿè®¡
  python scripts/download_sentence_transformers_models.py --check-cache
  
  # æ¸…ç†æ‰€æœ‰ç¼“å­˜
  python scripts/download_sentence_transformers_models.py --clear-cache
        """,
    )

    parser.add_argument("--download-all", action="store_true", help="ä¸‹è½½æ‰€æœ‰é¡¹ç›®æ¨¡å‹")
    parser.add_argument("--model", type=str, help="ä¸‹è½½æŒ‡å®šæ¨¡å‹")
    parser.add_argument("--list-models", action="store_true", help="åˆ—å‡ºæ‰€æœ‰æ”¯æŒçš„æ¨¡å‹")
    parser.add_argument("--check-cache", action="store_true", help="æ£€æŸ¥ç¼“å­˜çŠ¶æ€")
    parser.add_argument("--clear-cache", action="store_true", help="æ¸…ç†æ‰€æœ‰æ¨¡å‹ç¼“å­˜")
    parser.add_argument("--force", action="store_true", help="å¼ºåˆ¶é‡æ–°ä¸‹è½½")
    parser.add_argument("--cache-dir", type=str, help="è‡ªå®šä¹‰ç¼“å­˜ç›®å½•")

    args = parser.parse_args()

    # åˆ›å»ºæ¨¡å‹ç®¡ç†å™¨
    cache_dir = Path(args.cache_dir) if args.cache_dir else None
    manager = SentenceTransformerModelManager(cache_dir)

    if args.download_all:
        print("ğŸš€ å¼€å§‹ä¸‹è½½æ‰€æœ‰é¡¹ç›®æ¨¡å‹...")
        results = manager.download_all_models(args.force)

        print("\nğŸ“Š ä¸‹è½½ç»“æœæ±‡æ€»:")
        print("=" * 80)
        for model_name, (success, message) in results.items():
            status = "âœ… æˆåŠŸ" if success else "âŒ å¤±è´¥"
            print(f"{model_name:<40} {status:<8} {message}")
        print("=" * 80)

    elif args.model:
        print(f"ğŸ“¦ ä¸‹è½½æ¨¡å‹: {args.model}")
        success, message = manager.download_model(args.model, args.force)
        status = "âœ… æˆåŠŸ" if success else "âŒ å¤±è´¥"
        print(f"{status}: {message}")

    elif args.list_models:
        models = manager.list_all_models()
        print("ğŸ“‹ æ‰€æœ‰æ”¯æŒçš„æ¨¡å‹:")
        print_models_table(models)

    elif args.check_cache:
        stats = manager.get_cache_stats()
        print("ğŸ“Š ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯:")
        print("=" * 60)
        print(f"ç¼“å­˜ç›®å½•: {stats['cache_dir']}")
        print(f"æ”¯æŒæ¨¡å‹æ€»æ•°: {stats['total_models']}")
        print(f"å·²ç¼“å­˜æ¨¡å‹æ•°: {stats['cached_models']}")
        print(f"ç¼“å­˜æ€»å¤§å°: {stats['total_cache_size_mb']} MB")

        if stats["models"]:
            print("\nå·²ç¼“å­˜çš„æ¨¡å‹:")
            print_models_table(stats["models"])
        else:
            print("\nâŒ æ²¡æœ‰å·²ç¼“å­˜çš„æ¨¡å‹")

    elif args.clear_cache:
        print("ğŸ—‘ï¸  æ¸…ç†æ‰€æœ‰æ¨¡å‹ç¼“å­˜...")
        if manager.clear_cache():
            print("âœ… ç¼“å­˜æ¸…ç†å®Œæˆ")
        else:
            print("âŒ ç¼“å­˜æ¸…ç†å¤±è´¥")

    else:
        parser.print_help()
        print("\nğŸ’¡ å»ºè®®é¦–å…ˆè¿è¡Œ: --download-all æ¥ä¸‹è½½æ‰€æœ‰é¡¹ç›®æ¨¡å‹")


if __name__ == "__main__":
    main()
