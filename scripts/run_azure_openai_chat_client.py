#!/usr/bin/env python3
"""
Azure OpenAI GPT-4oèŠå¤©ç³»ç»Ÿå¯åŠ¨è„šæœ¬

åŠŸèƒ½ï¼š
1. åŸºäºLangGraphæ„å»ºçš„Azure OpenAI GPT-4oèŠå¤©æœºå™¨äºº
2. æ”¯æŒè¿ç»­å¯¹è¯å’Œä¸Šä¸‹æ–‡è®°å¿†
3. æä¾›äº¤äº’å¼èŠå¤©ç•Œé¢

ä½¿ç”¨æ–¹æ³•ï¼š
    python scripts/run_azure_openai_chat.py

æˆ–è€…åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹ï¼š
    python -m scripts.run_azure_openai_chat
"""

import os
import sys
import traceback

# å°† src ç›®å½•æ·»åŠ åˆ°æ¨¡å—æœç´¢è·¯å¾„
sys.path.insert(
    0, os.path.join(os.path.dirname(os.path.abspath(__file__)), "..", "src")
)

# å¯¼å…¥å¿…è¦çš„æ¨¡å—
from langchain.schema import HumanMessage
from loguru import logger

from magic_book.azure_openai_gpt import (
    State,
    create_compiled_stage_graph,
    stream_graph_updates,
    create_azure_openai_gpt_llm,
)


def main() -> None:
    """
    Azure OpenAI GPT-4oèŠå¤©ç³»ç»Ÿä¸»å‡½æ•°

    åŠŸèƒ½ï¼š
    1. åˆå§‹åŒ–Azure OpenAI GPT-4oèŠå¤©æœºå™¨äºº
    2. æä¾›è¿ç»­å¯¹è¯èƒ½åŠ›
    3. æ”¯æŒä¸Šä¸‹æ–‡è®°å¿†
    4. ä¼˜é›…çš„é”™è¯¯å¤„ç†
    """
    logger.info("ğŸ¤– å¯åŠ¨Azure OpenAI GPT-4oèŠå¤©ç³»ç»Ÿ...")

    try:
        # ä¸ºæ¯ä¸ªä¼šè¯åˆ›å»ºç‹¬ç«‹çš„LLMå®ä¾‹
        llm = create_azure_openai_gpt_llm()

        # èŠå¤©å†å²ï¼ˆåŒ…å«LLMå®ä¾‹ï¼‰
        chat_history_state: State = {"messages": [], "llm": llm}

        # ç”ŸæˆèŠå¤©æœºå™¨äººçŠ¶æ€å›¾
        compiled_stage_graph = create_compiled_stage_graph(
            "azure_chat_openai_chatbot_node"
        )

        logger.success("ğŸ¤– Azure OpenAI GPT-4oèŠå¤©ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆï¼Œå¼€å§‹å¯¹è¯...")
        logger.info("ğŸ’¡ æç¤ºï¼šæ‚¨å¯ä»¥ä¸Azure OpenAI GPT-4oè¿›è¡Œè‡ªç”±å¯¹è¯")
        logger.info("ğŸ’¡ è¾“å…¥ /quitã€/exit æˆ– /q é€€å‡ºç¨‹åº")

        while True:
            try:
                print("\n" + "=" * 60)
                user_input = input("User: ")

                if user_input.lower() in ["/quit", "/exit", "/q"]:
                    print("Goodbye!")
                    break

                # ç”¨æˆ·è¾“å…¥
                user_input_state: State = {
                    "messages": [HumanMessage(content=user_input)],
                    "llm": llm,
                }

                # è·å–å›å¤
                update_messages = stream_graph_updates(
                    state_compiled_graph=compiled_stage_graph,
                    chat_history_state=chat_history_state,
                    user_input_state=user_input_state,
                )

                # æµ‹è¯•ç”¨ï¼šè®°å½•ä¸Šä¸‹æ–‡ã€‚
                chat_history_state["messages"].extend(user_input_state["messages"])
                chat_history_state["messages"].extend(update_messages)

                # æ˜¾ç¤ºæœ€æ–°çš„AIå›å¤
                if update_messages:
                    latest_response = update_messages[-1]
                    print(f"\nAzure-OpenAI-GPT4o: {latest_response.content}")

                logger.debug("*" * 50)
                for message in chat_history_state["messages"]:
                    if isinstance(message, HumanMessage):
                        logger.info(f"User: {message.content}")
                    else:
                        logger.success(f"Azure-OpenAI-GPT4o: {message.content}")

            except KeyboardInterrupt:
                logger.info("ğŸ›‘ [MAIN] ç”¨æˆ·ä¸­æ–­ç¨‹åº")
                break
            except Exception as e:
                logger.error(
                    f"âŒ Error in processing user input = {e}\n"
                    f"Traceback: {traceback.format_exc()}"
                )
                print("æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶å‘ç”Ÿé”™è¯¯ï¼Œè¯·é‡è¯•ã€‚")

    except Exception as e:
        logger.error(f"âŒ [MAIN] ç³»ç»Ÿå¯åŠ¨å¤±è´¥: {e}")
        print("ç³»ç»Ÿå¯åŠ¨å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç¯å¢ƒé…ç½®ã€‚")

    finally:
        logger.info("ğŸ”’ [MAIN] æ¸…ç†ç³»ç»Ÿèµ„æº...")


if __name__ == "__main__":
    main()
