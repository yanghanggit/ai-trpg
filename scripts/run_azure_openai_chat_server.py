#!/usr/bin/env python3
"""
Azure OpenAI Chat Serverå¯åŠ¨è„šæœ¬

åŠŸèƒ½ï¼š
1. åŸºäºFastAPIæ„å»ºçš„Azure OpenAI GPTèŠå¤©æœåŠ¡å™¨
2. æä¾›RESTful APIæ¥å£
3. æ”¯æŒèŠå¤©å†å²å’Œä¸Šä¸‹æ–‡è®°å¿†
4. å¼‚æ­¥å¤„ç†èŠå¤©è¯·æ±‚

ä½¿ç”¨æ–¹æ³•ï¼š
    python scripts/run_azure_openai_chat_server.py

æˆ–è€…åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹ï¼š
    python -m scripts.run_azure_openai_chat_server

APIç«¯ç‚¹ï¼š
    POST /api/chat/v1/
"""

import os
import sys
import asyncio
from typing import Any, Dict

# å°† src ç›®å½•æ·»åŠ åˆ°æ¨¡å—æœç´¢è·¯å¾„
sys.path.insert(
    0, os.path.join(os.path.dirname(os.path.abspath(__file__)), "..", "src")
)

from fastapi import FastAPI
from loguru import logger

from magic_book.chat_services.protocol import ChatRequest, ChatResponse
from magic_book.azure_openai_gpt import (
    State,
    create_compiled_stage_graph,
    stream_graph_updates,
    create_azure_openai_gpt_llm,
)

from magic_book.configuration import (
    server_configuration,
)

##################################################################################################################
# åˆå§‹åŒ– FastAPI åº”ç”¨
app = FastAPI(
    title="Azure OpenAI Chat Server",
    description="åŸºäºAzure OpenAI GPTçš„èŠå¤©æœåŠ¡å™¨",
    version="1.0.0",
)


##################################################################################################################
# å¥åº·æ£€æŸ¥ç«¯ç‚¹
@app.get("/")
async def health_check() -> Dict[str, Any]:
    """
    æœåŠ¡å™¨å¥åº·æ£€æŸ¥ç«¯ç‚¹

    Returns:
        dict: åŒ…å«æœåŠ¡å™¨çŠ¶æ€ä¿¡æ¯çš„å­—å…¸
    """
    from datetime import datetime

    return {
        "service": "Azure OpenAI Chat Server",
        "version": "1.0.0",
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "available_endpoints": [
            "GET /",
            "POST /api/chat/v1/",
        ],
        "description": "åŸºäºAzure OpenAIçš„èŠå¤©æœåŠ¡å™¨æ­£åœ¨æ­£å¸¸è¿è¡Œ",
    }


##################################################################################################################
# å®šä¹‰ POST è¯·æ±‚å¤„ç†é€»è¾‘
@app.post(
    path="/api/chat/v1/",
    response_model=ChatResponse,
)
async def process_chat_request(payload: ChatRequest) -> ChatResponse:
    """
    å¤„ç†èŠå¤©è¯·æ±‚

    Args:
        request: åŒ…å«èŠå¤©å†å²å’Œç”¨æˆ·æ¶ˆæ¯çš„è¯·æ±‚å¯¹è±¡

    Returns:
        ChatResponse: åŒ…å«AIå›å¤æ¶ˆæ¯çš„å“åº”å¯¹è±¡
    """
    try:
        logger.info(f"æ”¶åˆ°èŠå¤©è¯·æ±‚: {payload.message.content}")

        # ä¸ºæ¯ä¸ªè¯·æ±‚åˆ›å»ºç‹¬ç«‹çš„LLMå®ä¾‹
        llm = create_azure_openai_gpt_llm()

        # ä¸ºæ¯ä¸ªè¯·æ±‚åˆ›å»ºç‹¬ç«‹çš„çŠ¶æ€å›¾å®ä¾‹
        compiled_state_graph = create_compiled_stage_graph(
            "azure_chat_openai_chatbot_node"
        )

        # èŠå¤©å†å²ï¼ˆåŒ…å«LLMå®ä¾‹ï¼‰
        chat_history_state: State = {
            "messages": [message for message in payload.chat_history],
            "llm": llm,
        }

        # ç”¨æˆ·è¾“å…¥
        user_input_state: State = {"messages": [payload.message], "llm": llm}

        # è·å–å›å¤ - ä½¿ç”¨ asyncio.to_thread å°†é˜»å¡è°ƒç”¨åŒ…è£…ä¸ºå¼‚æ­¥
        update_messages = await asyncio.to_thread(
            stream_graph_updates,
            state_compiled_graph=compiled_state_graph,
            chat_history_state=chat_history_state,
            user_input_state=user_input_state,
        )

        logger.success(f"ç”Ÿæˆå›å¤æ¶ˆæ¯æ•°é‡: {len(update_messages)}")

        # æ‰“å°æ‰€æœ‰æ¶ˆæ¯çš„è¯¦ç»†å†…å®¹
        for i, message in enumerate(update_messages):
            logger.success(f"æ¶ˆæ¯ {i+1}: {message.model_dump_json(indent=2)}")

        # è¿”å›
        return ChatResponse(messages=update_messages)

    except Exception as e:
        logger.error(f"å¤„ç†èŠå¤©è¯·æ±‚æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        # è¿”å›é”™è¯¯æ¶ˆæ¯
        from langchain.schema import AIMessage

        error_message = AIMessage(content=f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
        return ChatResponse(messages=[error_message])


##################################################################################################################
def main() -> None:
    """
    Azure OpenAIèŠå¤©æœåŠ¡å™¨ä¸»å‡½æ•°

    åŠŸèƒ½ï¼š
    1. å¯åŠ¨FastAPIæœåŠ¡å™¨
    2. é…ç½®æœåŠ¡å™¨å‚æ•°
    3. æä¾›èŠå¤©APIæœåŠ¡
    """
    logger.info("ğŸš€ å¯åŠ¨Azure OpenAIèŠå¤©æœåŠ¡å™¨...")

    # åŠ è½½æœåŠ¡å™¨é…ç½®
    # server_config = initialize_server_settings_instance(
    #     Path("server_configuration.json")
    # )

    try:
        import uvicorn

        # å¯åŠ¨æœåŠ¡å™¨
        uvicorn.run(
            app,
            host="localhost",
            port=server_configuration.azure_openai_chat_server_port,
            log_level="debug",
        )

    except Exception as e:
        logger.error(f"âŒ å¯åŠ¨æœåŠ¡å™¨å¤±è´¥: {e}")
        raise


##################################################################################################################
if __name__ == "__main__":
    main()
