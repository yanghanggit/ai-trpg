"""
Excel æ–‡ä»¶æ“ä½œæµ‹è¯•æ¨¡å—

åŒ…å«CSVå’ŒExcelæ–‡ä»¶çš„è¯»å†™ã€è½¬æ¢å’ŒéªŒè¯åŠŸèƒ½æµ‹è¯•
"""

import pytest
import pandas as pd
from pathlib import Path
from typing import Optional, Generator
from loguru import logger
from datetime import datetime
import shutil
import tempfile
import os


# ================================
# pytest fixtures
# ================================


@pytest.fixture
def temp_dir() -> Generator[str, None, None]:
    """åˆ›å»ºä¸´æ—¶ç›®å½•è¿›è¡Œæµ‹è¯•"""
    with tempfile.TemporaryDirectory() as temp_dir:
        yield temp_dir


@pytest.fixture
def sample_dungeons_data() -> pd.DataFrame:
    """æä¾›ç¤ºä¾‹åœ°ç‰¢æ•°æ®"""
    return pd.DataFrame(
        [
            {
                "name": "æµ‹è¯•æ´çªŸ",
                "character_sheet_name": "test_cave",
                "stage_profile": "ä¸€ä¸ªç”¨äºæµ‹è¯•çš„ç¥ç§˜æ´çªŸï¼Œé‡Œé¢éšè—ç€æœªçŸ¥çš„å®è—å’Œå±é™©ã€‚",
            },
            {
                "name": "æš—å½±æ£®æ—",
                "character_sheet_name": "shadow_forest",
                "stage_profile": "å……æ»¡æš—å½±ç”Ÿç‰©çš„å±é™©æ£®æ—ï¼Œæ ‘æœ¨é«˜è€¸å…¥äº‘ï¼Œé˜³å…‰éš¾ä»¥ç©¿é€ã€‚",
            },
        ]
    )


@pytest.fixture
def sample_actors_data() -> pd.DataFrame:
    """æä¾›ç¤ºä¾‹è§’è‰²æ•°æ®"""
    return pd.DataFrame(
        [
            {
                "name": "æµ‹è¯•å“¥å¸ƒæ—",
                "character_sheet_name": "test_goblin",
                "actor_profile": "ä¸€ä¸ªç”¨äºæµ‹è¯•çš„å“¥å¸ƒæ—æˆ˜å£«ï¼Œè™½ç„¶å¼±å°ä½†ååˆ†ç‹¡çŒ¾ã€‚",
                "appearance": "ç»¿è‰²çš®è‚¤çš„å°å‹äººå½¢ç”Ÿç‰©ï¼ŒæŒæœ‰ç”Ÿé”ˆçš„çŸ­å‰‘ã€‚",
            },
            {
                "name": "æš—å½±ç‹¼",
                "character_sheet_name": "shadow_wolf",
                "actor_profile": "æ£®æ—ä¸­çš„æš—å½±ç”Ÿç‰©ï¼Œé€Ÿåº¦æå¿«ä¸”å–„äºéšè”½ã€‚",
                "appearance": "é»‘è‰²æ¯›å‘çš„å·¨å¤§ç‹¼ç±»ï¼Œçœ¼ä¸­é—ªçƒç€çº¢å…‰ã€‚",
            },
        ]
    )


@pytest.fixture
def test_files(temp_dir: str) -> dict[str, str]:
    """æä¾›æµ‹è¯•æ–‡ä»¶è·¯å¾„"""
    return {
        "excel_file": os.path.join(temp_dir, "test_excel_output.xlsx"),
        "dungeons_csv": os.path.join(temp_dir, "test_dungeons_data.csv"),
        "actors_csv": os.path.join(temp_dir, "test_actors_data.csv"),
    }


# ================================
# å·¥å…·å‡½æ•°
# ================================


def backup_file(file_path: str) -> bool:
    """åˆ›å»ºæ–‡ä»¶å¤‡ä»½"""
    try:
        if not Path(file_path).exists():
            return False
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_path = f"{file_path}.backup_{timestamp}"
        shutil.copy2(file_path, backup_path)
        logger.info(f"âœ… å·²åˆ›å»ºå¤‡ä»½: {backup_path}")
        return True
    except Exception as e:
        logger.error(f"âŒ å¤‡ä»½å¤±è´¥: {e}")
        return False


def read_csv_safe(file_path: str) -> Optional[pd.DataFrame]:
    """å®‰å…¨è¯»å–CSVæ–‡ä»¶"""
    try:
        if not Path(file_path).exists():
            logger.error(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            return None

        # å°è¯•ä¸åŒç¼–ç 
        encodings = ["utf-8-sig", "utf-8", "gbk", "gb2312"]
        for encoding in encodings:
            try:
                df = pd.read_csv(file_path, encoding=encoding)
                logger.info(f"æˆåŠŸè¯»å–CSV: {file_path} (ç¼–ç : {encoding})")
                logger.info(f"æ•°æ®å½¢çŠ¶: {df.shape}")
                return df
            except UnicodeDecodeError:
                continue

        logger.error(f"æ— æ³•è¯»å–CSVæ–‡ä»¶ï¼Œå°è¯•äº†æ‰€æœ‰ç¼–ç : {file_path}")
        return None
    except Exception as e:
        logger.error(f"è¯»å–CSVå¤±è´¥: {e}")
        return None


def save_csv_safe(df: pd.DataFrame, file_path: str) -> bool:
    """å®‰å…¨ä¿å­˜CSVæ–‡ä»¶"""
    try:
        # åˆ›å»ºå¤‡ä»½
        backup_file(file_path)
        # ä¿å­˜æ–°æ•°æ®
        df.to_csv(file_path, index=False, encoding="utf-8-sig")
        logger.info(f"âœ… æˆåŠŸä¿å­˜CSV: {file_path}")
        return True
    except Exception as e:
        logger.error(f"âŒ ä¿å­˜CSVå¤±è´¥: {e}")
        return False


def update_excel_from_csv(excel_file: str, dungeons_csv: str, actors_csv: str) -> bool:
    """ä»CSVæ–‡ä»¶æ›´æ–°Excelè¡¨æ ¼"""
    try:
        logger.info(f"å¼€å§‹æ›´æ–°Excelæ–‡ä»¶: {excel_file}")

        # åˆ›å»ºExcelæ–‡ä»¶å¤‡ä»½
        backup_file(excel_file)

        # è¯»å–CSVæ•°æ®
        dungeons_df = None
        actors_df = None

        if Path(dungeons_csv).exists():
            dungeons_df = read_csv_safe(dungeons_csv)
            if dungeons_df is not None:
                logger.info(f"è¯»å–åœ°ç‰¢æ•°æ®: {len(dungeons_df)} æ¡è®°å½•")

        if Path(actors_csv).exists():
            actors_df = read_csv_safe(actors_csv)
            if actors_df is not None:
                logger.info(f"è¯»å–è§’è‰²æ•°æ®: {len(actors_df)} æ¡è®°å½•")

        # å†™å…¥Excelæ–‡ä»¶
        with pd.ExcelWriter(excel_file, engine="openpyxl") as writer:
            has_data = False
            if dungeons_df is not None:
                dungeons_df.to_excel(writer, sheet_name="dungeons", index=False)
                logger.info("âœ… åœ°ç‰¢æ•°æ®å·²å†™å…¥Excel")
                has_data = True

            if actors_df is not None:
                actors_df.to_excel(writer, sheet_name="actors", index=False)
                logger.info("âœ… è§’è‰²æ•°æ®å·²å†™å…¥Excel")
                has_data = True

            # å¦‚æœæ²¡æœ‰ä»»ä½•æ•°æ®ï¼Œåˆ›å»ºä¸€ä¸ªç©ºçš„å·¥ä½œè¡¨
            if not has_data:
                empty_df = pd.DataFrame({"message": ["No data available"]})
                empty_df.to_excel(writer, sheet_name="empty", index=False)
                logger.info("â„¹ï¸ åˆ›å»ºäº†ç©ºçš„Excelå·¥ä½œè¡¨")

        logger.info(f"âœ… æˆåŠŸæ›´æ–°Excelæ–‡ä»¶: {excel_file}")
        return True
    except Exception as e:
        logger.error(f"âŒ æ›´æ–°Excelæ–‡ä»¶å¤±è´¥: {e}")
        return False


def convert_excel_to_csv(excel_file: str, dungeons_csv: str, actors_csv: str) -> bool:
    """å°†Excelæ–‡ä»¶è½¬æ¢ä¸ºCSVæ–‡ä»¶"""
    try:
        if not Path(excel_file).exists():
            logger.warning(f"Excelæ–‡ä»¶ä¸å­˜åœ¨: {excel_file}")
            return False

        logger.info(f"å¼€å§‹è½¬æ¢Excelæ–‡ä»¶ä¸ºCSV: {excel_file}")

        # è¯»å–Excelä¸­çš„åœ°ç‰¢æ•°æ®
        try:
            dungeons_df = pd.read_excel(excel_file, sheet_name="dungeons")
            dungeons_df.to_csv(dungeons_csv, index=False, encoding="utf-8-sig")
            logger.info(f"âœ… åœ°ç‰¢æ•°æ®å·²è½¬æ¢ä¸ºCSV: {dungeons_csv}")
        except Exception as e:
            logger.warning(f"æ— æ³•è¯»å–åœ°ç‰¢å·¥ä½œè¡¨: {e}")

        # è¯»å–Excelä¸­çš„è§’è‰²æ•°æ®
        try:
            actors_df = pd.read_excel(excel_file, sheet_name="actors")
            actors_df.to_csv(actors_csv, index=False, encoding="utf-8-sig")
            logger.info(f"âœ… è§’è‰²æ•°æ®å·²è½¬æ¢ä¸ºCSV: {actors_csv}")
        except Exception as e:
            logger.warning(f"æ— æ³•è¯»å–è§’è‰²å·¥ä½œè¡¨: {e}")

        return True
    except Exception as e:
        logger.error(f"âŒ Excelè½¬CSVå¤±è´¥: {e}")
        return False


def create_sample_csv_files(
    dungeons_csv: str,
    actors_csv: str,
    dungeons_data: pd.DataFrame,
    actors_data: pd.DataFrame,
) -> None:
    """åˆ›å»ºç¤ºä¾‹CSVæ–‡ä»¶ï¼ˆè‡ªå®šä¹‰æ–‡ä»¶åï¼‰"""
    logger.info(f"åˆ›å»ºç¤ºä¾‹CSVæ–‡ä»¶: {dungeons_csv}, {actors_csv}")

    # ä¿å­˜ä¸ºCSVæ–‡ä»¶
    dungeons_data.to_csv(dungeons_csv, index=False, encoding="utf-8-sig")
    actors_data.to_csv(actors_csv, index=False, encoding="utf-8-sig")


# ================================
# pytest æµ‹è¯•å‡½æ•°
# ================================


@pytest.mark.excel
def test_csv_file_creation(
    test_files: dict[str, str],
    sample_dungeons_data: pd.DataFrame,
    sample_actors_data: pd.DataFrame,
) -> None:
    """æµ‹è¯•CSVæ–‡ä»¶åˆ›å»º"""
    logger.info("ğŸ“ æµ‹è¯•CSVæ–‡ä»¶åˆ›å»º...")

    create_sample_csv_files(
        test_files["dungeons_csv"],
        test_files["actors_csv"],
        sample_dungeons_data,
        sample_actors_data,
    )

    assert Path(test_files["dungeons_csv"]).exists(), "åœ°ç‰¢CSVæ–‡ä»¶æœªåˆ›å»º"
    assert Path(test_files["actors_csv"]).exists(), "è§’è‰²CSVæ–‡ä»¶æœªåˆ›å»º"
    logger.info("âœ… CSVæ–‡ä»¶åˆ›å»ºæµ‹è¯•é€šè¿‡")


@pytest.mark.excel
def test_csv_file_reading(
    test_files: dict[str, str],
    sample_dungeons_data: pd.DataFrame,
    sample_actors_data: pd.DataFrame,
) -> None:
    """æµ‹è¯•CSVæ–‡ä»¶è¯»å–"""
    logger.info("ğŸ“– æµ‹è¯•CSVæ–‡ä»¶è¯»å–...")

    # å…ˆåˆ›å»ºæ–‡ä»¶
    create_sample_csv_files(
        test_files["dungeons_csv"],
        test_files["actors_csv"],
        sample_dungeons_data,
        sample_actors_data,
    )

    # è¯»å–æ–‡ä»¶
    dungeons_df = read_csv_safe(test_files["dungeons_csv"])
    actors_df = read_csv_safe(test_files["actors_csv"])

    assert dungeons_df is not None, "æ— æ³•è¯»å–åœ°ç‰¢CSVæ–‡ä»¶"
    assert actors_df is not None, "æ— æ³•è¯»å–è§’è‰²CSVæ–‡ä»¶"
    assert len(dungeons_df) == 2, f"åœ°ç‰¢æ•°æ®è¡Œæ•°ä¸æ­£ç¡®: {len(dungeons_df)}"
    assert len(actors_df) == 2, f"è§’è‰²æ•°æ®è¡Œæ•°ä¸æ­£ç¡®: {len(actors_df)}"

    logger.info(
        f"âœ… CSVæ–‡ä»¶è¯»å–æµ‹è¯•é€šè¿‡ - åœ°ç‰¢: {len(dungeons_df)}è¡Œ, è§’è‰²: {len(actors_df)}è¡Œ"
    )


@pytest.mark.excel
def test_data_content_validation(
    test_files: dict[str, str],
    sample_dungeons_data: pd.DataFrame,
    sample_actors_data: pd.DataFrame,
) -> None:
    """æµ‹è¯•æ•°æ®å†…å®¹éªŒè¯"""
    logger.info("ğŸ” æµ‹è¯•æ•°æ®å†…å®¹éªŒè¯...")

    # åˆ›å»ºæ–‡ä»¶
    create_sample_csv_files(
        test_files["dungeons_csv"],
        test_files["actors_csv"],
        sample_dungeons_data,
        sample_actors_data,
    )

    # è¯»å–å¹¶éªŒè¯
    dungeons_df = read_csv_safe(test_files["dungeons_csv"])
    actors_df = read_csv_safe(test_files["actors_csv"])

    assert dungeons_df is not None
    assert actors_df is not None

    # éªŒè¯æ•°æ®å†…å®¹
    expected_dungeons = ["æµ‹è¯•æ´çªŸ", "æš—å½±æ£®æ—"]
    expected_actors = ["æµ‹è¯•å“¥å¸ƒæ—", "æš—å½±ç‹¼"]

    actual_dungeons = dungeons_df["name"].tolist()
    actual_actors = actors_df["name"].tolist()

    assert actual_dungeons == expected_dungeons, f"åœ°ç‰¢åç§°ä¸åŒ¹é…: {actual_dungeons}"
    assert actual_actors == expected_actors, f"è§’è‰²åç§°ä¸åŒ¹é…: {actual_actors}"

    logger.info("âœ… æ•°æ®å†…å®¹éªŒè¯æµ‹è¯•é€šè¿‡")
    logger.info(f"   åœ°ç‰¢æ•°æ®: {actual_dungeons}")
    logger.info(f"   è§’è‰²æ•°æ®: {actual_actors}")


@pytest.mark.excel
def test_csv_to_excel_conversion(
    test_files: dict[str, str],
    sample_dungeons_data: pd.DataFrame,
    sample_actors_data: pd.DataFrame,
) -> None:
    """æµ‹è¯•CSVè½¬Excelæ–‡ä»¶"""
    logger.info("ğŸ’¾ æµ‹è¯•CSVè½¬Excelæ–‡ä»¶...")

    # åˆ›å»ºCSVæ–‡ä»¶
    create_sample_csv_files(
        test_files["dungeons_csv"],
        test_files["actors_csv"],
        sample_dungeons_data,
        sample_actors_data,
    )

    # è½¬æ¢ä¸ºExcel
    success = update_excel_from_csv(
        test_files["excel_file"], test_files["dungeons_csv"], test_files["actors_csv"]
    )

    assert success, "Excelæ–‡ä»¶åˆ›å»ºå¤±è´¥"
    assert Path(test_files["excel_file"]).exists(), "Excelæ–‡ä»¶ä¸å­˜åœ¨"

    logger.info("âœ… CSVè½¬Excelæ–‡ä»¶æµ‹è¯•é€šè¿‡")


@pytest.mark.excel
def test_excel_file_content_validation(
    test_files: dict[str, str],
    sample_dungeons_data: pd.DataFrame,
    sample_actors_data: pd.DataFrame,
) -> None:
    """æµ‹è¯•Excelæ–‡ä»¶å†…å®¹éªŒè¯"""
    logger.info("ğŸ”„ æµ‹è¯•Excelæ–‡ä»¶å†…å®¹éªŒè¯...")

    # åˆ›å»ºCSVæ–‡ä»¶å¹¶è½¬æ¢ä¸ºExcel
    create_sample_csv_files(
        test_files["dungeons_csv"],
        test_files["actors_csv"],
        sample_dungeons_data,
        sample_actors_data,
    )

    success = update_excel_from_csv(
        test_files["excel_file"], test_files["dungeons_csv"], test_files["actors_csv"]
    )
    assert success, "Excelæ–‡ä»¶åˆ›å»ºå¤±è´¥"

    # è¯»å–Excelæ–‡ä»¶å¹¶éªŒè¯
    excel_dungeons = pd.read_excel(test_files["excel_file"], sheet_name="dungeons")
    excel_actors = pd.read_excel(test_files["excel_file"], sheet_name="actors")

    # éªŒè¯æ•°æ®å®Œæ•´æ€§
    assert len(excel_dungeons) == 2, f"Excelåœ°ç‰¢æ•°æ®è¡Œæ•°ä¸æ­£ç¡®: {len(excel_dungeons)}"
    assert len(excel_actors) == 2, f"Excelè§’è‰²æ•°æ®è¡Œæ•°ä¸æ­£ç¡®: {len(excel_actors)}"

    # éªŒè¯å†…å®¹ä¸€è‡´æ€§
    expected_dungeons = ["æµ‹è¯•æ´çªŸ", "æš—å½±æ£®æ—"]
    expected_actors = ["æµ‹è¯•å“¥å¸ƒæ—", "æš—å½±ç‹¼"]

    actual_excel_dungeons = excel_dungeons["name"].tolist()
    actual_excel_actors = excel_actors["name"].tolist()

    assert (
        actual_excel_dungeons == expected_dungeons
    ), f"Excelåœ°ç‰¢åç§°ä¸åŒ¹é…: {actual_excel_dungeons}"
    assert (
        actual_excel_actors == expected_actors
    ), f"Excelè§’è‰²åç§°ä¸åŒ¹é…: {actual_excel_actors}"

    logger.info("âœ… Excelæ–‡ä»¶å†…å®¹éªŒè¯æµ‹è¯•é€šè¿‡")


@pytest.mark.excel
def test_excel_to_csv_conversion(
    test_files: dict[str, str],
    sample_dungeons_data: pd.DataFrame,
    sample_actors_data: pd.DataFrame,
) -> None:
    """æµ‹è¯•Excelè½¬CSVæ–‡ä»¶"""
    logger.info("ğŸ”„ æµ‹è¯•Excelè½¬CSVè½¬æ¢...")

    # å…ˆåˆ›å»ºExcelæ–‡ä»¶
    create_sample_csv_files(
        test_files["dungeons_csv"],
        test_files["actors_csv"],
        sample_dungeons_data,
        sample_actors_data,
    )

    update_excel_from_csv(
        test_files["excel_file"], test_files["dungeons_csv"], test_files["actors_csv"]
    )

    # åˆ é™¤åŸå§‹CSVæ–‡ä»¶
    Path(test_files["dungeons_csv"]).unlink()
    Path(test_files["actors_csv"]).unlink()

    # ä»Excelè½¬æ¢å›CSV
    new_dungeons_csv = test_files["dungeons_csv"].replace(".csv", "_new.csv")
    new_actors_csv = test_files["actors_csv"].replace(".csv", "_new.csv")

    success = convert_excel_to_csv(
        test_files["excel_file"], new_dungeons_csv, new_actors_csv
    )
    assert success, "Excelè½¬CSVå¤±è´¥"

    # éªŒè¯æ–°ç”Ÿæˆçš„CSVæ–‡ä»¶
    assert Path(new_dungeons_csv).exists(), "è½¬æ¢åçš„åœ°ç‰¢CSVæ–‡ä»¶ä¸å­˜åœ¨"
    assert Path(new_actors_csv).exists(), "è½¬æ¢åçš„è§’è‰²CSVæ–‡ä»¶ä¸å­˜åœ¨"

    # éªŒè¯å†…å®¹
    new_dungeons_df = read_csv_safe(new_dungeons_csv)
    new_actors_df = read_csv_safe(new_actors_csv)

    assert new_dungeons_df is not None and len(new_dungeons_df) == 2
    assert new_actors_df is not None and len(new_actors_df) == 2

    logger.info("âœ… Excelè½¬CSVè½¬æ¢æµ‹è¯•é€šè¿‡")


@pytest.mark.excel
@pytest.mark.integration
def test_comprehensive_excel_workflow(
    test_files: dict[str, str],
    sample_dungeons_data: pd.DataFrame,
    sample_actors_data: pd.DataFrame,
) -> None:
    """ç»¼åˆæµ‹è¯•ï¼šå®Œæ•´çš„Excelå·¥ä½œæµç¨‹"""
    logger.info("ğŸ¯ ç»¼åˆæµ‹è¯•ï¼šå®Œæ•´çš„Excelå·¥ä½œæµç¨‹...")

    # 1. åˆ›å»ºCSVæ–‡ä»¶
    create_sample_csv_files(
        test_files["dungeons_csv"],
        test_files["actors_csv"],
        sample_dungeons_data,
        sample_actors_data,
    )

    # 2. éªŒè¯CSVæ–‡ä»¶
    dungeons_df = read_csv_safe(test_files["dungeons_csv"])
    actors_df = read_csv_safe(test_files["actors_csv"])
    assert dungeons_df is not None and actors_df is not None

    # 3. è½¬æ¢ä¸ºExcel
    success = update_excel_from_csv(
        test_files["excel_file"], test_files["dungeons_csv"], test_files["actors_csv"]
    )
    assert success

    # 4. éªŒè¯Excelå†…å®¹
    excel_dungeons = pd.read_excel(test_files["excel_file"], sheet_name="dungeons")
    excel_actors = pd.read_excel(test_files["excel_file"], sheet_name="actors")
    assert len(excel_dungeons) == len(dungeons_df)
    assert len(excel_actors) == len(actors_df)

    # 5. ä»Excelè½¬æ¢å›CSV
    new_dungeons_csv = test_files["dungeons_csv"].replace(".csv", "_roundtrip.csv")
    new_actors_csv = test_files["actors_csv"].replace(".csv", "_roundtrip.csv")

    success = convert_excel_to_csv(
        test_files["excel_file"], new_dungeons_csv, new_actors_csv
    )
    assert success

    # 6. éªŒè¯å¾€è¿”è½¬æ¢çš„æ•°æ®ä¸€è‡´æ€§
    roundtrip_dungeons = read_csv_safe(new_dungeons_csv)
    roundtrip_actors = read_csv_safe(new_actors_csv)

    assert roundtrip_dungeons is not None and roundtrip_actors is not None
    assert len(roundtrip_dungeons) == len(dungeons_df)
    assert len(roundtrip_actors) == len(actors_df)

    # éªŒè¯åç§°ä¸€è‡´æ€§
    original_dungeon_names = dungeons_df["name"].tolist()
    roundtrip_dungeon_names = roundtrip_dungeons["name"].tolist()
    assert original_dungeon_names == roundtrip_dungeon_names

    original_actor_names = actors_df["name"].tolist()
    roundtrip_actor_names = roundtrip_actors["name"].tolist()
    assert original_actor_names == roundtrip_actor_names

    logger.info("âœ… ç»¼åˆExcelå·¥ä½œæµç¨‹æµ‹è¯•é€šè¿‡")


# ================================
# é”™è¯¯å¤„ç†æµ‹è¯•
# ================================


@pytest.mark.excel
@pytest.mark.error_handling
def test_read_nonexistent_csv() -> None:
    """æµ‹è¯•è¯»å–ä¸å­˜åœ¨çš„CSVæ–‡ä»¶"""
    result = read_csv_safe("nonexistent_file.csv")
    assert result is None, "è¯»å–ä¸å­˜åœ¨æ–‡ä»¶åº”è¯¥è¿”å›None"


@pytest.mark.excel
@pytest.mark.error_handling
def test_excel_conversion_with_missing_csv(test_files: dict[str, str]) -> None:
    """æµ‹è¯•å½“CSVæ–‡ä»¶ä¸å­˜åœ¨æ—¶çš„Excelè½¬æ¢"""
    # ç¡®ä¿æ–‡ä»¶ä¸å­˜åœ¨
    assert not Path(test_files["dungeons_csv"]).exists()
    assert not Path(test_files["actors_csv"]).exists()

    # å°è¯•è½¬æ¢ä¸å­˜åœ¨çš„CSVæ–‡ä»¶
    success = update_excel_from_csv(
        test_files["excel_file"], test_files["dungeons_csv"], test_files["actors_csv"]
    )

    # åº”è¯¥åˆ›å»ºä¸€ä¸ªç©ºçš„Excelæ–‡ä»¶
    assert success, "å³ä½¿CSVæ–‡ä»¶ä¸å­˜åœ¨ï¼Œä¹Ÿåº”è¯¥èƒ½åˆ›å»ºExcelæ–‡ä»¶"


# ================================
# æ€§èƒ½æµ‹è¯•ï¼ˆå¯é€‰ï¼‰
# ================================


@pytest.mark.excel
@pytest.mark.slow
@pytest.mark.skip(reason="æ€§èƒ½æµ‹è¯•ï¼Œé€šå¸¸ä¸éœ€è¦è¿è¡Œ")
def test_large_dataset_performance(temp_dir: str) -> None:
    """æµ‹è¯•å¤§æ•°æ®é›†çš„æ€§èƒ½"""
    logger.info("ğŸš€ æ€§èƒ½æµ‹è¯•ï¼šå¤§æ•°æ®é›†å¤„ç†...")

    # åˆ›å»ºå¤§é‡æ•°æ®
    large_data = pd.DataFrame(
        {
            "name": [f"é¡¹ç›®_{i}" for i in range(10000)],
            "character_sheet_name": [f"sheet_{i}" for i in range(10000)],
            "stage_profile": [f"æè¿°_{i}" for i in range(10000)],
        }
    )

    csv_file = os.path.join(temp_dir, "large_test.csv")
    excel_file = os.path.join(temp_dir, "large_test.xlsx")

    # æµ‹è¯•å¤§æ–‡ä»¶ä¿å­˜
    start_time = datetime.now()
    large_data.to_csv(csv_file, index=False, encoding="utf-8-sig")
    csv_time = (datetime.now() - start_time).total_seconds()

    # æµ‹è¯•Excelè½¬æ¢
    start_time = datetime.now()
    with pd.ExcelWriter(excel_file, engine="openpyxl") as writer:
        large_data.to_excel(writer, sheet_name="large_data", index=False)
    excel_time = (datetime.now() - start_time).total_seconds()

    logger.info(f"CSVä¿å­˜æ—¶é—´: {csv_time:.2f}ç§’")
    logger.info(f"Excelä¿å­˜æ—¶é—´: {excel_time:.2f}ç§’")

    # åŸºæœ¬çš„æ€§èƒ½æ–­è¨€
    assert csv_time < 10, f"CSVä¿å­˜æ—¶é—´è¿‡é•¿: {csv_time}ç§’"
    assert excel_time < 30, f"Excelä¿å­˜æ—¶é—´è¿‡é•¿: {excel_time}ç§’"


if __name__ == "__main__":
    # å¯ä»¥ç›´æ¥è¿è¡Œpytest
    pytest.main([__file__, "-v"])
