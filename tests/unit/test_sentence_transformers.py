"""
Comprehensive tests for sentence-transformers functionality.

This test suite ensures that sentence-transformers is properly installed
and functioning correctly in the current environment. It includes both
pytest-compatible unit tests and manual test functions for direct execution.
"""

import pytest
import numpy as np
import sys
from typing import List, Callable, Any

# å¯¼å…¥åµŒå…¥æ¨¡å‹æ¨¡å—
try:
    from src.ai_trpg.embedding_model import (
        multilingual_model,
        cache_path,
        is_model_cached,
    )
    from sentence_transformers import SentenceTransformer

    USE_EMBEDDING_MODULE = True
except ImportError:
    # å¦‚æœå¯¼å…¥å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æ–¹å¼
    USE_EMBEDDING_MODULE = False
    print("âš ï¸  åµŒå…¥æ¨¡å‹æ¨¡å—ä¸å¯ç”¨ï¼Œå°†ç›´æ¥ä»ç½‘ç»œä¸‹è½½æ¨¡å‹")


# Global fixtures for model caching to improve test performance
@pytest.fixture(scope="session")
def basic_model() -> "SentenceTransformer":
    """Load the basic English model once per test session."""
    from sentence_transformers import SentenceTransformer

    print("\nğŸ”„ Loading basic model (all-MiniLM-L6-v2)...")

    if USE_EMBEDDING_MODULE:
        # ä½¿ç”¨ç¼“å­˜è·¯å¾„åŠ è½½æ¨¡å‹
        model_name = "all-MiniLM-L6-v2"
        if is_model_cached(model_name):
            model = SentenceTransformer(str(cache_path(model_name)))
            print("âœ… Basic model loaded from cache")
            assert isinstance(model, SentenceTransformer)
            return model
        else:
            print("âš ï¸  æ¨¡å‹æœªç¼“å­˜ï¼Œä»ç½‘ç»œä¸‹è½½...")

    # å›é€€åˆ°ç›´æ¥ä¸‹è½½
    model = SentenceTransformer("all-MiniLM-L6-v2")
    print("âœ… Basic model loaded and cached")
    return model


@pytest.fixture(scope="session")
def multilingual_model_fixture() -> "SentenceTransformer":
    """Load the multilingual model once per test session."""
    from sentence_transformers import SentenceTransformer

    print("\nğŸ”„ Loading multilingual model (paraphrase-multilingual-MiniLM-L12-v2)...")

    if USE_EMBEDDING_MODULE:
        # ç›´æ¥ä½¿ç”¨é¢„åŠ è½½çš„å…¨å±€æ¨¡å‹å®ä¾‹
        print("âœ… Multilingual model loaded from module (pre-loaded)")
        assert isinstance(multilingual_model, SentenceTransformer)
        return multilingual_model
    else:
        print("âš ï¸  åµŒå…¥æ¨¡å‹æ¨¡å—ä¸å¯ç”¨ï¼Œå›é€€åˆ°ç›´æ¥ä¸‹è½½")
        # å›é€€åˆ°ç›´æ¥ä¸‹è½½
        model = SentenceTransformer("paraphrase-multilingual-MiniLM-L12-v2")
        print("âœ… Multilingual model loaded and cached")
        return model


@pytest.fixture(scope="session")
def cos_sim_func() -> Callable[..., Any]:
    """Import cos_sim function once per test session."""
    from sentence_transformers.util import cos_sim

    return cos_sim


class TestSentenceTransformersBasic:
    """Basic functionality tests for sentence-transformers."""

    def test_import_sentence_transformers(self) -> None:
        """Test that sentence-transformers can be imported successfully."""
        try:
            import sentence_transformers
            from sentence_transformers import SentenceTransformer
            from sentence_transformers.util import cos_sim

            assert True, "Successfully imported sentence-transformers"
        except ImportError as e:
            pytest.fail(f"Failed to import sentence-transformers: {e}")

    def test_load_model_basic(self, basic_model: Any) -> None:
        """Test basic model functionality using cached model."""
        assert basic_model is not None
        assert hasattr(basic_model, "encode")

    def test_encode_single_sentence(self, basic_model: Any) -> None:
        """Test encoding a single sentence using cached model."""
        test_sentence = "This is a test sentence."
        embedding = basic_model.encode(test_sentence)

        assert isinstance(embedding, np.ndarray)
        assert len(embedding.shape) == 1  # 1D array for single sentence
        assert embedding.shape[0] > 0  # Non-empty embedding
        assert not np.isnan(embedding).any()  # No NaN values

    def test_encode_multiple_sentences(self, basic_model: Any) -> None:
        """Test encoding multiple sentences using cached model."""
        test_sentences = [
            "This is the first sentence.",
            "This is the second sentence.",
            "This is a completely different sentence.",
        ]

        embeddings = basic_model.encode(test_sentences)

        assert isinstance(embeddings, np.ndarray)
        assert len(embeddings.shape) == 2  # 2D array for multiple sentences
        assert embeddings.shape[0] == len(test_sentences)
        assert embeddings.shape[1] > 0  # Non-empty embeddings
        assert not np.isnan(embeddings).any()  # No NaN values

    def test_similarity_computation(
        self, basic_model: Any, cos_sim_func: Callable[..., Any]
    ) -> None:
        """Test computing similarity between sentences using cached model."""
        # Similar sentences
        sentence1 = "The cat is sleeping on the mat."
        sentence2 = "A cat is lying on a mat."

        # Different sentence
        sentence3 = "The weather is very nice today."

        embeddings = basic_model.encode([sentence1, sentence2, sentence3])

        # Compute similarities
        sim_1_2 = cos_sim_func(embeddings[0], embeddings[1])
        sim_1_3 = cos_sim_func(embeddings[0], embeddings[2])

        # Extract scalar values from tensors
        sim_1_2_value = sim_1_2.item()
        sim_1_3_value = sim_1_3.item()

        # Similar sentences should have higher similarity
        assert sim_1_2_value > sim_1_3_value
        assert -1 <= sim_1_2_value <= 1  # Cosine similarity should be between -1 and 1
        assert -1 <= sim_1_3_value <= 1


class TestSentenceTransformersGameContext:
    """Tests for sentence-transformers with game-specific content."""

    @pytest.fixture
    def game_knowledge_base(self) -> List[str]:
        """Sample game knowledge base for testing."""
        return [
            "è‰¾å°”æ³•å°¼äºšå¤§é™†åˆ†ä¸ºä¸‰å¤§ç‹å›½ï¼šäººç±»çš„é˜¿æ–¯ç‰¹æ‹‰ç‹å›½ã€ç²¾çµçš„æœˆæ¡‚æ£®æ—è”é‚¦ã€å…½äººçš„é“çˆªéƒ¨æ—è”ç›Ÿã€‚",
            "æ™¨æ›¦ä¹‹åˆƒæ˜¯ä¼ è¯´ä¸­çš„åœ£å‰‘ï¼Œå‰‘èº«ç”±æ˜Ÿè¾°é’¢æ‰“é€ ï¼Œå‰‘æŸ„é•¶åµŒç€å…‰æ˜ç¥çš„çœ¼æ³ªç»“æ™¶ã€‚",
            "é»‘æš—é­”ç‹é˜¿å·´é¡¿æ›¾ç»ç»Ÿæ²»è‰¾å°”æ³•å°¼äºšå¤§é™†ï¼Œå°†å…¶å˜æˆæ­»äº¡ä¸ç»æœ›çš„åœŸåœ°ã€‚",
            "äººç±»ä»¥é˜¿æ–¯ç‰¹æ‹‰ç‹å›½ä¸ºä¸­å¿ƒï¼Œæ“…é•¿é”»é€ å’Œè´¸æ˜“ï¼Œä»–ä»¬çš„éª‘å£«å›¢ä»¥é‡ç”²å’Œé•¿å‰‘é—»åã€‚",
            "ç²¾çµå±…ä½åœ¨æœˆæ¡‚æ£®æ—ï¼Œå¯¿å‘½å¯è¾¾åƒå¹´ï¼Œæ˜¯æœ€ä¼˜ç§€çš„å¼“ç®­æ‰‹å’Œè‡ªç„¶é­”æ³•å¸ˆã€‚",
            "å¤±è½çš„è´¤è€…ä¹‹å¡”ï¼šå¤ä»£é­”æ³•å¸ˆçš„ç ”ç©¶æ‰€ï¼Œå†…è—å¼ºå¤§çš„é­”æ³•é“å…·å’Œç¦å¿ŒçŸ¥è¯†ã€‚",
        ]

    def test_chinese_text_encoding(
        self, game_knowledge_base: List[str], multilingual_model_fixture: Any
    ) -> None:
        """Test encoding Chinese game content using cached model."""
        embeddings = multilingual_model_fixture.encode(game_knowledge_base)

        assert isinstance(embeddings, np.ndarray)
        assert embeddings.shape[0] == len(game_knowledge_base)
        assert embeddings.shape[1] > 0
        assert not np.isnan(embeddings).any()

    def test_semantic_search_simulation(
        self,
        game_knowledge_base: List[str],
        multilingual_model_fixture: Any,
        cos_sim_func: Callable[..., Any],
    ) -> None:
        """Test simulating semantic search functionality using cached model."""
        # Encode knowledge base
        kb_embeddings = multilingual_model_fixture.encode(game_knowledge_base)

        # Test queries
        queries = [
            "åœ£å‰‘çš„ä¿¡æ¯",  # Should match info about æ™¨æ›¦ä¹‹åˆƒ
            "ç‹å›½æœ‰å“ªäº›",  # Should match info about kingdoms
            "ç²¾çµçš„ç‰¹ç‚¹",  # Should match info about elves
        ]

        for query in queries:
            query_embedding = multilingual_model_fixture.encode([query])
            similarities = cos_sim_func(query_embedding, kb_embeddings)[0]

            # Find most similar document
            best_match_idx = int(similarities.argmax().item())
            best_similarity = similarities[best_match_idx].item()

            assert 0 <= best_similarity <= 1
            assert best_match_idx < len(game_knowledge_base)

            # The similarity should be reasonable (> 0.1 for related content)
            assert (
                best_similarity > 0.1
            ), f"Query '{query}' has low similarity ({best_similarity})"

    def test_document_ranking(
        self,
        game_knowledge_base: List[str],
        multilingual_model_fixture: Any,
        cos_sim_func: Callable[..., Any],
    ) -> None:
        """Test ranking documents by relevance using cached model."""
        # Encode knowledge base
        kb_embeddings = multilingual_model_fixture.encode(game_knowledge_base)

        # Query about sword/weapon
        query = "æ­¦å™¨å’Œå‰‘çš„ä¿¡æ¯"
        query_embedding = multilingual_model_fixture.encode([query])

        similarities = cos_sim_func(query_embedding, kb_embeddings)[0]

        # Get top 3 most relevant documents
        top_indices = similarities.argsort(descending=True)[:3]
        top_similarities = similarities[top_indices]

        # Check that similarities are in descending order
        for i in range(len(top_similarities) - 1):
            assert top_similarities[i] >= top_similarities[i + 1]

        # The top result should be reasonably relevant
        assert top_similarities[0] > 0.2


class TestSentenceTransformersPerformance:
    """Performance and resource usage tests."""

    def test_model_memory_usage(self, basic_model: Any) -> None:
        """Test that model doesn't consume excessive memory using cached model."""
        import psutil
        import os

        # Get current memory usage (model already loaded in fixture)
        process = psutil.Process(os.getpid())
        current_memory = process.memory_info().rss / 1024 / 1024  # MB

        # Use the model to ensure it's active
        test_embedding = basic_model.encode("Memory test sentence")

        # Memory should be reasonable (models are already loaded)
        if current_memory >= 2000:
            print(f"âš ï¸  WARNING: Total memory usage is high: {current_memory:.2f}MB")
        else:
            print(f"âœ… Memory usage is reasonable: {current_memory:.2f}MB")

        assert test_embedding.shape[0] > 0  # Ensure model works

    def test_encoding_speed(self, basic_model: Any) -> None:
        """Test encoding speed for reasonable performance using cached model."""
        import time

        # Test sentences
        sentences = [f"This is test sentence number {i}." for i in range(100)]

        # Measure encoding time (model already loaded)
        start_time = time.time()
        embeddings = basic_model.encode(sentences)
        end_time = time.time()

        encoding_time = end_time - start_time
        sentences_per_second = len(sentences) / encoding_time

        # Should be much faster with pre-loaded model
        assert (
            sentences_per_second > 20
        ), f"Encoding too slow: {sentences_per_second:.2f} sentences/sec"


class TestSentenceTransformersErrorHandling:
    """Test error handling and edge cases."""

    def test_empty_input(self, basic_model: Any) -> None:
        """Test handling of empty input using cached model."""
        # Empty string
        embedding = basic_model.encode("")
        assert isinstance(embedding, np.ndarray)
        assert embedding.shape[0] > 0

        # Empty list
        embeddings = basic_model.encode([])
        assert isinstance(embeddings, np.ndarray)
        assert embeddings.shape[0] == 0

    def test_very_long_text(self, basic_model: Any) -> None:
        """Test handling of very long text using cached model."""
        # Very long text (beyond typical token limits)
        long_text = "This is a test sentence. " * 1000

        try:
            embedding = basic_model.encode(long_text)
            assert isinstance(embedding, np.ndarray)
            assert embedding.shape[0] > 0
        except Exception as e:
            # If it fails, it should fail gracefully
            assert "token" in str(e).lower() or "length" in str(e).lower()

    def test_special_characters(self, multilingual_model_fixture: Any) -> None:
        """Test handling of special characters and mixed languages using cached model."""
        special_texts = [
            "Hello ä¸–ç•Œ! ğŸŒ",
            "Special chars: @#$%^&*()",
            "Numbers: 123456789",
            "Ã‰mojis and aÃ§cÃ©nts",
            "ğŸš€ğŸ®ğŸ†âš”ï¸ğŸ›¡ï¸",
        ]

        for text in special_texts:
            embedding = multilingual_model_fixture.encode(text)
            assert isinstance(embedding, np.ndarray)
            assert embedding.shape[0] > 0
            assert not np.isnan(embedding).any()


if __name__ == "__main__":
    # Manual test functions for direct execution
    def test_basic_functionality() -> bool:
        """Test basic sentence-transformers functionality."""
        print("=" * 60)
        print("Testing sentence-transformers Basic Functionality")
        print("=" * 60)

        try:
            # Test 1: Import
            print("1. Testing import...")
            from sentence_transformers import SentenceTransformer
            from sentence_transformers.util import cos_sim

            print("âœ… Import successful")

            # Test 2: Load model
            print("\n2. Testing model loading...")
            if USE_EMBEDDING_MODULE:
                model_name = "all-MiniLM-L6-v2"
                if is_model_cached(model_name):
                    model = SentenceTransformer(str(cache_path(model_name)))
                else:
                    # å›é€€åˆ°ç›´æ¥åŠ è½½
                    model = SentenceTransformer("all-MiniLM-L6-v2")
            else:
                model = SentenceTransformer("all-MiniLM-L6-v2")
            print("âœ… Model loaded successfully")

            # Test 3: Encode single sentence
            print("\n3. Testing single sentence encoding...")
            sentence = "This is a test sentence."
            embedding = model.encode(sentence)
            print(f"âœ… Encoded sentence: '{sentence}'")
            print(f"   Embedding shape: {embedding.shape}")
            print(f"   Embedding type: {type(embedding)}")

            # Test 4: Encode multiple sentences
            print("\n4. Testing multiple sentence encoding...")
            sentences = [
                "This is the first sentence.",
                "This is the second sentence.",
                "This is a different sentence.",
            ]
            embeddings = model.encode(sentences)
            print(f"âœ… Encoded {len(sentences)} sentences")
            print(f"   Embeddings shape: {embeddings.shape}")

            # Test 5: Similarity computation
            print("\n5. Testing similarity computation...")
            sim_1_2 = cos_sim(embeddings[0], embeddings[1])
            sim_1_3 = cos_sim(embeddings[0], embeddings[2])
            print(f"âœ… Similarity between sentence 1 and 2: {sim_1_2.item():.4f}")
            print(f"âœ… Similarity between sentence 1 and 3: {sim_1_3.item():.4f}")

            return True

        except Exception as e:
            print(f"âŒ Test failed: {e}")
            import traceback

            traceback.print_exc()
            return False

    def test_game_context() -> bool:
        """Test with game-specific content."""
        print("\n" + "=" * 60)
        print("Testing Game Context Functionality")
        print("=" * 60)

        try:
            from sentence_transformers import SentenceTransformer
            from sentence_transformers.util import cos_sim
            import numpy as np

            # Use multilingual model for Chinese content
            print("1. Loading multilingual model...")
            if USE_EMBEDDING_MODULE:
                # ç›´æ¥ä½¿ç”¨é¢„åŠ è½½çš„å…¨å±€æ¨¡å‹å®ä¾‹
                from src.ai_trpg.embedding_model import multilingual_model as model

                print("âœ… Using pre-loaded multilingual model from module")
            else:
                # å›é€€åˆ°ç›´æ¥åŠ è½½
                model = SentenceTransformer("paraphrase-multilingual-MiniLM-L12-v2")
                print("âœ… Multilingual model loaded")

            # Game knowledge base
            knowledge_base = [
                "è‰¾å°”æ³•å°¼äºšå¤§é™†åˆ†ä¸ºä¸‰å¤§ç‹å›½ï¼šäººç±»çš„é˜¿æ–¯ç‰¹æ‹‰ç‹å›½ã€ç²¾çµçš„æœˆæ¡‚æ£®æ—è”é‚¦ã€å…½äººçš„é“çˆªéƒ¨æ—è”ç›Ÿã€‚",
                "æ™¨æ›¦ä¹‹åˆƒæ˜¯ä¼ è¯´ä¸­çš„åœ£å‰‘ï¼Œå‰‘èº«ç”±æ˜Ÿè¾°é’¢æ‰“é€ ï¼Œå‰‘æŸ„é•¶åµŒç€å…‰æ˜ç¥çš„çœ¼æ³ªç»“æ™¶ã€‚",
                "é»‘æš—é­”ç‹é˜¿å·´é¡¿æ›¾ç»ç»Ÿæ²»è‰¾å°”æ³•å°¼äºšå¤§é™†ï¼Œå°†å…¶å˜æˆæ­»äº¡ä¸ç»æœ›çš„åœŸåœ°ã€‚",
                "äººç±»ä»¥é˜¿æ–¯ç‰¹æ‹‰ç‹å›½ä¸ºä¸­å¿ƒï¼Œæ“…é•¿é”»é€ å’Œè´¸æ˜“ï¼Œä»–ä»¬çš„éª‘å£«å›¢ä»¥é‡ç”²å’Œé•¿å‰‘é—»åã€‚",
                "ç²¾çµå±…ä½åœ¨æœˆæ¡‚æ£®æ—ï¼Œå¯¿å‘½å¯è¾¾åƒå¹´ï¼Œæ˜¯æœ€ä¼˜ç§€çš„å¼“ç®­æ‰‹å’Œè‡ªç„¶é­”æ³•å¸ˆã€‚",
            ]

            print(f"\n2. Encoding knowledge base ({len(knowledge_base)} documents)...")
            kb_embeddings = model.encode(knowledge_base)
            print(f"âœ… Knowledge base encoded: {kb_embeddings.shape}")

            # Test queries
            queries = [
                "åœ£å‰‘çš„ä¿¡æ¯",
                "ç‹å›½æœ‰å“ªäº›",
                "ç²¾çµçš„ç‰¹ç‚¹",
            ]

            print(f"\n3. Testing semantic search with {len(queries)} queries...")
            for i, query in enumerate(queries):
                print(f"\n   Query {i+1}: '{query}'")
                query_embedding = model.encode([query])
                similarities = cos_sim(query_embedding, kb_embeddings)[0]

                # Find best match
                best_idx = int(similarities.argmax().item())
                best_sim = similarities[best_idx].item()

                print(f"   Best match (similarity: {best_sim:.4f}):")
                print(f"   '{knowledge_base[best_idx][:50]}...'")

            print("âœ… Semantic search functionality working correctly")
            return True

        except Exception as e:
            print(f"âŒ Game context test failed: {e}")
            import traceback

            traceback.print_exc()
            return False

    def test_performance() -> bool:
        """Test basic performance metrics."""
        print("\n" + "=" * 60)
        print("Testing Performance")
        print("=" * 60)

        try:
            import time
            from sentence_transformers import SentenceTransformer

            print("1. Testing encoding speed...")
            if USE_EMBEDDING_MODULE:
                model_name = "all-MiniLM-L6-v2"
                if is_model_cached(model_name):
                    model = SentenceTransformer(str(cache_path(model_name)))
                else:
                    # å›é€€åˆ°ç›´æ¥åŠ è½½
                    model = SentenceTransformer("all-MiniLM-L6-v2")
            else:
                model = SentenceTransformer("all-MiniLM-L6-v2")

            # Test sentences
            test_sentences = [f"This is test sentence number {i}." for i in range(50)]

            start_time = time.time()
            embeddings = model.encode(test_sentences)
            end_time = time.time()

            encoding_time = end_time - start_time
            sentences_per_second = len(test_sentences) / encoding_time

            print(
                f"âœ… Encoded {len(test_sentences)} sentences in {encoding_time:.2f} seconds"
            )
            print(f"âœ… Speed: {sentences_per_second:.2f} sentences/second")

            if sentences_per_second > 5:  # Reasonable threshold
                print("âœ… Performance is acceptable")
            else:
                print("âš ï¸  Performance might be slow but functional")

            return True

        except Exception as e:
            print(f"âŒ Performance test failed: {e}")
            return False

    def run_manual_tests() -> bool:
        """Run all manual tests."""
        print("Starting sentence-transformers comprehensive test suite...")
        print(f"Python version: {sys.version}")
        print(f"Test script location: {__file__}")

        tests = [
            ("Basic Functionality", test_basic_functionality),
            ("Game Context", test_game_context),
            ("Performance", test_performance),
        ]

        results = {}
        for test_name, test_func in tests:
            print(f"\n{'='*80}")
            print(f"Running {test_name} Tests")
            print(f"{'='*80}")

            try:
                results[test_name] = test_func()
            except Exception as e:
                print(f"âŒ {test_name} test suite failed with exception: {e}")
                results[test_name] = False

        # Summary
        print(f"\n{'='*80}")
        print("TEST SUMMARY")
        print(f"{'='*80}")

        all_passed = True
        for test_name, passed in results.items():
            status = "âœ… PASSED" if passed else "âŒ FAILED"
            print(f"{test_name:20}: {status}")
            if not passed:
                all_passed = False

        print(f"\n{'='*80}")
        if all_passed:
            print(
                "ğŸ‰ ALL TESTS PASSED! sentence-transformers is ready for integration."
            )
        else:
            print("âš ï¸  Some tests failed. Please check the output above.")
        print(f"{'='*80}")

        return all_passed

    # Determine execution mode
    if len(sys.argv) > 1 and sys.argv[1] == "--manual":
        # Manual test mode
        success = run_manual_tests()
        sys.exit(0 if success else 1)
    else:
        # Basic smoke test when executed directly without arguments
        print("Running sentence-transformers smoke test...")
        print("Use --manual flag for comprehensive manual tests")

        try:
            if USE_EMBEDDING_MODULE:
                model_name = "all-MiniLM-L6-v2"
                if is_model_cached(model_name):
                    model = SentenceTransformer(str(cache_path(model_name)))
                else:
                    # å›é€€åˆ°ç›´æ¥åŠ è½½
                    from sentence_transformers import SentenceTransformer

                    model = SentenceTransformer("all-MiniLM-L6-v2")
            else:
                from sentence_transformers import SentenceTransformer

                model = SentenceTransformer("all-MiniLM-L6-v2")

            test_sentence = "Hello, world!"
            embedding = model.encode(test_sentence)

            print(f"âœ… Successfully encoded sentence: '{test_sentence}'")
            print(f"âœ… Embedding shape: {embedding.shape}")
            print(f"âœ… Embedding sample: {embedding[:5]}")
            print("âœ… Basic smoke test passed!")
            print("\nğŸ’¡ Run with --manual flag for comprehensive testing:")
            print(f"   python {__file__} --manual")

        except Exception as e:
            print(f"âŒ Smoke test failed: {e}")
            sys.exit(1)
