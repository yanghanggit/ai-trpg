"""
pgvector ç»¼åˆæµ‹è¯•å’Œæ¼”ç¤ºæ–‡ä»¶
åˆå¹¶äº†åŸºç¡€æµ‹è¯•ã€å®Œæ•´åŠŸèƒ½æµ‹è¯•å’Œå®é™…ä½¿ç”¨æ¼”ç¤º
åŒ…å«ï¼šåŸºç¡€SQLæ“ä½œæµ‹è¯•ã€ORMå‘é‡æ“ä½œæµ‹è¯•ã€å®é™…åº”ç”¨åœºæ™¯æ¼”ç¤º
"""

import pytest
import numpy as np
from typing import List, Any, cast
from sqlalchemy import create_engine, text
from loguru import logger
import hashlib

# å¯¼å…¥é…ç½®
from src.magic_book.pgsql import postgresql_config


# ================================
# pytest fixtures
# ================================


@pytest.fixture(scope="session", autouse=True)
def setup_database_tables() -> Any:
    """è®¾ç½®æ•°æ®åº“è¡¨çš„ fixture"""
    try:
        from src.magic_book.pgsql.client import (
            pgsql_ensure_database_tables,
        )

        pgsql_ensure_database_tables()
        logger.info("âœ… æ•°æ®åº“è¡¨å·²å°±ç»ª")
        yield
    except Exception as e:
        logger.error(f"âŒ æ•°æ®åº“è¡¨è®¾ç½®å¤±è´¥: {e}")
        raise e


# ================================
# åµŒå…¥å‘é‡ç”Ÿæˆå‡½æ•° (æ¨¡æ‹ŸOpenAI API)
# ================================


def mock_get_embedding(text: str) -> List[float]:
    """
    æ¨¡æ‹Ÿè·å–æ–‡æœ¬åµŒå…¥å‘é‡çš„å‡½æ•° (1536ç»´)
    å®é™…ä½¿ç”¨æ—¶åº”è¯¥è°ƒç”¨OpenAIæˆ–å…¶ä»–åµŒå…¥API

    å‚æ•°:
        text: è¾“å…¥æ–‡æœ¬

    è¿”å›:
        List[float]: 1536ç»´çš„å‘é‡
    """
    # ä½¿ç”¨æ–‡æœ¬å“ˆå¸Œç”Ÿæˆç¡®å®šæ€§çš„å‘é‡ (ä»…ç”¨äºæµ‹è¯•)
    np.random.seed(hash(text) % 2**32)
    vector = np.random.randn(1536).astype(float)
    # å½’ä¸€åŒ–å‘é‡
    vector = vector / np.linalg.norm(vector)
    return cast(List[float], list(vector))


def mock_openai_embedding(text: str) -> List[float]:
    """
    å¦ä¸€ç§æ¨¡æ‹ŸOpenAIåµŒå…¥APIçš„å®ç°
    ä½¿ç”¨MD5å“ˆå¸Œç”Ÿæˆæ›´ç¨³å®šçš„å‘é‡
    """
    hash_obj = hashlib.md5(text.encode())
    seed = int(hash_obj.hexdigest(), 16) % (2**32)

    np.random.seed(seed)
    vector = np.random.randn(1536).astype(float)
    vector = vector / np.linalg.norm(vector)  # å½’ä¸€åŒ–
    return cast(List[float], vector.tolist())


# ================================
# pgvector æµ‹è¯•ç±»
# ================================


class TestPgvectorIntegration:
    """pgvector é›†æˆæµ‹è¯•ç±»"""

    def setup_method(self) -> None:
        """åœ¨æ¯ä¸ªæµ‹è¯•æ–¹æ³•å‰è¿è¡Œ"""
        logger.info("ğŸ”§ è®¾ç½®æµ‹è¯•ç¯å¢ƒ...")

    def teardown_method(self) -> None:
        """åœ¨æ¯ä¸ªæµ‹è¯•æ–¹æ³•åè¿è¡Œ"""
        logger.info("ğŸ§¹ æ¸…ç†æµ‹è¯•ç¯å¢ƒ...")


# ================================
# ç¬¬ä¸€éƒ¨åˆ†ï¼šåŸºç¡€SQLå‘é‡æ“ä½œæµ‹è¯•
# ================================


@pytest.mark.integration
@pytest.mark.database
def test_basic_vector_operations() -> None:
    """æµ‹è¯•åŸºæœ¬çš„å‘é‡æ“ä½œ - ç›´æ¥SQLæ“ä½œ"""
    logger.info("ğŸ§ª å¼€å§‹æµ‹è¯•åŸºæœ¬å‘é‡æ“ä½œ...")

    # åˆ›å»ºæ•°æ®åº“è¿æ¥
    engine = create_engine(postgresql_config.connection_string)

    try:
        with engine.connect() as conn:
            # 1. ç¡®ä¿pgvectoræ‰©å±•å·²å®‰è£…
            logger.info("ğŸ”§ æ£€æŸ¥pgvectoræ‰©å±•...")
            result = conn.execute(
                text("SELECT extname FROM pg_extension WHERE extname = 'vector'")
            ).fetchone()
            if result:
                logger.info(f"âœ… pgvectoræ‰©å±•å·²å®‰è£…: {result[0]}")
            else:
                logger.error("âŒ pgvectoræ‰©å±•æœªå®‰è£…")
                return

            # 2. æµ‹è¯•åˆ›å»ºç®€å•å‘é‡è¡¨
            logger.info("ğŸ“ åˆ›å»ºæµ‹è¯•å‘é‡è¡¨...")
            conn.execute(
                text(
                    """
                DROP TABLE IF EXISTS test_vectors;
                CREATE TABLE test_vectors (
                    id SERIAL PRIMARY KEY,
                    content TEXT,
                    embedding vector(3)
                );
            """
                )
            )

            # 3. æ’å…¥æµ‹è¯•æ•°æ®
            logger.info("ğŸ’¾ æ’å…¥æµ‹è¯•å‘é‡æ•°æ®...")
            test_vectors = [
                ("æ–‡æ¡£1ï¼šå…³äºæœºå™¨å­¦ä¹ çš„ä»‹ç»", [1.0, 2.0, 3.0]),
                ("æ–‡æ¡£2ï¼šæ·±åº¦å­¦ä¹ æ•™ç¨‹", [1.1, 2.1, 3.1]),
                ("æ–‡æ¡£3ï¼šPythonç¼–ç¨‹æŒ‡å—", [4.0, 5.0, 6.0]),
            ]

            for content, vector in test_vectors:
                conn.execute(
                    text(
                        """
                    INSERT INTO test_vectors (content, embedding) 
                    VALUES (:content, :vector)
                """
                    ),
                    {"content": content, "vector": vector},
                )

            # 4. æµ‹è¯•å‘é‡ç›¸ä¼¼åº¦æœç´¢
            logger.info("ğŸ” æµ‹è¯•å‘é‡ç›¸ä¼¼åº¦æœç´¢...")
            query_vector = "[1.05, 2.05, 3.05]"  # è½¬æ¢ä¸ºå­—ç¬¦ä¸²æ ¼å¼

            results = conn.execute(
                text(
                    """
                SELECT content, embedding, (embedding <=> :query_vector) as distance
                FROM test_vectors
                ORDER BY embedding <=> :query_vector
                LIMIT 3
            """
                ),
                {"query_vector": query_vector},
            ).fetchall()

            logger.info("ğŸ“‹ æœç´¢ç»“æœ:")
            for i, row in enumerate(results):
                logger.info(f"  {i+1}. {row.content}")
                logger.info(f"     å‘é‡: {row.embedding}")
                logger.info(f"     è·ç¦»: {row.distance:.4f}")

            # 5. æµ‹è¯•ä½™å¼¦ç›¸ä¼¼åº¦
            logger.info("ğŸ“ æµ‹è¯•ä½™å¼¦ç›¸ä¼¼åº¦...")
            similarity_results = conn.execute(
                text(
                    """
                SELECT content, (1 - (embedding <=> :query_vector)) as similarity
                FROM test_vectors
                ORDER BY embedding <=> :query_vector
                LIMIT 3
            """
                ),
                {"query_vector": query_vector},
            ).fetchall()

            logger.info("ğŸ“Š ç›¸ä¼¼åº¦ç»“æœ:")
            for i, row in enumerate(similarity_results):
                logger.info(f"  {i+1}. {row.content}: ç›¸ä¼¼åº¦ {row.similarity:.4f}")

            # 6. æ¸…ç†æµ‹è¯•è¡¨
            conn.execute(text("DROP TABLE test_vectors"))
            conn.commit()

            logger.info("âœ… åŸºæœ¬å‘é‡æ“ä½œæµ‹è¯•å®Œæˆ!")

    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        raise e


@pytest.mark.integration
@pytest.mark.database
def test_high_dimension_vectors() -> None:
    """æµ‹è¯•é«˜ç»´å‘é‡ï¼ˆ1536ç»´ï¼‰- ç›´æ¥SQLæ“ä½œ"""
    logger.info("ğŸ§ª å¼€å§‹æµ‹è¯•é«˜ç»´å‘é‡æ“ä½œ...")

    engine = create_engine(postgresql_config.connection_string)

    try:
        with engine.connect() as conn:
            # åˆ›å»º1536ç»´å‘é‡è¡¨
            logger.info("ğŸ“ åˆ›å»º1536ç»´å‘é‡è¡¨...")
            conn.execute(
                text(
                    """
                DROP TABLE IF EXISTS test_vectors_1536;
                CREATE TABLE test_vectors_1536 (
                    id SERIAL PRIMARY KEY,
                    content TEXT,
                    embedding vector(1536)
                );
            """
                )
            )

            # ç”Ÿæˆæµ‹è¯•å‘é‡
            logger.info("ğŸ² ç”Ÿæˆæµ‹è¯•å‘é‡...")
            np.random.seed(42)  # ç¡®ä¿ç»“æœå¯é‡ç°
            test_embedding = np.random.randn(1536).astype(float).tolist()
            # è½¬æ¢ä¸ºå­—ç¬¦ä¸²æ ¼å¼
            vector_str = "[" + ",".join(map(str, test_embedding)) + "]"

            # æ’å…¥æ•°æ®
            conn.execute(
                text(
                    """
                INSERT INTO test_vectors_1536 (content, embedding) 
                VALUES (:content, :vector)
            """
                ),
                {
                    "content": "æµ‹è¯•æ–‡æ¡£ï¼šè¿™æ˜¯ä¸€ä¸ª1536ç»´å‘é‡çš„æµ‹è¯•æ–‡æ¡£",
                    "vector": vector_str,
                },
            )

            # æµ‹è¯•æœç´¢
            query_vector = vector_str  # ä½¿ç”¨ç›¸åŒå‘é‡åº”è¯¥å¾—åˆ°å®Œç¾åŒ¹é…

            result = conn.execute(
                text(
                    """
                SELECT content, (1 - (embedding <=> :query_vector)) as similarity
                FROM test_vectors_1536
                WHERE embedding IS NOT NULL
                ORDER BY embedding <=> :query_vector
                LIMIT 1
            """
                ),
                {"query_vector": query_vector},
            ).fetchone()

            if result:
                logger.info(f"âœ… é«˜ç»´å‘é‡æœç´¢æˆåŠŸ!")
                logger.info(f"   å†…å®¹: {result.content}")
                logger.info(f"   ç›¸ä¼¼åº¦: {result.similarity:.6f}")
            else:
                logger.error("âŒ é«˜ç»´å‘é‡æœç´¢å¤±è´¥")

            # æ¸…ç†
            conn.execute(text("DROP TABLE test_vectors_1536"))
            conn.commit()

            logger.info("âœ… é«˜ç»´å‘é‡æµ‹è¯•å®Œæˆ!")

    except Exception as e:
        logger.error(f"âŒ é«˜ç»´å‘é‡æµ‹è¯•å¤±è´¥: {e}")
        raise e


# ================================
# ç¬¬äºŒéƒ¨åˆ†ï¼šORMå‘é‡æ“ä½œæµ‹è¯•
# ================================


@pytest.mark.integration
@pytest.mark.database
def test_vector_document_operations() -> None:
    """æµ‹è¯•å‘é‡æ–‡æ¡£æ“ä½œ - ä½¿ç”¨ORM"""
    from src.magic_book.pgsql.vector_document import (
        save_vector_document,
        search_similar_documents,
        get_database_vector_stats,
    )

    logger.info("ğŸ§ª å¼€å§‹æµ‹è¯•å‘é‡æ–‡æ¡£æ“ä½œ...")

    # 1. ä¿å­˜ä¸€äº›æµ‹è¯•æ–‡æ¡£
    test_documents = [
        {
            "content": "è¿™æ˜¯ä¸€ä¸ªå…³äºæœºå™¨å­¦ä¹ çš„åŸºç¡€æ•™ç¨‹ï¼Œä»‹ç»äº†ç›‘ç£å­¦ä¹ å’Œæ— ç›‘ç£å­¦ä¹ çš„åŸºæœ¬æ¦‚å¿µã€‚",
            "title": "æœºå™¨å­¦ä¹ åŸºç¡€",
            "doc_type": "tutorial",
            "source": "ml_guide.md",
        },
        {
            "content": "æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œä½¿ç”¨ç¥ç»ç½‘ç»œæ¥æ¨¡æ‹Ÿäººè„‘çš„å­¦ä¹ è¿‡ç¨‹ã€‚",
            "title": "æ·±åº¦å­¦ä¹ ä»‹ç»",
            "doc_type": "tutorial",
            "source": "dl_intro.md",
        },
        {
            "content": "Pythonæ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€ï¼Œå¹¿æ³›ç”¨äºæ•°æ®ç§‘å­¦ã€æœºå™¨å­¦ä¹ å’ŒWebå¼€å‘ã€‚",
            "title": "Pythonç¼–ç¨‹å…¥é—¨",
            "doc_type": "programming",
            "source": "python_basics.md",
        },
        {
            "content": "æ•°æ®åº“è®¾è®¡æ˜¯è½¯ä»¶å¼€å‘ä¸­çš„é‡è¦ç¯èŠ‚ï¼Œéœ€è¦è€ƒè™‘æ•°æ®çš„ç»“æ„åŒ–å­˜å‚¨å’ŒæŸ¥è¯¢æ•ˆç‡ã€‚",
            "title": "æ•°æ®åº“è®¾è®¡åŸåˆ™",
            "doc_type": "database",
            "source": "db_design.md",
        },
    ]

    saved_docs = []
    for doc_data in test_documents:
        try:
            # ç”ŸæˆåµŒå…¥å‘é‡
            embedding = mock_get_embedding(doc_data["content"])

            # ä¿å­˜åˆ°æ•°æ®åº“
            doc = save_vector_document(
                content=doc_data["content"],
                embedding=embedding,
                title=doc_data["title"],
                doc_type=doc_data["doc_type"],
                source=doc_data["source"],
                metadata={"test": True, "category": doc_data["doc_type"]},
            )
            saved_docs.append(doc)
            logger.info(f"âœ… å·²ä¿å­˜æ–‡æ¡£: {doc.title}")

        except Exception as e:
            logger.error(f"âŒ ä¿å­˜æ–‡æ¡£å¤±è´¥: {e}")

    # 2. æµ‹è¯•ç›¸ä¼¼åº¦æœç´¢
    try:
        query_text = "æˆ‘æƒ³å­¦ä¹ äººå·¥æ™ºèƒ½å’Œç¥ç»ç½‘ç»œ"
        query_embedding = mock_get_embedding(query_text)

        logger.info(f"ğŸ” æœç´¢æŸ¥è¯¢: {query_text}")

        # æœç´¢ç›¸ä¼¼æ–‡æ¡£
        similar_docs = search_similar_documents(
            query_embedding=query_embedding,
            limit=3,
            similarity_threshold=0.0,  # é™ä½é˜ˆå€¼ä»¥ä¾¿çœ‹åˆ°ç»“æœ
        )

        logger.info(f"ğŸ“‹ æ‰¾åˆ° {len(similar_docs)} ä¸ªç›¸ä¼¼æ–‡æ¡£:")
        for doc, similarity in similar_docs:
            logger.info(f"  - {doc.title}: ç›¸ä¼¼åº¦ {similarity:.4f}")
            logger.info(f"    å†…å®¹: {doc.content[:50]}...")

        # æŒ‰ç±»å‹è¿‡æ»¤æœç´¢
        tutorial_docs = search_similar_documents(
            query_embedding=query_embedding,
            limit=3,
            doc_type_filter="tutorial",
            similarity_threshold=0.0,
        )

        logger.info(f"ğŸ“š æ•™ç¨‹ç±»æ–‡æ¡£æœç´¢ç»“æœ ({len(tutorial_docs)} ä¸ª):")
        for doc, similarity in tutorial_docs:
            logger.info(f"  - {doc.title}: ç›¸ä¼¼åº¦ {similarity:.4f}")

    except Exception as e:
        logger.error(f"âŒ æœç´¢æµ‹è¯•å¤±è´¥: {e}")

    # 3. è·å–ç»Ÿè®¡ä¿¡æ¯
    try:
        stats = get_database_vector_stats()
        logger.info(f"ğŸ“Š æ•°æ®åº“ç»Ÿè®¡: {stats}")
    except Exception as e:
        logger.error(f"âŒ è·å–ç»Ÿè®¡å¤±è´¥: {e}")


@pytest.mark.integration
@pytest.mark.database
# è¯¥å‡½æ•°å·²è¢«æ³¨é‡Šï¼Œå› ä¸º ConversationVectorDB ç±»å·²è¢«ç§»é™¤
def test_conversation_vector_operations() -> None:
    """æµ‹è¯•å¯¹è¯å‘é‡æ“ä½œ - å·²ç§»é™¤ï¼Œå› ä¸º ConversationVectorDB ç±»å·²è¢«åˆ é™¤"""
    logger.info("âš ï¸ test_conversation_vector_operations å·²è¢«ç§»é™¤")
    pass


# ================================
# ç¬¬ä¸‰éƒ¨åˆ†ï¼šå®é™…åº”ç”¨åœºæ™¯æ¼”ç¤º
# ================================


@pytest.mark.integration
@pytest.mark.demo
def demo_document_rag_system() -> None:
    """æ¼”ç¤ºåŸºäºæ–‡æ¡£çš„RAGç³»ç»Ÿ"""
    from src.magic_book.pgsql.vector_document import (
        save_vector_document,
        search_similar_documents,
    )

    logger.info("ğŸ¤– æ¼”ç¤ºæ–‡æ¡£RAGç³»ç»Ÿ...")

    # 1. ä¿å­˜ä¸€äº›çŸ¥è¯†æ–‡æ¡£
    documents = [
        {
            "title": "æœºå™¨å­¦ä¹ åŸºç¡€",
            "content": "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œå®ƒè®©è®¡ç®—æœºèƒ½å¤Ÿåœ¨æ²¡æœ‰æ˜ç¡®ç¼–ç¨‹çš„æƒ…å†µä¸‹å­¦ä¹ ã€‚ä¸»è¦åŒ…æ‹¬ç›‘ç£å­¦ä¹ ã€æ— ç›‘ç£å­¦ä¹ å’Œå¼ºåŒ–å­¦ä¹ ä¸‰ç§ç±»å‹ã€‚",
            "doc_type": "knowledge",
            "source": "ml_textbook.pdf",
        },
        {
            "title": "æ·±åº¦å­¦ä¹ åŸç†",
            "content": "æ·±åº¦å­¦ä¹ ä½¿ç”¨å¤šå±‚ç¥ç»ç½‘ç»œæ¥æ¨¡æ‹Ÿäººè„‘çš„å·¥ä½œæ–¹å¼ã€‚å®ƒåœ¨å›¾åƒè¯†åˆ«ã€è‡ªç„¶è¯­è¨€å¤„ç†ç­‰é¢†åŸŸå–å¾—äº†çªç ´æ€§è¿›å±•ã€‚",
            "doc_type": "knowledge",
            "source": "dl_guide.pdf",
        },
        {
            "title": "Pythonæ•°æ®ç§‘å­¦",
            "content": "Pythonæ˜¯æ•°æ®ç§‘å­¦é¢†åŸŸæœ€æµè¡Œçš„ç¼–ç¨‹è¯­è¨€ã€‚ä¸»è¦åº“åŒ…æ‹¬NumPyã€Pandasã€Matplotlibå’ŒScikit-learnç­‰ã€‚",
            "doc_type": "tutorial",
            "source": "python_ds.md",
        },
        {
            "title": "å‘é‡æ•°æ®åº“åº”ç”¨",
            "content": "å‘é‡æ•°æ®åº“ç”¨äºå­˜å‚¨å’Œæ£€ç´¢é«˜ç»´å‘é‡æ•°æ®ï¼Œç‰¹åˆ«é€‚ç”¨äºç›¸ä¼¼æ€§æœç´¢ã€æ¨èç³»ç»Ÿå’ŒRAGåº”ç”¨ã€‚",
            "doc_type": "knowledge",
            "source": "vector_db.pdf",
        },
    ]

    logger.info("ğŸ“š ä¿å­˜çŸ¥è¯†æ–‡æ¡£...")
    for doc_data in documents:
        embedding = mock_openai_embedding(doc_data["content"])
        save_vector_document(
            content=doc_data["content"],
            embedding=embedding,
            title=doc_data["title"],
            doc_type=doc_data["doc_type"],
            source=doc_data["source"],
            metadata={"category": "knowledge_base"},
        )

    # 2. æ¨¡æ‹Ÿç”¨æˆ·æŸ¥è¯¢
    queries = [
        "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ",
        "å¦‚ä½•ä½¿ç”¨Pythonè¿›è¡Œæ•°æ®åˆ†æï¼Ÿ",
        "å‘é‡æ•°æ®åº“æœ‰ä»€ä¹ˆç”¨é€”ï¼Ÿ",
        "æ·±åº¦å­¦ä¹ å’Œæœºå™¨å­¦ä¹ çš„åŒºåˆ«æ˜¯ä»€ä¹ˆï¼Ÿ",
    ]

    logger.info("ğŸ” å¤„ç†ç”¨æˆ·æŸ¥è¯¢...")
    for query in queries:
        logger.info(f"\nâ“ ç”¨æˆ·é—®é¢˜: {query}")

        # è·å–æŸ¥è¯¢çš„åµŒå…¥å‘é‡
        query_embedding = mock_openai_embedding(query)

        # æœç´¢ç›¸å…³æ–‡æ¡£
        results = search_similar_documents(
            query_embedding=query_embedding, limit=2, similarity_threshold=0.1
        )

        logger.info("ğŸ“– ç›¸å…³æ–‡æ¡£:")
        for doc, similarity in results:
            logger.info(f"   - {doc.title} (ç›¸ä¼¼åº¦: {similarity:.3f})")
            logger.info(f"     å†…å®¹ç‰‡æ®µ: {doc.content[:100]}...")


@pytest.mark.integration
@pytest.mark.demo
# è¯¥å‡½æ•°å·²è¢«æ³¨é‡Šï¼Œå› ä¸º ConversationVectorDB ç±»å·²è¢«ç§»é™¤
@pytest.mark.integration
@pytest.mark.demo
def demo_conversation_memory() -> None:
    """æ¼”ç¤ºå¯¹è¯è®°å¿†ç³»ç»Ÿ - å·²ç§»é™¤ï¼Œå› ä¸º ConversationVectorDB ç±»å·²è¢«åˆ é™¤"""
    logger.info("âš ï¸ demo_conversation_memory å·²è¢«ç§»é™¤")
    pass


# è¯¥å‡½æ•°å·²è¢«æ³¨é‡Šï¼Œå› ä¸º GameKnowledgeVectorDB ç±»å·²è¢«ç§»é™¤
@pytest.mark.integration
@pytest.mark.demo
def demo_game_knowledge_system() -> None:
    """æ¼”ç¤ºæ¸¸æˆçŸ¥è¯†ç³»ç»Ÿ - å·²ç§»é™¤ï¼Œå› ä¸º GameKnowledgeVectorDB ç±»å·²è¢«åˆ é™¤"""
    logger.info("âš ï¸ demo_game_knowledge_system å·²è¢«ç§»é™¤")
    pass


# ================================
# ä¸»å‡½æ•°å’Œæµ‹è¯•è¿è¡Œå™¨
# ================================


def run_all_vector_tests() -> None:
    """è¿è¡Œæ‰€æœ‰å‘é‡åŠŸèƒ½æµ‹è¯•"""
    logger.info("ğŸš€ å¼€å§‹è¿è¡Œ pgvector åŠŸèƒ½æµ‹è¯•...")

    try:
        # ç¡®ä¿æ•°æ®åº“è¡¨å·²åˆ›å»º
        from src.magic_book.pgsql.client import engine
        from src.magic_book.pgsql.client import Base  # type: ignore[attr-defined]

        Base.metadata.create_all(bind=engine)
        logger.info("âœ… æ•°æ®åº“è¡¨å·²å°±ç»ª")

        # è¿è¡Œå„é¡¹æµ‹è¯•
        test_vector_document_operations()
        test_conversation_vector_operations()  # ç°åœ¨æ˜¯å ä½ç¬¦å‡½æ•°
        # test_game_knowledge_operations()       # å·²ç§»é™¤

        # è·å–æœ€ç»ˆç»Ÿè®¡
        from src.magic_book.pgsql.vector_document import (
            get_database_vector_stats,
        )

        final_stats = get_database_vector_stats()
        logger.info(f"ğŸ æµ‹è¯•å®Œæˆï¼Œæœ€ç»ˆç»Ÿè®¡: {final_stats}")

    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•è¿è¡Œå¤±è´¥: {e}")
        raise e


def run_all_demos() -> None:
    """è¿è¡Œæ‰€æœ‰æ¼”ç¤º"""
    logger.info("ğŸš€ pgvectoré›†æˆæ¼”ç¤ºå¼€å§‹...")

    try:
        # ç¡®ä¿æ•°æ®åº“è¡¨å·²åˆ›å»º
        from src.magic_book.pgsql.client import engine
        from src.magic_book.pgsql.client import Base  # type: ignore[attr-defined]

        Base.metadata.create_all(bind=engine)

        # è¿è¡Œå„ç§æ¼”ç¤º
        demo_document_rag_system()
        demo_conversation_memory()  # ç°åœ¨æ˜¯å ä½ç¬¦å‡½æ•°
        demo_game_knowledge_system()  # ç°åœ¨æ˜¯å ä½ç¬¦å‡½æ•°

        # æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
        from src.magic_book.pgsql.vector_document import (
            get_database_vector_stats,
        )

        logger.info("\nğŸ“Š æœ€ç»ˆæ•°æ®åº“ç»Ÿè®¡:")
        stats = get_database_vector_stats()
        for table_name, table_stats in stats.items():
            logger.info(f"   {table_name}: {table_stats['with_embeddings']} æ¡å‘é‡è®°å½•")

        logger.info("\nâœ… pgvectoré›†æˆæ¼”ç¤ºå®Œæˆï¼")
        logger.info("ğŸ‰ æ‚¨ç°åœ¨å¯ä»¥åœ¨é¡¹ç›®ä¸­ä½¿ç”¨å‘é‡æ•°æ®åº“åŠŸèƒ½äº†ï¼")

    except Exception as e:
        logger.error(f"âŒ æ¼”ç¤ºå¤±è´¥: {e}")


@pytest.mark.integration
@pytest.mark.comprehensive
def test_comprehensive_pgvector_integration(setup_database_tables: Any) -> None:
    """è¿è¡Œå®Œæ•´çš„ pgvector é›†æˆæµ‹è¯•"""
    logger.info("ğŸŒŸ å¼€å§‹ pgvector ç»¼åˆæµ‹è¯•å’Œæ¼”ç¤º...")

    try:
        # ç¬¬ä¸€éƒ¨åˆ†ï¼šåŸºç¡€SQLæµ‹è¯•
        logger.info("\n" + "=" * 50)
        logger.info("ç¬¬ä¸€éƒ¨åˆ†ï¼šåŸºç¡€SQLå‘é‡æ“ä½œæµ‹è¯•")
        logger.info("=" * 50)
        test_basic_vector_operations()
        test_high_dimension_vectors()

        # ç¬¬äºŒéƒ¨åˆ†ï¼šORMæµ‹è¯•
        logger.info("\n" + "=" * 50)
        logger.info("ç¬¬äºŒéƒ¨åˆ†ï¼šORMå‘é‡æ“ä½œæµ‹è¯•")
        logger.info("=" * 50)
        test_vector_document_operations()
        test_conversation_vector_operations()  # ç°åœ¨æ˜¯å ä½ç¬¦å‡½æ•°
        # test_game_knowledge_operations()       # å·²ç§»é™¤

        # æœ€ç»ˆæ€»ç»“
        logger.info("\n" + "=" * 50)
        logger.info("ğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")
        logger.info("âœ… pgvector åŠŸèƒ½é›†æˆéªŒè¯æˆåŠŸï¼")
        logger.info("ğŸ’¡ æ‚¨ç°åœ¨å¯ä»¥åœ¨é¡¹ç›®ä¸­ä½¿ç”¨å®Œæ•´çš„å‘é‡æ•°æ®åº“åŠŸèƒ½äº†ï¼")
        logger.info("=" * 50)

    except Exception as e:
        logger.error(f"âŒ ç»¼åˆæµ‹è¯•å¤±è´¥: {e}")
        raise e


@pytest.mark.integration
@pytest.mark.demo
@pytest.mark.slow
def test_comprehensive_pgvector_demos(setup_database_tables: Any) -> None:
    """è¿è¡Œå®Œæ•´çš„ pgvector æ¼”ç¤º"""
    logger.info("ğŸš€ pgvectoré›†æˆæ¼”ç¤ºå¼€å§‹...")

    try:
        # ç¬¬ä¸‰éƒ¨åˆ†ï¼šå®é™…åº”ç”¨æ¼”ç¤º
        logger.info("\n" + "=" * 50)
        logger.info("ç¬¬ä¸‰éƒ¨åˆ†ï¼šå®é™…åº”ç”¨åœºæ™¯æ¼”ç¤º")
        logger.info("=" * 50)
        demo_document_rag_system()
        demo_conversation_memory()  # ç°åœ¨æ˜¯å ä½ç¬¦å‡½æ•°
        demo_game_knowledge_system()  # ç°åœ¨æ˜¯å ä½ç¬¦å‡½æ•°

        # æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
        from src.magic_book.pgsql.vector_document import (
            get_database_vector_stats,
        )

        logger.info("\nğŸ“Š æœ€ç»ˆæ•°æ®åº“ç»Ÿè®¡:")
        stats = get_database_vector_stats()
        for table_name, table_stats in stats.items():
            logger.info(f"   {table_name}: {table_stats['with_embeddings']} æ¡å‘é‡è®°å½•")

        logger.info("\nâœ… pgvectoré›†æˆæ¼”ç¤ºå®Œæˆï¼")
        logger.info("ğŸ‰ æ‚¨ç°åœ¨å¯ä»¥åœ¨é¡¹ç›®ä¸­ä½¿ç”¨å‘é‡æ•°æ®åº“åŠŸèƒ½äº†ï¼")

    except Exception as e:
        logger.error(f"âŒ æ¼”ç¤ºå¤±è´¥: {e}")
        raise e


if __name__ == "__main__":
    # å½“ç›´æ¥è¿è¡Œè„šæœ¬æ—¶ï¼Œæ‰§è¡Œå®Œæ•´æµ‹è¯•
    import pytest

    # å¯ä»¥é€‰æ‹©è¿è¡Œä¸åŒçš„æµ‹è¯•æ¨¡å—
    import argparse

    parser = argparse.ArgumentParser(description="pgvector ç»¼åˆæµ‹è¯•å’Œæ¼”ç¤º")
    parser.add_argument(
        "--mode",
        choices=["all", "basic", "orm", "demo"],
        default="all",
        help="é€‰æ‹©è¿è¡Œæ¨¡å¼",
    )

    args = parser.parse_args()

    if args.mode == "all":
        # è¿è¡Œæ‰€æœ‰æµ‹è¯•
        pytest.main([__file__, "-v", "-s"])
    elif args.mode == "basic":
        logger.info("ğŸ§ª åªè¿è¡ŒåŸºç¡€SQLæµ‹è¯•...")
        pytest.main(
            [
                __file__ + "::test_basic_vector_operations",
                __file__ + "::test_high_dimension_vectors",
                "-v",
                "-s",
            ]
        )
    elif args.mode == "orm":
        logger.info("ğŸ§ª åªè¿è¡ŒORMæµ‹è¯•...")
        pytest.main(
            [
                __file__ + "::test_vector_document_operations",
                __file__ + "::test_conversation_vector_operations",
                __file__ + "::test_game_knowledge_operations",
                "-v",
                "-s",
            ]
        )
    elif args.mode == "demo":
        logger.info("ğŸ§ª åªè¿è¡Œæ¼”ç¤º...")
        pytest.main([__file__ + "::test_comprehensive_pgvector_demos", "-v", "-s"])
