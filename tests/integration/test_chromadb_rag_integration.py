#!/usr/bin/env python3
"""
ChromaDB RAGç³»ç»Ÿé›†æˆæµ‹è¯•

ç”¨äºéªŒè¯æ”¹é€ åçš„RAGç³»ç»Ÿæ˜¯å¦èƒ½æ­£å¸¸åˆå§‹åŒ–å’Œè¿è¡Œ
"""

from typing import Generator, cast
import pytest
import asyncio
import time
from loguru import logger

from src.magic_book.chroma import (
    chroma_client,
    reset_client,
    get_default_collection,
)
from src.magic_book.rag import (
    load_knowledge_base_to_vector_db,
    search_similar_documents,  # å¯¼å…¥é‡æ„åçš„å‡½æ•°
)
from src.magic_book.embedding_model.sentence_transformer import (
    get_embedding_model,
)
from src.magic_book.demo.campaign_setting import (
    FANTASY_WORLD_RPG_KNOWLEDGE_BASE,
)


def _init_rag_system_with_model() -> bool:
    """è¾…åŠ©å‡½æ•°ï¼šä½¿ç”¨é»˜è®¤æ¨¡å‹åˆå§‹åŒ–RAGç³»ç»Ÿ"""
    embedding_model = get_embedding_model()
    if embedding_model is None:
        return False
    collection = get_default_collection()
    return load_knowledge_base_to_vector_db(
        FANTASY_WORLD_RPG_KNOWLEDGE_BASE, embedding_model, collection
    )


def _rag_search_with_defaults(
    query: str, top_k: int = 5
) -> tuple[list[str], list[float]]:
    """è¾…åŠ©å‡½æ•°ï¼šä½¿ç”¨é»˜è®¤å®ä¾‹æ‰§è¡Œè¯­ä¹‰æœç´¢"""
    collection = get_default_collection()
    embedding_model = get_embedding_model()
    if embedding_model is None:
        raise RuntimeError("åµŒå…¥æ¨¡å‹æœªåˆå§‹åŒ–")
    return search_similar_documents(query, collection, embedding_model, top_k)


class TestChromaDBRAGIntegration:
    """ChromaDB RAGç³»ç»Ÿé›†æˆæµ‹è¯•ç±»"""

    _db_initialized = False  # ç±»çº§åˆ«çš„æ ‡å¿—ï¼Œç¡®ä¿åªåˆå§‹åŒ–ä¸€æ¬¡

    def test_chromadb_initialization(self) -> None:
        """æµ‹è¯•ChromaDBåˆå§‹åŒ–"""
        logger.info("ğŸ§ª å¼€å§‹æµ‹è¯•ChromaDB RAGç³»ç»Ÿåˆå§‹åŒ–...")

        # æµ‹è¯•ChromaDB collectionåˆ›å»º
        collection = get_default_collection()
        assert collection is not None, "ChromaDB collectionåˆ›å»ºå¤±è´¥"
        logger.info(f"âœ… ChromaDB collectionåˆ›å»ºæˆåŠŸ: {type(collection)}")

        # è·å–åµŒå…¥æ¨¡å‹
        embedding_model = get_embedding_model()
        assert embedding_model is not None, "åµŒå…¥æ¨¡å‹åˆå§‹åŒ–å¤±è´¥"

        # æµ‹è¯•å®Œæ•´åˆå§‹åŒ–
        success = load_knowledge_base_to_vector_db(
            FANTASY_WORLD_RPG_KNOWLEDGE_BASE, embedding_model, collection
        )
        assert success, "ChromaDB RAGç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥"
        logger.success("ğŸ‰ ChromaDB RAGç³»ç»Ÿåˆå§‹åŒ–æµ‹è¯•é€šè¿‡ï¼")

    def test_semantic_search(self) -> None:
        """æµ‹è¯•è¯­ä¹‰æœç´¢åŠŸèƒ½"""
        logger.info("ğŸ” å¼€å§‹æµ‹è¯•è¯­ä¹‰æœç´¢åŠŸèƒ½...")

        # è·å–collectionå¹¶ç¡®ä¿æ•°æ®åº“ä¸­æœ‰æ•°æ®
        collection = get_default_collection()
        assert collection is not None, "ChromaDBé›†åˆåº”è¯¥å·²åˆ›å»º"
        collection_count = collection.count()
        if collection_count == 0:
            success = _init_rag_system_with_model()
            assert success, "ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥"
            collection_count = collection.count()
            assert collection_count > 0, f"åˆå§‹åŒ–åæ•°æ®åº“ä»ä¸ºç©º"

        # æµ‹è¯•è¯­ä¹‰æœç´¢
        test_queries = [
            "æ™¨æ›¦ä¹‹åˆƒçš„ç¥åœ£æŠ€èƒ½",
            "è‰¾å°”æ³•å°¼äºšå¤§é™†æœ‰å“ªäº›ç‹å›½",
            "é­”ç‹é˜¿å·´é¡¿çš„å¼±ç‚¹",
            "å†’é™©è€…å…¬ä¼šçš„ç­‰çº§åˆ¶åº¦",
            "æ—¶ä¹‹æ²™æ¼çš„ç¥ç§˜åŠ›é‡",
            "ç²¾çµçš„é­”æ³•èƒ½åŠ›",
            "å¤±è½çš„è´¤è€…ä¹‹å¡”",
            "æš´é£é›ªå›¢çš„æˆå‘˜ç»„æˆ",
        ]

        for test_query in test_queries:
            docs, scores = _rag_search_with_defaults(test_query, top_k=3)

            # éªŒè¯æœç´¢ç»“æœ
            assert isinstance(docs, list), f"æœç´¢ç»“æœåº”è¯¥æ˜¯åˆ—è¡¨: {test_query}"
            assert isinstance(scores, list), f"ç›¸ä¼¼åº¦åˆ†æ•°åº”è¯¥æ˜¯åˆ—è¡¨: {test_query}"
            assert len(docs) == len(scores), f"æ–‡æ¡£å’Œåˆ†æ•°æ•°é‡åº”è¯¥ä¸€è‡´: {test_query}"

            logger.info(f"ğŸ” æµ‹è¯•æŸ¥è¯¢: '{test_query}' - æ‰¾åˆ° {len(docs)} ä¸ªç»“æœ")

            for i, (doc, score) in enumerate(zip(docs, scores)):
                assert isinstance(doc, str), f"æ–‡æ¡£å†…å®¹åº”è¯¥æ˜¯å­—ç¬¦ä¸²: {test_query}"
                assert isinstance(
                    score, (int, float)
                ), f"ç›¸ä¼¼åº¦åˆ†æ•°åº”è¯¥æ˜¯æ•°å­—: {test_query}"
                assert 0 <= score <= 1, f"ç›¸ä¼¼åº¦åˆ†æ•°åº”è¯¥åœ¨0-1ä¹‹é—´: {score}"
                logger.info(f"  [{i+1}] ç›¸ä¼¼åº¦: {score:.3f}, å†…å®¹: {doc[:50]}...")

    def test_database_state(self) -> None:
        """æµ‹è¯•æ•°æ®åº“çŠ¶æ€"""
        logger.info("ğŸ“Š å¼€å§‹æµ‹è¯•æ•°æ®åº“çŠ¶æ€...")

        # è·å–collectionå’Œå®¢æˆ·ç«¯
        collection = get_default_collection()
        assert collection is not None, "ChromaDBé›†åˆåº”è¯¥å·²åˆ›å»º"
        assert chroma_client is not None, "ChromaDBå®¢æˆ·ç«¯åº”è¯¥å·²åˆ›å»º"

        # ç¡®ä¿æ•°æ®åº“ä¸­æœ‰æ•°æ®
        collection_count = collection.count()
        if collection_count == 0:
            success = _init_rag_system_with_model()
            assert success, "ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥"
            collection_count = collection.count()

        # éªŒè¯å…¨å±€åµŒå…¥æ¨¡å‹å·²åŠ è½½
        embedding_model = get_embedding_model()
        assert embedding_model is not None, "åµŒå…¥æ¨¡å‹åº”è¯¥å·²åŠ è½½"

        # éªŒè¯é›†åˆä¸­æœ‰æ•°æ®
        assert collection_count > 0, f"é›†åˆä¸­åº”è¯¥æœ‰æ•°æ®ï¼Œå½“å‰æ•°é‡: {collection_count}"
        logger.info(f"ğŸ“Š æ•°æ®åº“çŠ¶æ€æ­£å¸¸ï¼Œæ–‡æ¡£æ•°é‡: {collection_count}")

    def test_error_handling(self) -> None:
        """æµ‹è¯•é”™è¯¯å¤„ç†"""
        logger.info("âš ï¸ å¼€å§‹æµ‹è¯•é”™è¯¯å¤„ç†...")

        # è·å–collectionå¹¶ç¡®ä¿æ•°æ®åº“ä¸­æœ‰æ•°æ®
        collection = get_default_collection()
        collection_count = collection.count()
        if collection_count == 0:
            success = _init_rag_system_with_model()
            assert success, "ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥"

        # æµ‹è¯•ç©ºæŸ¥è¯¢
        docs, scores = _rag_search_with_defaults("", top_k=3)
        assert isinstance(docs, list), "ç©ºæŸ¥è¯¢åº”è¯¥è¿”å›åˆ—è¡¨"
        assert isinstance(scores, list), "ç©ºæŸ¥è¯¢åº”è¯¥è¿”å›åˆ†æ•°åˆ—è¡¨"

        # æµ‹è¯•å¼‚å¸¸æŸ¥è¯¢å‚æ•°
        docs, scores = _rag_search_with_defaults("æµ‹è¯•æŸ¥è¯¢", top_k=0)
        assert isinstance(docs, list), "å¼‚å¸¸å‚æ•°åº”è¯¥è¿”å›åˆ—è¡¨"
        assert isinstance(scores, list), "å¼‚å¸¸å‚æ•°åº”è¯¥è¿”å›åˆ†æ•°åˆ—è¡¨"

        logger.info("âš ï¸ é”™è¯¯å¤„ç†æµ‹è¯•é€šè¿‡")

    async def test_parallel_semantic_search(self) -> None:
        """æµ‹è¯•å¹¶è¡Œè¯­ä¹‰æœç´¢åŠŸèƒ½"""
        logger.info("ğŸš€ å¼€å§‹æµ‹è¯•å¹¶è¡Œè¯­ä¹‰æœç´¢åŠŸèƒ½...")

        # è·å–collectionå¹¶ç¡®ä¿æ•°æ®åº“ä¸­æœ‰æ•°æ®
        collection = get_default_collection()
        assert collection is not None, "ChromaDBé›†åˆåº”è¯¥å·²åˆ›å»º"
        collection_count = collection.count()
        if collection_count == 0:
            success = _init_rag_system_with_model()
            assert success, "ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥"
            collection_count = collection.count()
            assert collection_count > 0, f"åˆå§‹åŒ–åæ•°æ®åº“ä»ä¸ºç©º"

        # å®šä¹‰å¤šä¸ªæµ‹è¯•æŸ¥è¯¢
        test_queries = [
            "æ™¨æ›¦ä¹‹åˆƒçš„ç¥åœ£æŠ€èƒ½",
            "è‰¾å°”æ³•å°¼äºšå¤§é™†æœ‰å“ªäº›ç‹å›½",
            "é­”ç‹é˜¿å·´é¡¿çš„å¼±ç‚¹",
            "å†’é™©è€…å…¬ä¼šçš„ç­‰çº§åˆ¶åº¦",
            "æ—¶ä¹‹æ²™æ¼çš„ç¥ç§˜åŠ›é‡",
            "ç²¾çµçš„é­”æ³•èƒ½åŠ›",
            "å¤±è½çš„è´¤è€…ä¹‹å¡”",
            "æš´é£é›ªå›¢çš„æˆå‘˜ç»„æˆ",
        ]

        # åˆ›å»ºå¼‚æ­¥ä»»åŠ¡åŒ…è£…å™¨
        async def async_search(query: str) -> tuple[str, list[str], list[float]]:
            """å¼‚æ­¥æœç´¢åŒ…è£…å™¨ - ä½¿ç”¨æ¨èçš„ asyncio.to_thread æ–¹æ³•"""
            collection = get_default_collection()
            embedding_model = get_embedding_model()
            if embedding_model is None:
                return query, [], []
            docs, scores = await asyncio.to_thread(
                search_similar_documents,
                query,
                collection,
                embedding_model,
                3,
            )
            return query, docs, scores

        # è®°å½•å¼€å§‹æ—¶é—´
        start_time = time.time()

        # å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰æœç´¢æŸ¥è¯¢
        logger.info(f"ğŸ” å¹¶è¡Œæ‰§è¡Œ {len(test_queries)} ä¸ªæœç´¢æŸ¥è¯¢...")
        results = await asyncio.gather(
            *[async_search(query) for query in test_queries], return_exceptions=True
        )

        # è®°å½•ç»“æŸæ—¶é—´
        parallel_time = time.time() - start_time
        logger.info(f"âš¡ å¹¶è¡Œæœç´¢è€—æ—¶: {parallel_time:.2f}ç§’")

        # éªŒè¯å¹¶è¡Œæœç´¢ç»“æœ
        successful_results: list[tuple[str, list[str], list[float]]] = []
        for result in results:
            if isinstance(result, Exception):
                logger.error(f"æœç´¢å¤±è´¥: {result}")
                pytest.fail(f"å¹¶è¡Œæœç´¢ä¸­å‡ºç°å¼‚å¸¸: {result}")
            else:
                # ä½¿ç”¨ç±»å‹æ–­è¨€ç¡®ä¿mypyç†è§£è¿™é‡Œçš„ç±»å‹
                successful_results.append(
                    cast(tuple[str, list[str], list[float]], result)
                )

        assert len(successful_results) == len(test_queries), "æ‰€æœ‰æŸ¥è¯¢éƒ½åº”è¯¥æˆåŠŸ"

        # éªŒè¯æ¯ä¸ªæœç´¢ç»“æœ
        for query, docs, scores in successful_results:
            assert isinstance(docs, list), f"æœç´¢ç»“æœåº”è¯¥æ˜¯åˆ—è¡¨: {query}"
            assert isinstance(scores, list), f"ç›¸ä¼¼åº¦åˆ†æ•°åº”è¯¥æ˜¯åˆ—è¡¨: {query}"
            assert len(docs) == len(scores), f"æ–‡æ¡£å’Œåˆ†æ•°æ•°é‡åº”è¯¥ä¸€è‡´: {query}"

            logger.info(f"ğŸ” å¹¶è¡ŒæŸ¥è¯¢: '{query}' - æ‰¾åˆ° {len(docs)} ä¸ªç»“æœ")

            for i, (doc, score) in enumerate(zip(docs, scores)):
                assert isinstance(doc, str), f"æ–‡æ¡£å†…å®¹åº”è¯¥æ˜¯å­—ç¬¦ä¸²: {query}"
                assert isinstance(score, (int, float)), f"ç›¸ä¼¼åº¦åˆ†æ•°åº”è¯¥æ˜¯æ•°å­—: {query}"
                assert 0 <= score <= 1, f"ç›¸ä¼¼åº¦åˆ†æ•°åº”è¯¥åœ¨0-1ä¹‹é—´: {score}"

        # æ¯”è¾ƒä¸²è¡Œæ‰§è¡Œæ—¶é—´ï¼ˆå¯é€‰ï¼‰
        logger.info("â±ï¸ å¼€å§‹ä¸²è¡Œæ‰§è¡Œå¯¹æ¯”æµ‹è¯•...")
        start_time = time.time()

        for query in test_queries:
            docs, scores = _rag_search_with_defaults(query, top_k=3)
            assert isinstance(docs, list) and isinstance(scores, list)

        serial_time = time.time() - start_time
        logger.info(f"â±ï¸ ä¸²è¡Œæœç´¢è€—æ—¶: {serial_time:.2f}ç§’")

        # è®¡ç®—æ€§èƒ½æå‡
        if serial_time > 0:
            speedup = serial_time / parallel_time
            logger.success(f"ğŸš€ å¹¶è¡Œæœç´¢æ€§èƒ½æå‡: {speedup:.2f}x")

        logger.success("ğŸ‰ å¹¶è¡Œè¯­ä¹‰æœç´¢æµ‹è¯•é€šè¿‡ï¼")

    def test_parallel_semantic_search_sync(self) -> None:
        """åŒæ­¥è°ƒç”¨å¹¶è¡Œè¯­ä¹‰æœç´¢æµ‹è¯•çš„åŒ…è£…å™¨"""
        logger.info("ğŸ”„ å¯åŠ¨å¹¶è¡Œè¯­ä¹‰æœç´¢æµ‹è¯•...")
        asyncio.run(self.test_parallel_semantic_search())

    @pytest.fixture(autouse=True)
    def setup_and_teardown(self) -> Generator[None, None, None]:
        """æµ‹è¯•å‰åçš„è®¾ç½®å’Œæ¸…ç†"""
        logger.info("ğŸ”§ æµ‹è¯•ç¯å¢ƒè®¾ç½®...")

        # åªåœ¨ç¬¬ä¸€æ¬¡æµ‹è¯•æ—¶æ¸…ç†æ•°æ®åº“ï¼Œç¡®ä¿ä½¿ç”¨å¹²å‡€çš„æµ‹è¯•ç¯å¢ƒ
        if not TestChromaDBRAGIntegration._db_initialized:
            reset_client()
            logger.info("ğŸ§¹ é¦–æ¬¡æµ‹è¯•å‰ï¼šæ¸…ç†äº†ç°æœ‰æ•°æ®åº“ï¼Œå‡†å¤‡åˆ›å»ºæ–°çš„æµ‹è¯•æ•°æ®")
            TestChromaDBRAGIntegration._db_initialized = True
        else:
            logger.info("ğŸ”„ åç»­æµ‹è¯•ï¼šå¤ç”¨ç°æœ‰æ•°æ®åº“ç¯å¢ƒ")

        yield

        # æµ‹è¯•ç»“æŸåä¿ç•™æ•°æ®åº“ï¼Œä¸å†æ¸…ç†
        logger.info("ğŸ§¹ æµ‹è¯•ç»“æŸï¼šä¿ç•™æ•°æ®åº“æ•°æ®ä¾›åç»­ä½¿ç”¨")
        logger.info("ğŸ§¹ æµ‹è¯•ç¯å¢ƒæ¸…ç†å®Œæˆ")


# ç‹¬ç«‹è¿è¡Œæ—¶çš„å…¥å£
if __name__ == "__main__":
    pytest.main([__file__, "-v", "-s"])
